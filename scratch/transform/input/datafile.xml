<?xml version="1.0" encoding="UTF-8"?>
<root>
<pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-30T19:07:04Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9189</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9193</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/9189-fix non-Globus properties</title>
            <url>https://github.com/IQSS/dataverse/pull/9193</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/9189-fix non-Globus properties</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>External Commitments (Jim)</text>
            </nodes>
            <totalCount>9</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEdV3I</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>Almost three years ago we made a [big push](https://github.com/IQSS/dataverse/issues/4714) thanks to @Xarthisius to teach https://mybinder.org to handle Dataverse datasets.
            
            For anyone not familiar, Binder gives you an environment for computational reproducibility in the cloud, for free!
            
            If there is code in the dataset, great, you can try to execute that code in Binder.
            
            If there is no code in the dataset, no problem, by launching the dataset in Binder, you have an environment in which you can start exploring and writing code.
            
            To be clear, the dataset author doesn't need to use Binder. Anyone wanting to explore the data (especially with code) can use Binder.
            
            @siacus and I have been talking about containers (which Binder spins up for you) and I just gave a demo to @sbarbosadataverse on how we can add a Binder button to every dataset in Harvard Dataverse by loading up the Binder tool via curl (like any external tool).
            
            First some screenshots. On a dev server, here's a copy of my "Open Source at Harvard" dataset looks. Note that a "Binder" button is shown.
            
            ![Screen Shot 2023-01-19 at 11 57 44 AM](https://user-images.githubusercontent.com/21006/213547494-ad2ef84a-ab9b-492c-8c66-9833382a4d55.png)
            
            When you click the "Binder" button, in a new tab you'll see Binder spinning up a Docker container with the dataset (code, data, docs, etc.) in it…
            
            ![Screen Shot 2023-01-19 at 2 15 51 PM](https://user-images.githubusercontent.com/21006/213547428-647936bd-d50a-4659-a262-06276cf25f51.png)
            
            This dataset happens to have two directories, code and data:
            
            ![Screen Shot 2023-01-19 at 2 16 40 PM](https://user-images.githubusercontent.com/21006/213547430-3aa820f7-52a0-4a3f-9476-140254f6e344.png)
            
            As a proof of concept, here's the execution of a Python script but the sky is the limit it terms of which languages and tools you want to run, such as Jupyter notebooks:
            
            ![Screen Shot 2023-01-19 at 2 18 42 PM](https://user-images.githubusercontent.com/21006/213547432-7db6cea1-169d-414b-8e4f-a5d0e44cc078.png)
            
            To load up the tool, use curl like usual
            
            `curl -X POST -H 'Content-type: application/json' http://localhost:8080/api/admin/externalTools --upload-file binder.json`
            
            Here's the external tool manifest:
            
            ```
            {
              "displayName": "Binder",
              "description": "Run on Binder",
              "scope": "dataset",
              "type": "explore",
              "toolUrl": "https://girder.hub.yt/api/v1/ythub/dataverse",
              "toolParameters": {
                "queryParameters": [
                  {
                    "datasetPid": "{datasetPid}"
                  },
                  {
                    "siteUrl": "{siteUrl}"
                  },
                  {
                    "key": "{apiToken}"
                  }
                ]
              }
            }
            ```
            
            (We are looking for a permanent home for this manifest at https://github.com/data-exp-lab/girder_ythub/issues/10 which should help close https://github.com/IQSS/dataverse/issues/6807 .)</body>
            <bodyText>Almost three years ago we made a big push thanks to @Xarthisius to teach https://mybinder.org to handle Dataverse datasets.
            For anyone not familiar, Binder gives you an environment for computational reproducibility in the cloud, for free!
            If there is code in the dataset, great, you can try to execute that code in Binder.
            If there is no code in the dataset, no problem, by launching the dataset in Binder, you have an environment in which you can start exploring and writing code.
            To be clear, the dataset author doesn't need to use Binder. Anyone wanting to explore the data (especially with code) can use Binder.
            @siacus and I have been talking about containers (which Binder spins up for you) and I just gave a demo to @sbarbosadataverse on how we can add a Binder button to every dataset in Harvard Dataverse by loading up the Binder tool via curl (like any external tool).
            First some screenshots. On a dev server, here's a copy of my "Open Source at Harvard" dataset looks. Note that a "Binder" button is shown.
            
            When you click the "Binder" button, in a new tab you'll see Binder spinning up a Docker container with the dataset (code, data, docs, etc.) in it…
            
            This dataset happens to have two directories, code and data:
            
            As a proof of concept, here's the execution of a Python script but the sky is the limit it terms of which languages and tools you want to run, such as Jupyter notebooks:
            
            To load up the tool, use curl like usual
            curl -X POST -H 'Content-type: application/json' http://localhost:8080/api/admin/externalTools --upload-file binder.json
            Here's the external tool manifest:
            {
              "displayName": "Binder",
              "description": "Run on Binder",
              "scope": "dataset",
              "type": "explore",
              "toolUrl": "https://girder.hub.yt/api/v1/ythub/dataverse",
              "toolParameters": {
                "queryParameters": [
                  {
                    "datasetPid": "{datasetPid}"
                  },
                  {
                    "siteUrl": "{siteUrl}"
                  },
                  {
                    "key": "{apiToken}"
                  }
                ]
              }
            }
            
            (We are looking for a permanent home for this manifest at data-exp-lab/girder_ythub#10 which should help close IQSS/dataverse#6807 .)</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-30T16:11:04Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <nodes>
                <name>pm.netcdf-hdf5.d</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>208</number>
            <repository>
              <name>dataverse.harvard.edu</name>
            </repository>
            <title>Add Binder button for operating on datasets with Jupyter notebooks, Python, R, etc.</title>
            <url>https://github.com/IQSS/dataverse.harvard.edu/issues/208</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNzQwNTY1NTE=</id>
                <name>dataverse.harvard.edu</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <nodes>
                  <name>pm.netcdf-hdf5.d</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add Binder button for operating on datasets with Jupyter notebooks, Python, R, etc.</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>NIH NetCDF (Phil)</text>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEjFxw</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>GPortas</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            Instead of calling the AbstractApiBean's findUserOrDie method on each secured endpoint to authenticate the request through one of the possible authentication credentials, this responsibility can be delegated to an outer layer. Since Dataverse already uses the JAX-RS standard in its API, the layer would nominally be a JAX-RS ContainerRequestFilter doing authentication/revalidation as a _PreMatch_ operation which would either reject the request (if authentication fails) or pass the request to the underlying API method with the logged in user account info included. To mark API endpoints that require authentication and therefore filtering, a custom annotation can be used. 
            
            This new design would support Dataverse’s existing API authentication methods into such a filter (or another one(s) - filters can be stacked). This may be most straight-forward for the stateless SignedURL mechanism. The other mechanisms, which require Database lookups, could also be moved to a filter but would still have dependencies on internal Dataverse code.
            
            This new design improves the testability and extensibility of the API authentication mechanisms.
            
            (_Specification extracted from Dataverse - SPA Authentication document_)
            
            ## What kind of user is the feature intended for?
            API User, future SPA user
            
            ## What inspired the request?
            - Re-Architecture decisions for Dataverse Authentication and related Proof Of Concept (PoC) developed.
            - Dataverse - SPA Authentication document
            
            PoC repository link: https://github.com/GPortas/dataverse/tree/poc/api_security_filter
            
            ## What existing behavior do you want changed?
            AbstractApiBean's findUserOrDie method
            
            ## Any brand new behavior do you want to add to Dataverse?
            JAX-RS ContainerRequestFilter for authentication/revalidation
            
            ## Any related open or closed issues to this feature request?
            - #9229 
            - #9063 
            
            The API auth mechanisms requested in these issues should be part of the new filter-based mechanism.</body>
            <bodyText>Overview of the Feature Request
            Instead of calling the AbstractApiBean's findUserOrDie method on each secured endpoint to authenticate the request through one of the possible authentication credentials, this responsibility can be delegated to an outer layer. Since Dataverse already uses the JAX-RS standard in its API, the layer would nominally be a JAX-RS ContainerRequestFilter doing authentication/revalidation as a PreMatch operation which would either reject the request (if authentication fails) or pass the request to the underlying API method with the logged in user account info included. To mark API endpoints that require authentication and therefore filtering, a custom annotation can be used.
            This new design would support Dataverse’s existing API authentication methods into such a filter (or another one(s) - filters can be stacked). This may be most straight-forward for the stateless SignedURL mechanism. The other mechanisms, which require Database lookups, could also be moved to a filter but would still have dependencies on internal Dataverse code.
            This new design improves the testability and extensibility of the API authentication mechanisms.
            (Specification extracted from Dataverse - SPA Authentication document)
            What kind of user is the feature intended for?
            API User, future SPA user
            What inspired the request?
            
            Re-Architecture decisions for Dataverse Authentication and related Proof Of Concept (PoC) developed.
            Dataverse - SPA Authentication document
            
            PoC repository link: https://github.com/GPortas/dataverse/tree/poc/api_security_filter
            What existing behavior do you want changed?
            AbstractApiBean's findUserOrDie method
            Any brand new behavior do you want to add to Dataverse?
            JAX-RS ContainerRequestFilter for authentication/revalidation
            Any related open or closed issues to this feature request?
            
            #9229
            #9063
            
            The API auth mechanisms requested in these issues should be part of the new filter-based mechanism.</bodyText>
            <closed>True</closed>
            <closedAt>2023-02-22T15:14:06Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: API</name>
              </nodes>
              <nodes>
                <name>User Role: API User</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.7.1 (reArchitecture)</name>
              </nodes>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>9293</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>New filter-based design for the API authentication mechanisms</title>
            <url>https://github.com/IQSS/dataverse/issues/9293</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: API</name>
                </nodes>
                <nodes>
                  <name>User Role: API User</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.7.1 (reArchitecture)</name>
                </nodes>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.14</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>New filter-based design for the API authentication mechanisms</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: Auth MVP (Phil)</text>
            </nodes>
            <totalCount>10</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEW8Kk</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>Definition of Done:
            - [ ] front end is created
            - [ ] Code, javascript and a test metadatablock in the other repo
            
            
            
            (i.e. not production )</body>
            <bodyText>Definition of Done:
            
             front end is created
             Code, javascript and a test metadatablock in the other repo
            
            (i.e. not production )</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>NIH OTA: 1.2.1</name>
              </nodes>
              <nodes>
                <name>Size: 80</name>
              </nodes>
              <nodes>
                <name>D: 5 Core PIDs</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.2.1</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>9150</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Create a javascript for the frontend that supports Fundref</title>
            <url>https://github.com/IQSS/dataverse/issues/9150</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>NIH OTA: 1.2.1</name>
                </nodes>
                <nodes>
                  <name>Size: 80</name>
                </nodes>
                <nodes>
                  <name>D: 5 Core PIDs</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.2.1</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create a javascript for the frontend that supports Fundref</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>5 Core PIDs</text>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEPm1E</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-30T19:40:09Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>7349</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>QDR</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9086</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Iqss/7349 2 improve related pub citation entry</title>
            <url>https://github.com/IQSS/dataverse/pull/9086</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>QDR</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Iqss/7349 2 improve related pub citation entry</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>External Commitments (Jim)</text>
            </nodes>
            <totalCount>9</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTck</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>This script completes a single field on a form. Author affiliation
            
            
            definition of done:
            - [ ] If it acts as intended, in particular the last time it broke other pages, the we can call this complete.
            - [ ] If it works well, we can put it out on demo.
            - [ ] Make a recommendation as to if it can go into production
              - If this is the case this will lead to a separate issue to move the script into production
            
            
            
            
            
            </body>
            <bodyText>This script completes a single field on a form. Author affiliation
            definition of done:
            
             If it acts as intended, in particular the last time it broke other pages, the we can call this complete.
             If it works well, we can put it out on demo.
             Make a recommendation as to if it can go into production
            
            If this is the case this will lead to a separate issue to move the script into production</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>NIH OTA: 1.2.1</name>
              </nodes>
              <nodes>
                <name>Size: 80</name>
              </nodes>
              <nodes>
                <name>D: 5 Core PIDs</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.2.1</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>9151</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Get the existing ROR plug-in working on the dataverse demo</title>
            <url>https://github.com/IQSS/dataverse/issues/9151</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>NIH OTA: 1.2.1</name>
                </nodes>
                <nodes>
                  <name>Size: 80</name>
                </nodes>
                <nodes>
                  <name>D: 5 Core PIDs</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.2.1</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Get the existing ROR plug-in working on the dataverse demo</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>NIH NetCDF (Phil)</text>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEPm2g</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-30T18:37:14Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>7349</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>QDR</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9101</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/7349-5 - Use brand name for catalog</title>
            <url>https://github.com/IQSS/dataverse/pull/9101</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>QDR</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/7349-5 - Use brand name for catalog</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>External Commitments (Jim)</text>
            </nodes>
            <totalCount>9</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNnG4</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>sekmiller</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>
            Please fill out as much of the template as you can.
            Start below this comment section.
            --&gt;
            Follow the link to this draft dataset in production, which has a long list of file-level tags and long description:
            https://dataverse.harvard.edu/file.xhtml?fileId=6489063&amp;version=DRAFT
            The tags run off the page, see screen capture
            
            * When does this issue occur?
            Whenever file level tags or description exceed a certain # of characters, not sure how many characters are supported
            
            * Which page(s) does it occurs on?
            FILE LANDING PAGE
            
            * What happens?
            FILE-LEVEL METADATA TAGS/description RUN OFF THE PAGE WHEN EXCEED CERTAIN #CHARACTERS
            
            * To whom does it occur (all users, curators, superusers)?
            SUPER USERS, ADMINS (ALL USERS)
            
            * What did you expect to happen?
            * TAGS/TEXT SHOULD WRAP
            
            @scolapasta this is for a paid curation project we plan to release soon. Please add to sprint.
            
            **Which version of Dataverse are you using?**
            
            MOST RECENT
            
            **Any related open or closed issues to this bug report?**
            
            
            
            **Screenshots:**
            
            &lt;img width="2080" alt="Screen Shot 2022-09-13 at 4 18 29 PM" src="https://user-images.githubusercontent.com/8322346/190001154-2d82dc1f-73f5-4487-a15f-43ea8e7ce019.png"&gt;
            
            </body>
            <bodyText>Please fill out as much of the template as you can.
            Start below this comment section.
            --&gt;
            Follow the link to this draft dataset in production, which has a long list of file-level tags and long description:
            https://dataverse.harvard.edu/file.xhtml?fileId=6489063&amp;version=DRAFT
            The tags run off the page, see screen capture
            
            
            When does this issue occur?
            Whenever file level tags or description exceed a certain # of characters, not sure how many characters are supported
            
            
            Which page(s) does it occurs on?
            FILE LANDING PAGE
            
            
            What happens?
            FILE-LEVEL METADATA TAGS/description RUN OFF THE PAGE WHEN EXCEED CERTAIN #CHARACTERS
            
            
            To whom does it occur (all users, curators, superusers)?
            SUPER USERS, ADMINS (ALL USERS)
            
            
            What did you expect to happen?
            
            
            TAGS/TEXT SHOULD WRAP
            
            
            @scolapasta this is for a paid curation project we plan to release soon. Please add to sprint.
            Which version of Dataverse are you using?
            MOST RECENT
            Any related open or closed issues to this bug report?
            Screenshots:</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-31T18:27:25Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: Metadata</name>
              </nodes>
              <nodes>
                <name>Type: Bug</name>
              </nodes>
              <nodes>
                <name>Feature: Style Guide</name>
              </nodes>
              <nodes>
                <name>User Role: Superuser</name>
              </nodes>
              <nodes>
                <name>Feature: Controlled Vocabulary</name>
              </nodes>
              <nodes>
                <name>Hackathon: JSF</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>7</totalCount>
            </labels>
            <number>8975</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>File level metadata: File level metadata tags should wrap and not run off the page</title>
            <url>https://github.com/IQSS/dataverse/issues/8975</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Metadata</name>
                </nodes>
                <nodes>
                  <name>Type: Bug</name>
                </nodes>
                <nodes>
                  <name>Feature: Style Guide</name>
                </nodes>
                <nodes>
                  <name>User Role: Superuser</name>
                </nodes>
                <nodes>
                  <name>Feature: Controlled Vocabulary</name>
                </nodes>
                <nodes>
                  <name>Hackathon: JSF</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>7</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>File level metadata: File level metadata tags should wrap and not run off the page</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Harvard Dataverse Instance (Sonia)</text>
            </nodes>
            <totalCount>10</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgD1Szg</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-30T19:52:10Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>7349</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>QDR</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9087</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/7349-3 file updates for schema.org</title>
            <url>https://github.com/IQSS/dataverse/pull/9087</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>QDR</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/7349-3 file updates for schema.org</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>External Commitments (Jim)</text>
            </nodes>
            <totalCount>9</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTcg</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-27T21:02:15Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9130</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: SprintTail</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9132</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Dataset files cleanup</title>
            <url>https://github.com/IQSS/dataverse/pull/9132</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: SprintTail</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>1</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Dataset files cleanup</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Community Backlog (Phil)</text>
            </nodes>
            <totalCount>10</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDgBco</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <pageInfo>
          <endCursor>MTA</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>False</hasPreviousPage>
          <startCursor>MQ</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-31T19:27:31Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9211</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9212</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>#9211 fix render logic display with TOA OR restricted files</title>
            <url>https://github.com/IQSS/dataverse/pull/9212</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>#9211 fix render logic display with TOA OR restricted files</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Dataverse Team (Gustavo)</text>
            </nodes>
            <totalCount>9</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDy_vQ</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>sekmiller</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>Bug can be viewed on SAEF data collection in production
            
            
            **What steps does it take to reproduce the issue?**
            
            Enter a certain amount of text in the description metadata field of a dataset
            
            * When does this issue occur?
            On publishing with a certain amount of text in description field
            
            * Which page(s) does it occurs on?
            dataset  landing page
            
            * What happens?
            text runs off the page
            
            * To whom does it occur (all users, curators, superusers)?
            curatore
            
            * What did you expect to happen?
            
            text should wrap
            
            **Which version of Dataverse are you using?**
            
            most recent
            
            **Any related open or closed issues to this bug report?**
            
            file tags metadata field has same issues
            
            **Screenshots:**
            
            *
            ![Screen Shot 2023-01-25 at 12 05 57 PM](https://user-images.githubusercontent.com/8322346/214631963-30ddaed0-cfb8-43ab-b3c7-6b386b4817d0.png)
            
            </body>
            <bodyText>Bug can be viewed on SAEF data collection in production
            What steps does it take to reproduce the issue?
            Enter a certain amount of text in the description metadata field of a dataset
            
            
            When does this issue occur?
            On publishing with a certain amount of text in description field
            
            
            Which page(s) does it occurs on?
            dataset  landing page
            
            
            What happens?
            text runs off the page
            
            
            To whom does it occur (all users, curators, superusers)?
            curatore
            
            
            What did you expect to happen?
            
            
            text should wrap
            Which version of Dataverse are you using?
            most recent
            Any related open or closed issues to this bug report?
            file tags metadata field has same issues
            Screenshots:</bodyText>
            <closed>True</closed>
            <closedAt>2023-02-14T18:33:31Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9325</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Description metadata field: Description field text should wrap and not run off the page</title>
            <url>https://github.com/IQSS/dataverse/issues/9325</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Description metadata field: Description field text should wrap and not run off the page</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEgUqU</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-30T20:38:16Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>7349</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>QDR</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9085</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Iqss/7349 1 truncate description</title>
            <url>https://github.com/IQSS/dataverse/pull/9085</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>QDR</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Iqss/7349 1 truncate description</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTco</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>So far the Explore button in DV takes us to Whole Tale:
            
            ![image](https://user-images.githubusercontent.com/13986265/78938018-758f9200-7a7f-11ea-83ec-8261078b6b12.png)
            
            It would be good to discuss adding Binder also. This is already possible on their side, as one can explore Dataverse datasets with a DOI. See here: https://mybinder.org and in picture:
            
            ![image](https://user-images.githubusercontent.com/13986265/78937357-5c3a1600-7a7e-11ea-949a-c4ac162ec2d6.png)
            </body>
            <bodyText>So far the Explore button in DV takes us to Whole Tale:
            
            It would be good to discuss adding Binder also. This is already possible on their side, as one can explore Dataverse datasets with a DOI. See here: https://mybinder.org and in picture:</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-31T19:20:02Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: External Tool</name>
              </nodes>
              <nodes>
                <name>pm.netcdf-hdf5.d</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>6807</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Explore button for Binder</title>
            <url>https://github.com/IQSS/dataverse/issues/6807</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: External Tool</name>
                </nodes>
                <nodes>
                  <name>pm.netcdf-hdf5.d</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Explore button for Binder</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>NIH NetCDF (Phil)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgENlb0</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-30T19:18:15Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: User Guide</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9249</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>DOCS: add link to development documentation build</title>
            <url>https://github.com/IQSS/dataverse/pull/9249</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: User Guide</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>DOCS: add link to development documentation build</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEIJwM</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-02-09T19:59:42Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9253</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Metadata</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9254</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Make productionPlace multiple, facetable, and enabled for Advanced Search #9253</title>
            <url>https://github.com/IQSS/dataverse/pull/9254</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Metadata</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Make productionPlace multiple, facetable, and enabled for Advanced Search #9253</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEJJIY</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-31T20:51:49Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9016</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>JHU</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9017</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>GDCC/9016-handle no file PID case in metrics</title>
            <url>https://github.com/IQSS/dataverse/pull/9017</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>JHU</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>GDCC/9016-handle no file PID case in metrics</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTc4</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-03-20T15:49:37Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>DANS</name>
              </nodes>
              <nodes>
                <name>Size: 80</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>8674</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>DANS/Local PermaLink PID Provider</title>
            <url>https://github.com/IQSS/dataverse/pull/8674</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>DANS</name>
                </nodes>
                <nodes>
                  <name>Size: 80</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>1</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>DANS/Local PermaLink PID Provider</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTjw</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-30T22:19:20Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9309</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9316</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Fix for the broken "earliest date" (#9309)</title>
            <url>https://github.com/IQSS/dataverse/pull/9316</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Fix for the broken "earliest date" (#9309)</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEex98</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>landreev</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>(creating this as a followup to an email discussion; making this a NIH GREI deliverable has been mentioned)
            
            This is a request from/for a specific collaboration - integration of Dataverse with Data Monitor. The idea is that an admin will be able to configure a Harvesting Client with some entry(-ies) to be added as extra HTTP headers when making requests to the OAI archive in question. Specifically in their use case this extra header will contain a special token issued by the remote archive (DM), authorizing the client to receive some extra content (that, I'm assuming, they don't want to be fully public). 
            
            It feels like this would be something very doable. On the Dataverse side, I'm seeing this as another entry on the Harvesting Client config form ("Custom Headers"), and another entry in the json format that `/api/harvest/clients` understands. We'll add another column to the clients db table to store these entries. 
            
            The only remotely tricky part here is that it will require a PR into gdcc/xoai as well - because that's where the http requests are cooked. Should still be straightforward. 
            </body>
            <bodyText>(creating this as a followup to an email discussion; making this a NIH GREI deliverable has been mentioned)
            This is a request from/for a specific collaboration - integration of Dataverse with Data Monitor. The idea is that an admin will be able to configure a Harvesting Client with some entry(-ies) to be added as extra HTTP headers when making requests to the OAI archive in question. Specifically in their use case this extra header will contain a special token issued by the remote archive (DM), authorizing the client to receive some extra content (that, I'm assuming, they don't want to be fully public).
            It feels like this would be something very doable. On the Dataverse side, I'm seeing this as another entry on the Harvesting Client config form ("Custom Headers"), and another entry in the json format that /api/harvest/clients understands. We'll add another column to the clients db table to store these entries.
            The only remotely tricky part here is that it will require a PR into gdcc/xoai as well - because that's where the http requests are cooked. Should still be straightforward.</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-26T20:17:32Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 80</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.2</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>9231</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Feature request: Add the ability to configure a Harvesting Client to add a custom header to OAI calls</title>
            <url>https://github.com/IQSS/dataverse/issues/9231</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 80</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.2</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Feature request: Add the ability to configure a Harvesting Client to add a custom header to OAI calls</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEQ8hQ</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MjA</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MTE</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-25T20:57:01Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8339</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: SprintTail</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9269</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>8339 file data api</title>
            <url>https://github.com/IQSS/dataverse/pull/9269</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: SprintTail</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>8339 file data api</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEREPI</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-20T16:03:40Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9153</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9239</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>extract metadata (NcML XML) from NetCDF/HDF5 files, new "requirements" option for external tools</title>
            <url>https://github.com/IQSS/dataverse/pull/9239</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>extract metadata (NcML XML) from NetCDF/HDF5 files, new "requirements" option for external tools</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>NIH NetCDF (Phil)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgERENo</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-24T18:25:11Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>7980</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>8915</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>7980 enhanced dsd</title>
            <url>https://github.com/IQSS/dataverse/pull/8915</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>2</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>7980 enhanced dsd</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDO4h0</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-18T22:19:29Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: File Upload &amp; Handling</name>
              </nodes>
              <nodes>
                <name>Feature: Code Infrastructure</name>
              </nodes>
              <nodes>
                <name>Feature: Installation Guide</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>Containers &amp; Cloud</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>6</totalCount>
            </labels>
            <number>8827</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>7000 mpconfig files basic</title>
            <url>https://github.com/IQSS/dataverse/pull/8827</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: File Upload &amp; Handling</name>
                </nodes>
                <nodes>
                  <name>Feature: Code Infrastructure</name>
                </nodes>
                <nodes>
                  <name>Feature: Installation Guide</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>Containers &amp; Cloud</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>6</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>7000 mpconfig files basic</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPakE</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-23T15:15:42Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9104</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>DANS</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9105</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Add quotes around CVoc term URIs on advanced search page</title>
            <url>https://github.com/IQSS/dataverse/pull/9105</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>DANS</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add quotes around CVoc term URIs on advanced search page</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNnFM</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-23T15:25:40Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9121</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>DANS</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9122</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/9121 Fix for search display with ext. CVoc</title>
            <url>https://github.com/IQSS/dataverse/pull/9122</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>DANS</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/9121 Fix for search display with ext. CVoc</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDP82U</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-18T20:17:06Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9126</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>DANS</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9129</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/9126- Fix workflow token access</title>
            <url>https://github.com/IQSS/dataverse/pull/9129</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>DANS</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>1</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/9126- Fix workflow token access</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDQd5Q</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>qqmyers</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>- [x] In TabularSubsetGenerator.java use try-with-resources for BufferedWriter out = new BufferedWriter(new FileWriter(outfile)); in method subsetFile(...) 
            - [ ] 
            - [x] -- FileChannel fc = (FileChannel.open(Paths.get(rotatedImageFile.getAbsolutePath()), StandardOpenOption.READ)); in method subsetObjectVector(...) 
            - [ ] 
            - [x] --  BufferedInputStream rotfileStream = new BufferedInputStream(new FileInputStream(rotatedImageFile)); in method extract(...)  
            - [ ] 
            - [x] --- Scanner scanner = new Scanner(tabfileStream); in generateRotatedImage(...) 
            - [ ] 
            - [x] ---    BufferedOutputStream finalOut = new BufferedOutputStream(new FileOutputStream (new File(rotatedImageFileName))); in generateRotatedImage(...) 
            - [ ] 
            - [x] --- BufferedInputStream cachedIn = new BufferedInputStream(new FileInputStream(cachedTempFile)); in method generateRotatedImage(...) 
            - [ ] 
            - [x] ---BufferedInputStream rotfileStream = new BufferedInputStream(new FileInputStream(rotfile)); in reverseRotatedImage(...)</body>
            <bodyText>In TabularSubsetGenerator.java use try-with-resources for BufferedWriter out = new BufferedWriter(new FileWriter(outfile)); in method subsetFile(...)
            [ ]
             -- FileChannel fc = (FileChannel.open(Paths.get(rotatedImageFile.getAbsolutePath()), StandardOpenOption.READ)); in method subsetObjectVector(...)
            [ ]
             --  BufferedInputStream rotfileStream = new BufferedInputStream(new FileInputStream(rotatedImageFile)); in method extract(...)
            [ ]
             --- Scanner scanner = new Scanner(tabfileStream); in generateRotatedImage(...)
            [ ]
             ---    BufferedOutputStream finalOut = new BufferedOutputStream(new FileOutputStream (new File(rotatedImageFileName))); in generateRotatedImage(...)
            [ ]
             --- BufferedInputStream cachedIn = new BufferedInputStream(new FileInputStream(cachedTempFile)); in method generateRotatedImage(...)
            [ ]
             ---BufferedInputStream rotfileStream = new BufferedInputStream(new FileInputStream(rotfile)); in reverseRotatedImage(...)</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-26T18:18:23Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <nodes>
                <name>Tech Debt</name>
              </nodes>
              <nodes>
                <name>D: SonarQubeCleanup</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>9282</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>In TabularSubsetGenerator.java use try-with-resources for BufferedWriter</title>
            <url>https://github.com/IQSS/dataverse/issues/9282</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <nodes>
                  <name>Tech Debt</name>
                </nodes>
                <nodes>
                  <name>D: SonarQubeCleanup</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>In TabularSubsetGenerator.java use try-with-resources for BufferedWriter</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEQ35M</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>qqmyers</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>In Files.java usr try-with-resources to for  JsonReader jsonReader = Json.createReader(new StringReader(jsonData)); in method updateFileMetadata</body>
            <bodyText>In Files.java usr try-with-resources to for  JsonReader jsonReader = Json.createReader(new StringReader(jsonData)); in method updateFileMetadata</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-26T18:18:22Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <nodes>
                <name>Tech Debt</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9280</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>In Files.java usr try-with-resources to for  JsonReader</title>
            <url>https://github.com/IQSS/dataverse/issues/9280</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <nodes>
                  <name>Tech Debt</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>In Files.java usr try-with-resources to for  JsonReader</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEQ28M</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-21T15:23:24Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Type: Feature</name>
              </nodes>
              <nodes>
                <name>Feature: Code Infrastructure</name>
              </nodes>
              <nodes>
                <name>Feature: Installation Guide</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>Containers &amp; Cloud</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>6</totalCount>
            </labels>
            <number>8830</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>7000 mpconfig rserve</title>
            <url>https://github.com/IQSS/dataverse/pull/8830</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Type: Feature</name>
                </nodes>
                <nodes>
                  <name>Feature: Code Infrastructure</name>
                </nodes>
                <nodes>
                  <name>Feature: Installation Guide</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>Containers &amp; Cloud</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>6</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>7000 mpconfig rserve</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPajk</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <pageInfo>
          <endCursor>MzA</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MjE</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>Outcome from the daily Standups: Continue the daily standups
            This helps us have a good sprint.
            
            Definition of done:
            We need not do anything new.
            Just continue doing our daily standups as we did in this last sprint!
            This can be closed on the first day of the sprint.
            </body>
            <bodyText>Outcome from the daily Standups: Continue the daily standups
            This helps us have a good sprint.
            Definition of done:
            We need not do anything new.
            Just continue doing our daily standups as we did in this last sprint!
            This can be closed on the first day of the sprint.</bodyText>
            <closed>True</closed>
            <closedAt>2022-12-01T17:28:36Z</closedAt>
            <labels>
              <nodes>
                <name>Sprint Retrospective</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9201</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Retrospective: Continue the daily standups.</title>
            <url>https://github.com/IQSS/dataverse/issues/9201</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Sprint Retrospective</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Retrospective: Continue the daily standups.</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 1, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDr79w</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-03T22:13:20Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9095</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>DataverseNO</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9096</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/9095-dvwebloader integration</title>
            <url>https://github.com/IQSS/dataverse/pull/9096</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>DataverseNO</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/9095-dvwebloader integration</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNnIs</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-09T16:10:49Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9228</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Account &amp; User Info</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.7.1 (reArchitecture)</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>9234</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>9228 - add OIDC development setup for OIDC login feature testing</title>
            <url>https://github.com/IQSS/dataverse/pull/9234</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Account &amp; User Info</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.7.1 (reArchitecture)</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>1</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>9228 - add OIDC development setup for OIDC login feature testing</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEJPkw</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-15T18:45:07Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8843</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9227</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>8843 more harvest tests</title>
            <url>https://github.com/IQSS/dataverse/pull/9227</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>8843 more harvest tests</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgD575s</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-15T20:23:09Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9172</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9173</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>QDR/9172-fix messages</title>
            <url>https://github.com/IQSS/dataverse/pull/9173</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>QDR/9172-fix messages</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDieAs</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-16T14:18:18Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9226</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>import function DatasetUtil</title>
            <url>https://github.com/IQSS/dataverse/pull/9226</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>import function DatasetUtil</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgD4sWU</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>Assuming PR #9152 is merged we'll have a library in place to start extracting XML from NetCDF and HDF5 files.
            
            The supported XML format is called NcML and is described here: https://docs.unidata.ucar.edu/netcdf-java/current/userguide/ncml_overview.html
            
            Yesterday there was general agreement among devs that it would be fine to save the XML as a derivative or aux file.
            
            This will open the door for previewing the file as raw XML to start.
            
            Additionally, we could work on created a dedicated previewer that shows the data in a nicer way than raw XML.
            
            The code we write will look something like this:
            
            ```
            String ncml = netcdfFile.toNcml(file.getName());
            ```
            
            Here's the output for an HDF5 file at `src/test/resources/hdf/hdf5/vlen_string_dset` (from the PR above):
            
            ```
            &lt;?xml version="1.0" encoding="UTF-8"?&gt;
            &lt;netcdf xmlns="http://www.unidata.ucar.edu/namespaces/netcdf/ncml-2.2" location="file:vlen_string_dset"&gt;
              &lt;variable name="DS1" shape="4" type="String" /&gt;
            &lt;/netcdf&gt;
            ```
            
            Here's part of the output for a NetCDF file at `src/test/resources/netcdf/madis-raob.nc` (also from the PR above):
            
            ```
            &lt;?xml version="1.0" encoding="UTF-8"?&gt;
            &lt;netcdf xmlns="http://www.unidata.ucar.edu/namespaces/netcdf/ncml-2.2" location="file:madis-raob.nc"&gt;
              &lt;dimension name="recNum" length="1" isUnlimited="true" /&gt;
              &lt;dimension name="manLevel" length="22" /&gt;
              &lt;dimension name="sigTLevel" length="150" /&gt;
              &lt;dimension name="sigWLevel" length="76" /&gt;
              &lt;dimension name="mWndNum" length="4" /&gt;
              &lt;dimension name="mTropNum" length="4" /&gt;
              &lt;dimension name="staNameLen" length="50" /&gt;
              &lt;dimension name="QCcheckNum" length="10" /&gt;
              &lt;dimension name="QCcheckNameLen" length="60" /&gt;
              &lt;dimension name="maxStaticIds" length="1000" /&gt;
              &lt;dimension name="totalIdLen" length="50" /&gt;
              &lt;dimension name="nInventoryBins" length="32" /&gt;
              &lt;variable name="nStaticIds" shape="" type="int"&gt;
                &lt;attribute name="_FillValue" type="int" value="0" /&gt;
              &lt;/variable&gt;
              &lt;variable name="staticIds" shape="maxStaticIds totalIdLen" type="char"&gt;
                &lt;attribute name="_FillValue" value="" /&gt;
              &lt;/variable&gt;
              &lt;variable name="lastRecord" shape="maxStaticIds" type="int"&gt;
                &lt;attribute name="_FillValue" type="int" value="-1" /&gt;
              &lt;/variable&gt;
              &lt;variable name="invTime" shape="recNum" type="int"&gt;
                &lt;attribute name="_FillValue" type="int" value="0" /&gt;
              &lt;/variable&gt;
            ...
            ```
            
            Here's the full XML/NcML output: [madis-ncml.xml.txt](https://github.com/IQSS/dataverse/files/9972770/madis-ncml.xml.txt)
            
            ---
            
            2.5 years ago @qqmyers made some suggestions for previewing XML files at https://github.com/IQSS/dataverse.harvard.edu/issues/70#issuecomment-631087257 . Here's his comment:
            
            "FWIW: Something like https://www.jqueryscript.net/other/tree-xml-viewer-formatter.html adapted with the wiki instructions at https://github.com/GlobalDataverseCommunityConsortium/dataverse-previewers/wiki/How-to-create-a-previewer might be a quick win. (I didn't search too hard for an XML viewer - there could be better libraries out there to start from.)"</body>
            <bodyText>Assuming PR #9152 is merged we'll have a library in place to start extracting XML from NetCDF and HDF5 files.
            The supported XML format is called NcML and is described here: https://docs.unidata.ucar.edu/netcdf-java/current/userguide/ncml_overview.html
            Yesterday there was general agreement among devs that it would be fine to save the XML as a derivative or aux file.
            This will open the door for previewing the file as raw XML to start.
            Additionally, we could work on created a dedicated previewer that shows the data in a nicer way than raw XML.
            The code we write will look something like this:
            String ncml = netcdfFile.toNcml(file.getName());
            
            Here's the output for an HDF5 file at src/test/resources/hdf/hdf5/vlen_string_dset (from the PR above):
            &lt;?xml version="1.0" encoding="UTF-8"?&gt;
            &lt;netcdf xmlns="http://www.unidata.ucar.edu/namespaces/netcdf/ncml-2.2" location="file:vlen_string_dset"&gt;
              &lt;variable name="DS1" shape="4" type="String" /&gt;
            &lt;/netcdf&gt;
            
            Here's part of the output for a NetCDF file at src/test/resources/netcdf/madis-raob.nc (also from the PR above):
            &lt;?xml version="1.0" encoding="UTF-8"?&gt;
            &lt;netcdf xmlns="http://www.unidata.ucar.edu/namespaces/netcdf/ncml-2.2" location="file:madis-raob.nc"&gt;
              &lt;dimension name="recNum" length="1" isUnlimited="true" /&gt;
              &lt;dimension name="manLevel" length="22" /&gt;
              &lt;dimension name="sigTLevel" length="150" /&gt;
              &lt;dimension name="sigWLevel" length="76" /&gt;
              &lt;dimension name="mWndNum" length="4" /&gt;
              &lt;dimension name="mTropNum" length="4" /&gt;
              &lt;dimension name="staNameLen" length="50" /&gt;
              &lt;dimension name="QCcheckNum" length="10" /&gt;
              &lt;dimension name="QCcheckNameLen" length="60" /&gt;
              &lt;dimension name="maxStaticIds" length="1000" /&gt;
              &lt;dimension name="totalIdLen" length="50" /&gt;
              &lt;dimension name="nInventoryBins" length="32" /&gt;
              &lt;variable name="nStaticIds" shape="" type="int"&gt;
                &lt;attribute name="_FillValue" type="int" value="0" /&gt;
              &lt;/variable&gt;
              &lt;variable name="staticIds" shape="maxStaticIds totalIdLen" type="char"&gt;
                &lt;attribute name="_FillValue" value="" /&gt;
              &lt;/variable&gt;
              &lt;variable name="lastRecord" shape="maxStaticIds" type="int"&gt;
                &lt;attribute name="_FillValue" type="int" value="-1" /&gt;
              &lt;/variable&gt;
              &lt;variable name="invTime" shape="recNum" type="int"&gt;
                &lt;attribute name="_FillValue" type="int" value="0" /&gt;
              &lt;/variable&gt;
            ...
            
            Here's the full XML/NcML output: madis-ncml.xml.txt
            
            2.5 years ago @qqmyers made some suggestions for previewing XML files at IQSS/dataverse.harvard.edu#70 (comment) . Here's his comment:
            "FWIW: Something like https://www.jqueryscript.net/other/tree-xml-viewer-formatter.html adapted with the wiki instructions at https://github.com/GlobalDataverseCommunityConsortium/dataverse-previewers/wiki/How-to-create-a-previewer might be a quick win. (I didn't search too hard for an XML viewer - there could be better libraries out there to start from.)"</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-20T16:03:42Z</closedAt>
            <labels>
              <nodes>
                <name>pm.netcdf-hdf5.d</name>
              </nodes>
              <nodes>
                <name>Size: 80</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9153</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Extract metadata from NetCDF and HDF5 files as XML in NcML format</title>
            <url>https://github.com/IQSS/dataverse/issues/9153</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>pm.netcdf-hdf5.d</name>
                </nodes>
                <nodes>
                  <name>Size: 80</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Extract metadata from NetCDF and HDF5 files as XML in NcML format</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>NIH NetCDF (Phil)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDWIBo</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>sekmiller</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>
            
            We do not have an easy way to retrieve a full information record for a single datafile, such as what's listed in `/api/datasets/{did}/versions/{vid}` (for all files in the version). 
            We do have `/api/files/{id}/metadata`, but it literally only shows what's in the FileMetadata entity (such as file and folder names), plus the tags and the restriction status. I.e., it's not showing all the info that's in the DataFile entity (size, mime type, etc. etc.). So the only practical way for an API user to look up a full info record for a file is to get a full list of all the files (above) and parse it out, which is inefficient. 
            
            We could extend `/api/files/{id}/metadata`, synchronizing its output to what's listed in the records under `/api/datasets/{did}/versions/{vid}`. 
            Alternatively, we could provide a GET `/api/files/{id}` to produce such a record. (This could be a better option - since it would match the behavior of other entity APIs - `/api/datasets/{id}` etc. - ?)</body>
            <bodyText>We do not have an easy way to retrieve a full information record for a single datafile, such as what's listed in /api/datasets/{did}/versions/{vid} (for all files in the version).
            We do have /api/files/{id}/metadata, but it literally only shows what's in the FileMetadata entity (such as file and folder names), plus the tags and the restriction status. I.e., it's not showing all the info that's in the DataFile entity (size, mime type, etc. etc.). So the only practical way for an API user to look up a full info record for a file is to get a full list of all the files (above) and parse it out, which is inefficient.
            We could extend /api/files/{id}/metadata, synchronizing its output to what's listed in the records under /api/datasets/{did}/versions/{vid}.
            Alternatively, we could provide a GET /api/files/{id} to produce such a record. (This could be a better option - since it would match the behavior of other entity APIs - /api/datasets/{id} etc. - ?)</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-25T20:57:04Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>8339</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Provide an API for retrieving information about an individual datafile</title>
            <url>https://github.com/IQSS/dataverse/issues/8339</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Provide an API for retrieving information about an individual datafile</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNX3k</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-21T17:22:13Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>7844</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Metadata</name>
              </nodes>
              <nodes>
                <name>Working Group: SWC</name>
              </nodes>
              <nodes>
                <name>HERMES</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.3.1</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.3.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.3.2</name>
              </nodes>
              <totalCount>7</totalCount>
            </labels>
            <number>7877</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>7844 codemeta schema</title>
            <url>https://github.com/IQSS/dataverse/pull/7877</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Metadata</name>
                </nodes>
                <nodes>
                  <name>Working Group: SWC</name>
                </nodes>
                <nodes>
                  <name>HERMES</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.3.1</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.3.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.3.2</name>
                </nodes>
                <totalCount>7</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>2</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>7844 codemeta schema</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNc7o</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-21T17:41:20Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8840</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>8972</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Trigger auto-analyze more frequently for guestbook estimates</title>
            <url>https://github.com/IQSS/dataverse/pull/8972</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Trigger auto-analyze more frequently for guestbook estimates</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTdo</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <pageInfo>
          <endCursor>NDA</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MzE</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-10T23:44:57Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>5924</number>
              </nodes>
              <nodes>
                <number>9005</number>
              </nodes>
              <totalCount>2</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>DANS</name>
              </nodes>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9018</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>GDCC/9005 replace files api call</title>
            <url>https://github.com/IQSS/dataverse/pull/9018</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>DANS</name>
                </nodes>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>GDCC/9005 replace files api call</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTc0</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-16T16:19:57Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8730</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>DataverseNO</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>8962</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/8730 - fix direct upload progress</title>
            <url>https://github.com/IQSS/dataverse/pull/8962</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>DataverseNO</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/8730 - fix direct upload progress</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTdw</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-16T19:58:41Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8932</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Containers &amp; Cloud</name>
              </nodes>
              <nodes>
                <name>Working Group: SWC</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>8933</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>8932 container base image</title>
            <url>https://github.com/IQSS/dataverse/pull/8933</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Containers &amp; Cloud</name>
                </nodes>
                <nodes>
                  <name>Working Group: SWC</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>8932 container base image</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDO5Ug</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-16T22:47:09Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9074</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9076</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>#9074 - Added support for building sphinx docs using python 3.10+</title>
            <url>https://github.com/IQSS/dataverse/pull/9076</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>#9074 - Added support for building sphinx docs using python 3.10+</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTcs</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-16T21:01:50Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Code Infrastructure</name>
              </nodes>
              <nodes>
                <name>Feature: Developer Guide</name>
              </nodes>
              <nodes>
                <name>Containers &amp; Cloud</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>8824</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>7000 mpconfig version</title>
            <url>https://github.com/IQSS/dataverse/pull/8824</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Code Infrastructure</name>
                </nodes>
                <nodes>
                  <name>Feature: Developer Guide</name>
                </nodes>
                <nodes>
                  <name>Containers &amp; Cloud</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>7000 mpconfig version</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDRVZw</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-20T17:43:32Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Code Infrastructure</name>
              </nodes>
              <nodes>
                <name>Feature: Installation Guide</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>8826</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>7000 mpconfig fqdn &amp; siteUrl</title>
            <url>https://github.com/IQSS/dataverse/pull/8826</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Code Infrastructure</name>
                </nodes>
                <nodes>
                  <name>Feature: Installation Guide</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>7000 mpconfig fqdn &amp; siteUrl</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPaiw</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-21T21:24:28Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>3212</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Code Infrastructure</name>
              </nodes>
              <nodes>
                <name>Feature: Installation Guide</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>Containers &amp; Cloud</name>
              </nodes>
              <nodes>
                <name>Feature: Indexing</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>6</totalCount>
            </labels>
            <number>8825</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>7000 mpconfig solr</title>
            <url>https://github.com/IQSS/dataverse/pull/8825</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Code Infrastructure</name>
                </nodes>
                <nodes>
                  <name>Feature: Installation Guide</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>Containers &amp; Cloud</name>
                </nodes>
                <nodes>
                  <name>Feature: Indexing</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>6</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>7000 mpconfig solr</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPajM</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>We should understand how much time people are actually spending on board tasks.  Ask at the end of the daily to see if anyone is working something off the board. 
            
            Def of done:
            - Work items need to be worked during sprints and from the sprint backlog.
            - Work includes non code research on new items which we can represent as spikes
            - Emergencies happen. When they do, size the issue and add it to the work in process for this sprint.
            </body>
            <bodyText>We should understand how much time people are actually spending on board tasks.  Ask at the end of the daily to see if anyone is working something off the board.
            Def of done:
            
            Work items need to be worked during sprints and from the sprint backlog.
            Work includes non code research on new items which we can represent as spikes
            Emergencies happen. When they do, size the issue and add it to the work in process for this sprint.</bodyText>
            <closed>True</closed>
            <closedAt>2022-12-08T15:30:53Z</closedAt>
            <labels>
              <nodes>
                <name>Sprint Retrospective</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9203</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Retrospective: All dev work gets represented on the board.</title>
            <url>https://github.com/IQSS/dataverse/issues/9203</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Sprint Retrospective</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Retrospective: All dev work gets represented on the board.</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 1, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDr8_I</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-12T18:57:01Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>7940</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9187</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>7940 stop harvest in progress</title>
            <url>https://github.com/IQSS/dataverse/pull/9187</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>7940 stop harvest in progress</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 1, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDtA3k</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>landreev</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>A followup issue for #8372 (PR #8753).
            The existing restassured tests are fairly primitive. We need tests covering all the OAI functionality we provide. </body>
            <bodyText>A followup issue for #8372 (PR #8753).
            The existing restassured tests are fairly primitive. We need tests covering all the OAI functionality we provide.</bodyText>
            <closed>True</closed>
            <closedAt>2022-12-15T18:45:07Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: Harvesting</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.4.1</name>
              </nodes>
              <nodes>
                <name>Testing: API</name>
              </nodes>
              <nodes>
                <name>Size: 80</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.2</name>
              </nodes>
              <totalCount>6</totalCount>
            </labels>
            <number>8843</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Expand the suite of automated tests of the Harvesting functionality</title>
            <url>https://github.com/IQSS/dataverse/issues/8843</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Harvesting</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.4.1</name>
                </nodes>
                <nodes>
                  <name>Testing: API</name>
                </nodes>
                <nodes>
                  <name>Size: 80</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.2</name>
                </nodes>
                <totalCount>6</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Expand the suite of automated tests of the Harvesting functionality</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 1, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPAxw</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>NTA</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>NDE</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>Retrospective outcome: make the sprint board so that everything moves left to right.
            
            The reason is that it's confusing seeing PRs that are new and those made by the team in the "this sprint column".
            
            Def of done:
            - [ ] Add a "ready for review" column
            - [ ] Define a process for moving PRs, that are generated by the team via an issue during the sprint, into the "ready for review" column
            - [ ] Define a process for moving PRs, that are joining the sprint from the "ordered backlog" at sprint kickoff, into the "This Sprint" column.
            - [ ] Answer the question - will automation work in this scenario?
            
            </body>
            <bodyText>Retrospective outcome: make the sprint board so that everything moves left to right.
            The reason is that it's confusing seeing PRs that are new and those made by the team in the "this sprint column".
            Def of done:
            
             Add a "ready for review" column
             Define a process for moving PRs, that are generated by the team via an issue during the sprint, into the "ready for review" column
             Define a process for moving PRs, that are joining the sprint from the "ordered backlog" at sprint kickoff, into the "This Sprint" column.
             Answer the question - will automation work in this scenario?</bodyText>
            <closed>True</closed>
            <closedAt>2022-12-08T15:15:18Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>Sprint Retrospective</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9202</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Retrospective: make the sprint board so that everything moves left to right.</title>
            <url>https://github.com/IQSS/dataverse/issues/9202</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>Sprint Retrospective</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Retrospective: make the sprint board so that everything moves left to right.</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 1, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDr8GU</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-05T20:51:48Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>6656</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>8983</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>feat(upload): make upload file storage path configurable #6656</title>
            <url>https://github.com/IQSS/dataverse/pull/8983</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>2</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>feat(upload): make upload file storage path configurable #6656</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 1, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDYaFc</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-08T11:46:01Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8944</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>9091</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Extend 'metadatablocks/{block_id}' endpoint JSON output</title>
            <url>https://github.com/IQSS/dataverse/pull/9091</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>2</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Extend 'metadatablocks/{block_id}' endpoint JSON output</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 1, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTcQ</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>sekmiller</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>The _metadataFormat_ chunk for prefix _dataverse_json_ looks like:
            ```
            &lt;metadataFormat&gt;
               &lt;metadataPrefix&gt;dataverse_json&lt;/metadataPrefix&gt;
               &lt;schema&gt;JSON schema pending&lt;/schema&gt;
               &lt;metadataNamespace&gt;Custom Dataverse metadata in JSON format (Dataverse4 to Dataverse4 harvesting only)&lt;/metadataNamespace&gt;
            &lt;/metadataFormat&gt;
            ```
            The value for  _metadataNamespace_ should be a URI and the value for _schema_ should be a URL, but any URI will validate. In the short term, it might be reasonable to make up values in the http://dataverse.org namespace, so that the responses comply with the [OAI-PMH 2.0 schema](http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd).</body>
            <bodyText>The metadataFormat chunk for prefix dataverse_json looks like:
            &lt;metadataFormat&gt;
               &lt;metadataPrefix&gt;dataverse_json&lt;/metadataPrefix&gt;
               &lt;schema&gt;JSON schema pending&lt;/schema&gt;
               &lt;metadataNamespace&gt;Custom Dataverse metadata in JSON format (Dataverse4 to Dataverse4 harvesting only)&lt;/metadataNamespace&gt;
            &lt;/metadataFormat&gt;
            
            The value for  metadataNamespace should be a URI and the value for schema should be a URL, but any URI will validate. In the short term, it might be reasonable to make up values in the http://dataverse.org namespace, so that the responses comply with the OAI-PMH 2.0 schema.</bodyText>
            <closed>True</closed>
            <closedAt>2022-12-07T21:42:11Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: Harvesting</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.4.1</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.2</name>
              </nodes>
              <totalCount>6</totalCount>
            </labels>
            <number>3621</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>invalid schema and metadataNamespace fields in OAI-PMH ListMetadataFormats response</title>
            <url>https://github.com/IQSS/dataverse/issues/3621</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Harvesting</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.4.1</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.2</name>
                </nodes>
                <totalCount>6</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>invalid schema and metadataNamespace fields in OAI-PMH ListMetadataFormats response</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 1, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPA0M</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>rtreacy</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>
            While ingesting a simple test stata file, I'm seeing several log entries related to netcdf. This adds noise to the log and seems unnecessary.
            
            [ingest_50by1000_dta.txt](https://github.com/IQSS/dataverse/files/10960450/ingest_50by1000_dta.txt)
            </body>
            <bodyText>While ingesting a simple test stata file, I'm seeing several log entries related to netcdf. This adds noise to the log and seems unnecessary.
            ingest_50by1000_dta.txt</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Hackathon: Low Hanging Fruit</name>
              </nodes>
              <nodes>
                <name>Mentor: pdurbin</name>
              </nodes>
              <nodes>
                <name>pm.netcdf-hdf5.d</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <nodes>
                <name>good first issue</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>9441</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>File ingest: Some extra Netcdf logging was left in place, making ingest noisy, especially of non netcdf files.</title>
            <url>https://github.com/IQSS/dataverse/issues/9441</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Hackathon: Low Hanging Fruit</name>
                </nodes>
                <nodes>
                  <name>Mentor: pdurbin</name>
                </nodes>
                <nodes>
                  <name>pm.netcdf-hdf5.d</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <nodes>
                  <name>good first issue</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>File ingest: Some extra Netcdf logging was left in place, making ingest noisy, especially of non netcdf files.</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Dataverse Team (Gustavo)</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFb_iY</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9444</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Installation Guide</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>Containers &amp; Cloud</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <nodes>
                <name>D: DataverseInDocker</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>9447</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>9444 push images</title>
            <url>https://github.com/IQSS/dataverse/pull/9447</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Installation Guide</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>Containers &amp; Cloud</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <nodes>
                  <name>D: DataverseInDocker</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>9444 push images</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Dataverse Team (Gustavo)</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFfsTw</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>landreev</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>Several issues have been opened for adding mechanisms for storage quotas. There is some overlap between them, but different kinds of quotas have been requested - per-user, per-dataset, per-collection, per-user-per-day. Some appear to be more urgent than the others. (case in point, the most recent one, #8549, opened by me, is a specific request from our curation team that we wanted to address soon). 
            - #8549 
            - #7829
            - #4339 
            - #3939
            
            (there may be a couple more that are complete duplicates of something requested by one or more of the issues above, those are omitted).  
            
            Each one of these issues does require the actual quota check to be present somewhere in the workflow of uploading and creating a file. So this new issue is just for adding that mechanism. Perhaps it can be tested against a single setting that defines the limit for ALL uploads, but once it's there it should be extendable to add more types of quota checks to satisfy the specific cases and scenarios requested in the issues above. It should be programmatically configurable, and it should be enforced everywhere where the application allows a creation of a new file - via the GUI, the API and in the direct upload workflow. 
            
            It can be as simple as slightly modifying the individual file size check that's already there; but it should probably be made more programmatic, etc. </body>
            <bodyText>Several issues have been opened for adding mechanisms for storage quotas. There is some overlap between them, but different kinds of quotas have been requested - per-user, per-dataset, per-collection, per-user-per-day. Some appear to be more urgent than the others. (case in point, the most recent one, #8549, opened by me, is a specific request from our curation team that we wanted to address soon).
            
            #8549
            #7829
            #4339
            #3939
            
            (there may be a couple more that are complete duplicates of something requested by one or more of the issues above, those are omitted).
            Each one of these issues does require the actual quota check to be present somewhere in the workflow of uploading and creating a file. So this new issue is just for adding that mechanism. Perhaps it can be tested against a single setting that defines the limit for ALL uploads, but once it's there it should be extendable to add more types of quota checks to satisfy the specific cases and scenarios requested in the issues above. It should be programmatically configurable, and it should be enforced everywhere where the application allows a creation of a new file - via the GUI, the API and in the direct upload workflow.
            It can be as simple as slightly modifying the individual file size check that's already there; but it should probably be made more programmatic, etc.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 80</name>
              </nodes>
              <nodes>
                <name>D: FixRateLimitingBehaviors</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9361</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Add GENERIC storage quota check to the file upload framework. </title>
            <url>https://github.com/IQSS/dataverse/issues/9361</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 80</name>
                </nodes>
                <nodes>
                  <name>D: FixRateLimitingBehaviors</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add GENERIC storage quota check to the file upload framework. </text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Dataverse Team (Gustavo)</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Dataverse Team (Gustavo)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEqby4</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body></body>
            <bodyText></bodyText>
            <closed>True</closed>
            <closedAt>2023-02-13T17:26:58Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>212</number>
            <repository>
              <name>dataverse.harvard.edu</name>
            </repository>
            <title>shibb group: create a shibb group for Cornell University</title>
            <url>https://github.com/IQSS/dataverse.harvard.edu/issues/212</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNzQwNTY1NTE=</id>
                <name>dataverse.harvard.edu</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>shibb group: create a shibb group for Cornell University</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgExTZE</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8822</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Metadata</name>
              </nodes>
              <nodes>
                <name>Feature: API</name>
              </nodes>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>UI/UX: Design</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>8940</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>8822 incomplete datasets via api</title>
            <url>https://github.com/IQSS/dataverse/pull/8940</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Metadata</name>
                </nodes>
                <nodes>
                  <name>Feature: API</name>
                </nodes>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>UI/UX: Design</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>8822 incomplete datasets via api</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTd4</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>When resetting their password users see "Please, accept the new terms of use before continuing."
            
            However, there is no checkbox:
            
            ![Screen Shot 2023-01-25 at 12 14 04 PM](https://user-images.githubusercontent.com/21006/214633492-5315e9ab-93a4-473e-9902-7e9a47bf0619.png)
            
            Tested on the Payara server. Not sure if it's an issue in 5.12.1 or develop.</body>
            <bodyText>When resetting their password users see "Please, accept the new terms of use before continuing."
            However, there is no checkbox:
            
            Tested on the Payara server. Not sure if it's an issue in 5.12.1 or develop.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Type: Bug</name>
              </nodes>
              <nodes>
                <name>Feature: Account &amp; User Info</name>
              </nodes>
              <nodes>
                <name>D: Payara 6 Upgrade</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>9326</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Payara 6: during password reset, users asked to accept term but there is no checkbox</title>
            <url>https://github.com/IQSS/dataverse/issues/9326</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Type: Bug</name>
                </nodes>
                <nodes>
                  <name>Feature: Account &amp; User Info</name>
                </nodes>
                <nodes>
                  <name>D: Payara 6 Upgrade</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Payara 6: during password reset, users asked to accept term but there is no checkbox</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEgjkU</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>NjA</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>NTE</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-02-09T19:29:58Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9365</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Metadata</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9367</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Text corrections #9365</title>
            <url>https://github.com/IQSS/dataverse/pull/9367</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Metadata</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Text corrections #9365</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgErtco</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>Hi Dataverse Team,
            
            I just wanted to share with you something that affects datasets with high number of versions or files. 
            
             There have been some previously related issues that were already solved/closed. However, I strongly believe that the problem may still happen. I will backup the issue with some interesting data.
            
            The below problem is happening when retrieving `dataset versions information` through the native API, hitting the endpoint: `http://demo.dataverse.org/api/datasets/&lt;dataset-version&gt;/versions`
            
            **Given** that I am a user with large many files and versions in a dataset
            **When** I retrieve all the dataset versions
            **Then** I would like to receive a fairly "fast" response
            **So** the user experience is smooth
            
            # Current behavior
            When the dataset has a large number of files, and also a large number of versions, the response time increments dramatically. This can be seen in the below table
            
            | dataset id  | # of versions  | # of files | response size (MB) | response time  | # lines in response  |
            |:---:|:---:|:---:|:---:|:---:|:---:|
            | 767863 | 4 | 1349 | 2.92 | 11.42s | 120k |
            | 396086 | 82 | 36 | 1.66 | 10.83s | 80k |
            | 774618 | 14 | 69 | 0.51 | 3.57s | 23k |
            | 770972 | 2 | 60 | 0.08 | 1.14s | 3.3k |
            
            One of our concerns here is the fact that the dataset with id `767863` already takes a long time only having 4 versions, which means that once it reaches for instance 10 versions, it may be easily taking more than 20 seconds to respond, and could potentially cause a timeout in Dataverse.
            
            Additionally, Dataverse currently returns as part of the response to all the files and their metadata for each of the versions available. That causes a very large response payload that may be unnecessary.
            
            **Note:** The number of files also seem to affect the speed at which a version is published
            
            # Expected behavior
            To have the ability to retrieve **dataset versions information** in an efficient way that does not impact massively the response time.
            
            # Possible solution
            - To return basic metadata about each of the dataset versions available without file information that could potentially be the real problem.
            
            - To review whether there are possible parallelization improvements
            
            It is likely that the user will not necessarily need all the information for each of the datasets, normally, they would click on the version they are interested in, where we could actually perform another request such as `http://demo.dataverse.org/api/datasets/&lt;dataset-id&gt;/versions/&lt;version&gt;`
            
            Thanks a lot!
            
            </body>
            <bodyText>Hi Dataverse Team,
            I just wanted to share with you something that affects datasets with high number of versions or files.
            There have been some previously related issues that were already solved/closed. However, I strongly believe that the problem may still happen. I will backup the issue with some interesting data.
            The below problem is happening when retrieving dataset versions information through the native API, hitting the endpoint: http://demo.dataverse.org/api/datasets/&lt;dataset-version&gt;/versions
            Given that I am a user with large many files and versions in a dataset
            When I retrieve all the dataset versions
            Then I would like to receive a fairly "fast" response
            So the user experience is smooth
            Current behavior
            When the dataset has a large number of files, and also a large number of versions, the response time increments dramatically. This can be seen in the below table
            
            
            
            dataset id
            # of versions
            # of files
            response size (MB)
            response time
            # lines in response
            
            
            
            
            767863
            4
            1349
            2.92
            11.42s
            120k
            
            
            396086
            82
            36
            1.66
            10.83s
            80k
            
            
            774618
            14
            69
            0.51
            3.57s
            23k
            
            
            770972
            2
            60
            0.08
            1.14s
            3.3k
            
            
            
            One of our concerns here is the fact that the dataset with id 767863 already takes a long time only having 4 versions, which means that once it reaches for instance 10 versions, it may be easily taking more than 20 seconds to respond, and could potentially cause a timeout in Dataverse.
            Additionally, Dataverse currently returns as part of the response to all the files and their metadata for each of the versions available. That causes a very large response payload that may be unnecessary.
            Note: The number of files also seem to affect the speed at which a version is published
            Expected behavior
            To have the ability to retrieve dataset versions information in an efficient way that does not impact massively the response time.
            Possible solution
            
            
            To return basic metadata about each of the dataset versions available without file information that could potentially be the real problem.
            
            
            To review whether there are possible parallelization improvements
            
            
            It is likely that the user will not necessarily need all the information for each of the datasets, normally, they would click on the version they are interested in, where we could actually perform another request such as http://demo.dataverse.org/api/datasets/&lt;dataset-id&gt;/versions/&lt;version&gt;
            Thanks a lot!</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Feature: Performance &amp; Stability</name>
              </nodes>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>D: Dataset: large number of files</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>27</number>
            <repository>
              <name>dataverse-pm</name>
            </repository>
            <title>Performance: Slow response for the versions API call with large number of files or versions</title>
            <url>https://github.com/IQSS/dataverse-pm/issues/27</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOIwMRzQ</id>
                <name>dataverse-pm</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Performance &amp; Stability</name>
                </nodes>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>D: Dataset: large number of files</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Performance: Slow response for the versions API call with large number of files or versions</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgE3DYc</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-04-05T19:53:53Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9205</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9206</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/9205-Add role-based provider for S3</title>
            <url>https://github.com/IQSS/dataverse/pull/9206</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.14</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/9205-Add role-based provider for S3</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEvt4I</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>sekmiller</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>Permissions: Grant access errors for large # of files
            
            There was a data request sitting in permissions for Murray dataverse. I selected "accept" and it gave access to 308 file, which is the correct number of "Restricted" files, but the request came in for 315 files (7 files are not restricted). I clicked "Accept" again, and 168 files remained. I clicked "Accept" again and 8 files remained in the que. I clicked "Accept" again and nothing happened after the blue spinning, 8 files still remained in the que (the 8 not restricted for access)
            
            I left the page, went back into permissions-files to add the user manually. I expected when I added her username, to only see "8" files show up in the list of files to give access to. Instead, all 315 files show up. Basically the system doesn't recognize a username already assigned to "files?" The files are also not in any type of order in this files permissions page.
            
            When I added her to all 315 files again, I received 315 error messages as shown in the images below.
            
            Removing her access seems to work in the same manner. It removed access in "chunks" and the updated page reflects smaller and smaller number of files as you keep choosing to "remove" access
            
            &lt;img width="1300" alt="screen shot 2015-10-14 at 11 21 42 am" src="https://cloud.githubusercontent.com/assets/8322346/10488488/e60a1a08-7266-11e5-9955-878891822216.png"&gt;
            
            &lt;img width="1349" alt="screen shot 2015-10-14 at 11 23 19 am" src="https://cloud.githubusercontent.com/assets/8322346/10488490/e826852e-7266-11e5-814a-a6f5adce61d8.png"&gt;
            </body>
            <bodyText>Permissions: Grant access errors for large # of files
            There was a data request sitting in permissions for Murray dataverse. I selected "accept" and it gave access to 308 file, which is the correct number of "Restricted" files, but the request came in for 315 files (7 files are not restricted). I clicked "Accept" again, and 168 files remained. I clicked "Accept" again and 8 files remained in the que. I clicked "Accept" again and nothing happened after the blue spinning, 8 files still remained in the que (the 8 not restricted for access)
            I left the page, went back into permissions-files to add the user manually. I expected when I added her username, to only see "8" files show up in the list of files to give access to. Instead, all 315 files show up. Basically the system doesn't recognize a username already assigned to "files?" The files are also not in any type of order in this files permissions page.
            When I added her to all 315 files again, I received 315 error messages as shown in the images below.
            Removing her access seems to work in the same manner. It removed access in "chunks" and the updated page reflects smaller and smaller number of files as you keep choosing to "remove" access</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Status: UX &amp; UI</name>
              </nodes>
              <nodes>
                <name>Feature: File Upload &amp; Handling</name>
              </nodes>
              <nodes>
                <name>Type: Bug</name>
              </nodes>
              <nodes>
                <name>Feature: Permissions</name>
              </nodes>
              <nodes>
                <name>User Role: Curator</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <nodes>
                <name>D: Dataset: large number of files</name>
              </nodes>
              <totalCount>7</totalCount>
            </labels>
            <number>2641</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>spike: reproduce - Permissions: Grant access errors for large # of files</title>
            <url>https://github.com/IQSS/dataverse/issues/2641</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Status: UX &amp; UI</name>
                </nodes>
                <nodes>
                  <name>Feature: File Upload &amp; Handling</name>
                </nodes>
                <nodes>
                  <name>Type: Bug</name>
                </nodes>
                <nodes>
                  <name>Feature: Permissions</name>
                </nodes>
                <nodes>
                  <name>User Role: Curator</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <nodes>
                  <name>D: Dataset: large number of files</name>
                </nodes>
                <totalCount>7</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>spike: reproduce - Permissions: Grant access errors for large # of files</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgE3DcU</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>7129</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9012</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>rename role.editor to role.contributor</title>
            <url>https://github.com/IQSS/dataverse/pull/9012</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>rename role.editor to role.contributor</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTdE</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>The proposed idea is to modify the command engine as to make it possible to keep accurate counts of executed commands per specific time intervals. We would want to count the totals for all commands, as well as specific commands (and, possibly, classes of commands?) as well as the counts and rates for individual users. 
             
            Note that this can be achieved without adding any new data structures (the values can be obtained by counting the entries in the ActionLogRecord table). However, that table is quite unwieldy on any busy installation, so we almost certainly want to add some efficient way of caching and updating the counts in the database. 
            
            Then we want to add a system of configurable rate limits for specific commands, in a way that would allow setting different limits for different users/groups of users, etc. 
            In addition to limits by the number of executed commands - for example, "certain number of  UpdateDatasetVersionCommand per minute allowed for an otherwise unprivileged logged-in user" - Action Log records how much time it took to execute each command as well. So we may want to consider limiting use by that measure too (?). For example, if a specific user keeps making edits, but for whatever reason the UpdateDatasetVersionCommand on their dataset is especially cpu- and time-consuming - maybe that could trigger some red flags too. 
            
            A simplest use of this functionality would be to set a rate limit on, say, Get*Version commands for the anonymous (guest) users, and that would address a somewhat common case of a scripted crawler plowing through our holdings; past a certain call in too short a period of time the API starts giving them "too busy, try again later". 
            
            More care will need to be taken to make our pages communicate this "try again later" message to the UI users. We don't want anyone to lose a page-worth of edited metadata they are trying to save, etc. </body>
            <bodyText>The proposed idea is to modify the command engine as to make it possible to keep accurate counts of executed commands per specific time intervals. We would want to count the totals for all commands, as well as specific commands (and, possibly, classes of commands?) as well as the counts and rates for individual users.
            Note that this can be achieved without adding any new data structures (the values can be obtained by counting the entries in the ActionLogRecord table). However, that table is quite unwieldy on any busy installation, so we almost certainly want to add some efficient way of caching and updating the counts in the database.
            Then we want to add a system of configurable rate limits for specific commands, in a way that would allow setting different limits for different users/groups of users, etc.
            In addition to limits by the number of executed commands - for example, "certain number of  UpdateDatasetVersionCommand per minute allowed for an otherwise unprivileged logged-in user" - Action Log records how much time it took to execute each command as well. So we may want to consider limiting use by that measure too (?). For example, if a specific user keeps making edits, but for whatever reason the UpdateDatasetVersionCommand on their dataset is especially cpu- and time-consuming - maybe that could trigger some red flags too.
            A simplest use of this functionality would be to set a rate limit on, say, Get*Version commands for the anonymous (guest) users, and that would address a somewhat common case of a scripted crawler plowing through our holdings; past a certain call in too short a period of time the API starts giving them "too busy, try again later".
            More care will need to be taken to make our pages communicate this "try again later" message to the UI users. We don't want anyone to lose a page-worth of edited metadata they are trying to save, etc.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 80</name>
              </nodes>
              <nodes>
                <name>D: FixRateLimitingBehaviors</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9356</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Add execution rate metering to the command engine</title>
            <url>https://github.com/IQSS/dataverse/issues/9356</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 80</name>
                </nodes>
                <nodes>
                  <name>D: FixRateLimitingBehaviors</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add execution rate metering to the command engine</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEqbxk</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>This issue is to finish the investigation started in #8097. 
            Will copy-and-paste relevant experimental data/discussion from the corresponding PR #8152. 
            
            The short version of it is that it takes about 6 minutes to directly index a prod. dataset with 25K files ("directly" = via `/api/admin/index/dataset`), but the time goes up to 6 hours for the same dataset during an async. reindex (via `/api/admin/index` or `/api/admin/index/continue`). The difference between the 2 scenarios appears to have to do with where the dataset entity is instantiated in relation to the main transaction. (this is all explained in more details in the comments from #8152 below). This must have some rational explanation, related to how the transaction context is managed by the EJB. There's a good chance the same issue is affecting the performance elsewhere in the code when we have to modify datasets with similar numbers of files. </body>
            <bodyText>This issue is to finish the investigation started in #8097.
            Will copy-and-paste relevant experimental data/discussion from the corresponding PR #8152.
            The short version of it is that it takes about 6 minutes to directly index a prod. dataset with 25K files ("directly" = via /api/admin/index/dataset), but the time goes up to 6 hours for the same dataset during an async. reindex (via /api/admin/index or /api/admin/index/continue). The difference between the 2 scenarios appears to have to do with where the dataset entity is instantiated in relation to the main transaction. (this is all explained in more details in the comments from #8152 below). This must have some rational explanation, related to how the transaction context is managed by the EJB. There's a good chance the same issue is affecting the performance elsewhere in the code when we have to modify datasets with similar numbers of files.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>D: Dataset: large number of files</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>8256</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Investigate performance degradation in reindex of datasets with large numbers of files</title>
            <url>https://github.com/IQSS/dataverse/issues/8256</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>D: Dataset: large number of files</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Investigate performance degradation in reindex of datasets with large numbers of files</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgE3DW8</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>rtreacy</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body></body>
            <bodyText></bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <nodes>
                <name>D: SonarQubeCleanup</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9312</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>In FileUtil.java use try-with-resources for in = new FileInputStream(inputFile).getChannel(); and out = new FileOutputStream(outputFile).getChannel(); in method copyFile(...) and out = new FileOutputStream(outputFile).getChannel(); in method determineFileType(...) and FileReader fileReader = new FileReader(file); in isGraphMLFile(...)</title>
            <url>https://github.com/IQSS/dataverse/issues/9312</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <nodes>
                  <name>D: SonarQubeCleanup</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>In FileUtil.java use try-with-resources for in = new FileInputStream(inputFile).getChannel(); and out = new FileOutputStream(outputFile).getChannel(); in method copyFile(...) and out = new FileOutputStream(outputFile).getChannel(); in method determineFileType(...) and FileReader fileReader = new FileReader(file); in isGraphMLFile(...)</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEdbng</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-03-24T20:19:27Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: User Guide</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9306</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>9277 - correcting the sphinx documentation pdf build</title>
            <url>https://github.com/IQSS/dataverse/pull/9306</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: User Guide</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>9277 - correcting the sphinx documentation pdf build</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEuT1s</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-02-09T22:09:55Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: File Upload &amp; Handling</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9366</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Add initial support for .eln file format</title>
            <url>https://github.com/IQSS/dataverse/pull/9366</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: File Upload &amp; Handling</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add initial support for .eln file format</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEr1q4</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <pageInfo>
          <endCursor>NzA</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>NjE</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-03-28T23:26:49Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9063</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: API</name>
              </nodes>
              <nodes>
                <name>User Role: API User</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.7.1 (reArchitecture)</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>9290</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>9063 - add session API auth mechanism with feature flag</title>
            <url>https://github.com/IQSS/dataverse/pull/9290</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: API</name>
                </nodes>
                <nodes>
                  <name>User Role: API User</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.7.1 (reArchitecture)</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>9063 - add session API auth mechanism with feature flag</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEWUw8</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>**What steps does it take to reproduce the issue?**
            
            I found that the API and the web UI is not working similarly. I tested it in Dataverse v5.11.1. Here is a summary:
            
            If I create new role ("reviewer") for the root dataverse, it is displayed only in the root's roles list. It is not displayed other dataverse' role list, and I can not create another role with the same machine name elsewhere.
            
            Displaying a newly created role in the list of roles:
            
            web:
            - root dataverse: it is shown
            - elsewhere: it is not shown
            
            API:
            - root dataverse: it is shown
            - elsewhere: it is not shown
            
            Assign role to user/group:
            
            web:
            - root dataverse: possible
            - elsewhere: I can not assign the same rule in another dataverse, because it is not displayed among the selectable roles
            API:
            - root dataverse: possible
            - elsewhere: possible
            
            Checking the list of Users/Groups (assignments).
            
            web:
            - root dataverse: the assignment is shown in the list
            - elsewhere: it doesn't.
            API:
            - root dataverse: the assignment is shown in the list
            - elsewhere: the assignment is shown in the list
            
            I haven't found an explanation in the Dataverse guide.
            
            - Do you know if this inconvenience is by design? or it is rather a bug?
            - What would be your expectation regarding to newly created roles (those which is not packed in a freshly installed Dataverse)? Mine would be that if I create a new role in the root, it is visible and usable elsewhere in both the web UI and API, but maybe you have different opinion.
            
            
            * When does this issue occur?
            see above
            
            * Which page(s) does it occurs on?
            the Permission page
            
            * What happens?
            see above
            
            * To whom does it occur (all users, curators, superusers)?
            superusers, dataverse admins
            
            * What did you expect to happen?
            see above
            
            
            **Which version of Dataverse are you using?**
            v5.11.1
            
            **Any related open or closed issues to this bug report?**
            I am not aware of.
            
            **Screenshots:**
            
            No matter the issue, screenshots are always welcome.
            
            To add a screenshot, please use one of the following formats and/or methods described here:
            
            * https://help.github.com/en/articles/file-attachments-on-issues-and-pull-requests
            *
            </body>
            <bodyText>What steps does it take to reproduce the issue?
            I found that the API and the web UI is not working similarly. I tested it in Dataverse v5.11.1. Here is a summary:
            If I create new role ("reviewer") for the root dataverse, it is displayed only in the root's roles list. It is not displayed other dataverse' role list, and I can not create another role with the same machine name elsewhere.
            Displaying a newly created role in the list of roles:
            web:
            
            root dataverse: it is shown
            elsewhere: it is not shown
            
            API:
            
            root dataverse: it is shown
            elsewhere: it is not shown
            
            Assign role to user/group:
            web:
            
            root dataverse: possible
            elsewhere: I can not assign the same rule in another dataverse, because it is not displayed among the selectable roles
            API:
            root dataverse: possible
            elsewhere: possible
            
            Checking the list of Users/Groups (assignments).
            web:
            
            root dataverse: the assignment is shown in the list
            elsewhere: it doesn't.
            API:
            root dataverse: the assignment is shown in the list
            elsewhere: the assignment is shown in the list
            
            I haven't found an explanation in the Dataverse guide.
            
            Do you know if this inconvenience is by design? or it is rather a bug?
            What would be your expectation regarding to newly created roles (those which is not packed in a freshly installed Dataverse)? Mine would be that if I create a new role in the root, it is visible and usable elsewhere in both the web UI and API, but maybe you have different opinion.
            
            
            
            When does this issue occur?
            see above
            
            
            Which page(s) does it occurs on?
            the Permission page
            
            
            What happens?
            see above
            
            
            To whom does it occur (all users, curators, superusers)?
            superusers, dataverse admins
            
            
            What did you expect to happen?
            see above
            
            
            Which version of Dataverse are you using?
            v5.11.1
            Any related open or closed issues to this bug report?
            I am not aware of.
            Screenshots:
            No matter the issue, screenshots are always welcome.
            To add a screenshot, please use one of the following formats and/or methods described here:
            
            https://help.github.com/en/articles/file-attachments-on-issues-and-pull-requests</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9338</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Inconsistent behavior relating to Roles</title>
            <url>https://github.com/IQSS/dataverse/issues/9338</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Inconsistent behavior relating to Roles</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEjAlM</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>donsizemore</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>Small chunk from the big Payara 6 issue:
            
            - #8305
            
            We have https://jenkins.dataverse.org/job/IQSS-Dataverse-Payara6/ set up already so I think we can use it as a starting point.
            
            I'll defer to @donsizemore for a size estimate.</body>
            <bodyText>Small chunk from the big Payara 6 issue:
            
            #8305
            
            We have https://jenkins.dataverse.org/job/IQSS-Dataverse-Payara6/ set up already so I think we can use it as a starting point.
            I'll defer to @donsizemore for a size estimate.</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-20T18:16:25Z</closedAt>
            <labels>
              <nodes>
                <name>D: Payara 6 Upgrade</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9329</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Payara 6: ensure API tests are executing</title>
            <url>https://github.com/IQSS/dataverse/issues/9329</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>D: Payara 6 Upgrade</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Payara 6: ensure API tests are executing</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEh3ys</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>On the Payara 6 server I came upon an existing dataset in the root and tried to publish it. It failed in a strange way.
            
            ![Screen Shot 2023-01-25 at 11 50 06 AM](https://user-images.githubusercontent.com/21006/214626726-5f3bb446-b67f-44e1-9063-a6f248302c59.png)
            ![Screen Shot 2023-01-25 at 11 50 13 AM](https://user-images.githubusercontent.com/21006/214626722-dcbfc8c5-f8cc-4b63-9ecb-af254915f687.png)
            ![Screen Shot 2023-01-25 at 11 50 18 AM](https://user-images.githubusercontent.com/21006/214626727-f7f522b8-b5aa-4d6e-b38d-84b11a572dd0.png)
            ![Screen Shot 2023-01-25 at 11 50 59 AM](https://user-images.githubusercontent.com/21006/214626729-76e38024-1a77-4a14-9608-cc362bac6559.png)
            
            (here I clicked refresh)
            
            ![Screen Shot 2023-01-25 at 11 51 31 AM](https://user-images.githubusercontent.com/21006/214626737-574ae3b6-21ec-474d-a941-a972717ea2d2.png)
            </body>
            <bodyText>On the Payara 6 server I came upon an existing dataset in the root and tried to publish it. It failed in a strange way.
            
            
            
            
            (here I clicked refresh)</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>D: Payara 6 Upgrade</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9323</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Payara 6: Can't publish some datasets</title>
            <url>https://github.com/IQSS/dataverse/issues/9323</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>D: Payara 6 Upgrade</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Payara 6: Can't publish some datasets</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEgjmE</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-03-20T20:37:53Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9297</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Code Infrastructure</name>
              </nodes>
              <nodes>
                <name>Feature: Developer Guide</name>
              </nodes>
              <nodes>
                <name>Feature: Installation Guide</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>Testing: API</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>6</totalCount>
            </labels>
            <number>9299</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>9297 feature flags</title>
            <url>https://github.com/IQSS/dataverse/pull/9299</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Code Infrastructure</name>
                </nodes>
                <nodes>
                  <name>Feature: Developer Guide</name>
                </nodes>
                <nodes>
                  <name>Feature: Installation Guide</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>Testing: API</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>6</totalCount>
              </labels>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>1</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>9297 feature flags</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEYXVI</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>When creating and editing dataset templates in other collections with custom metadatablocks, the custom blocks are always at the bottom.
            
            But when creating and editing dataset templates in [the NDR collection](https://dataverse.harvard.edu/dataverse/NegotiationDataRepository), the customNDR metadatablock appears at the top, above the Citation block:
            
            &lt;kbd&gt;&lt;img width="1156" alt="Screen Shot 2022-08-01 at 12 18 51 PM" src="https://user-images.githubusercontent.com/18374574/182201524-9ea803bc-5307-4eb3-831c-b94e6e49c34d.png"&gt;&lt;/kbd&gt;
            
            Can we fix the order of the metadatablocks when creating and editing dataset templates so that the custom block is at the bottom?
            
            (When creating and editing dataset metadata, the Citation block is at the top. This was fixed in https://github.com/IQSS/dataverse.harvard.edu/issues/165)</body>
            <bodyText>When creating and editing dataset templates in other collections with custom metadatablocks, the custom blocks are always at the bottom.
            But when creating and editing dataset templates in the NDR collection, the customNDR metadatablock appears at the top, above the Citation block:
            
            Can we fix the order of the metadatablocks when creating and editing dataset templates so that the custom block is at the bottom?
            (When creating and editing dataset metadata, the Citation block is at the top. This was fixed in IQSS/dataverse.harvard.edu#165)</bodyText>
            <closed>True</closed>
            <closedAt>2023-02-09T22:27:54Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9376</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Fix order of metadatablocks when creating and editing dataset templates in NDR collection</title>
            <url>https://github.com/IQSS/dataverse/issues/9376</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Fix order of metadatablocks when creating and editing dataset templates in NDR collection</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgD1buo</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>jggautier</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>As far as I know this shouldn't happen. Datasets created in Dataverse collections can't be published if the collection is not published and published datasets can't be moved into unpublished collections.
            
            The three listed below are accessible without logging into the repository. Clicking on the Dataverse collection links at the top of the pages takes me to the repository login page, since the collections are unpublished.
            
            Both non-deaccessioned datasets can be found by searching for their titles. (Searching for deaccessioned datasets doesn't work well, by design.)
            
            https://doi.org/10.7910/DVN/JTPW3N, published in 2016
            https://doi.org/10.7910/DVN/YSK071, published in 2008
            https://doi.org/10.7910/DVN/0MBNAW, published and its only version deaccessioned in 2017 
            
            I think we could probably email the depositors of the first two and make sure they're aware the datasets are publicly accessible. If they are, we can probably just publish the collection, assuming that works.
            
            For the deaccessioned dataset, all of the other datasets in that collection are unpublished, so we can't publish the collection. And I'm not sure if we can delete the deaccessioned dataset due to a repository curation policy where we shouldn't delete deaccessioned datasets whose files have already been downloaded. @sbarbosadataverse, what do you think?
            
            &lt;details&gt;
              &lt;summary&gt;Here's the query I used to find them:&lt;/summary&gt;
            
            ```
            select
            	dataverse.alias,
            	dvobject_dataset.identifier,
            	dvobject_dataset.createdate, 
            	dvobject_dataset.publicationdate
            from dataset
            join dvobject dvobject_dataset on dvobject_dataset.id = dataset.id
            join dataverse on dataverse.id = dvobject_dataset.owner_id
            join dvobject dvobject_dataverse on dvobject_dataverse.id = dataverse.id
            where
                 -- dataset is published
                 dvobject_dataset.publicationdate is not null and
            
                 -- dataverse collection is not published
                 dvobject_dataverse.publicationdate is null 
            
            order by dataverse.alias, dvobject_dataset.identifier
            ```
            &lt;/details&gt;</body>
            <bodyText>As far as I know this shouldn't happen. Datasets created in Dataverse collections can't be published if the collection is not published and published datasets can't be moved into unpublished collections.
            The three listed below are accessible without logging into the repository. Clicking on the Dataverse collection links at the top of the pages takes me to the repository login page, since the collections are unpublished.
            Both non-deaccessioned datasets can be found by searching for their titles. (Searching for deaccessioned datasets doesn't work well, by design.)
            https://doi.org/10.7910/DVN/JTPW3N, published in 2016
            https://doi.org/10.7910/DVN/YSK071, published in 2008
            https://doi.org/10.7910/DVN/0MBNAW, published and its only version deaccessioned in 2017
            I think we could probably email the depositors of the first two and make sure they're aware the datasets are publicly accessible. If they are, we can probably just publish the collection, assuming that works.
            For the deaccessioned dataset, all of the other datasets in that collection are unpublished, so we can't publish the collection. And I'm not sure if we can delete the deaccessioned dataset due to a repository curation policy where we shouldn't delete deaccessioned datasets whose files have already been downloaded. @sbarbosadataverse, what do you think?
            
              Here's the query I used to find them:
            select
            	dataverse.alias,
            	dvobject_dataset.identifier,
            	dvobject_dataset.createdate, 
            	dvobject_dataset.publicationdate
            from dataset
            join dvobject dvobject_dataset on dvobject_dataset.id = dataset.id
            join dataverse on dataverse.id = dvobject_dataset.owner_id
            join dvobject dvobject_dataverse on dvobject_dataverse.id = dataverse.id
            where
                 -- dataset is published
                 dvobject_dataset.publicationdate is not null and
            
                 -- dataverse collection is not published
                 dvobject_dataverse.publicationdate is null 
            
            order by dataverse.alias, dvobject_dataset.identifier</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-02T20:37:33Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>186</number>
            <repository>
              <name>dataverse.harvard.edu</name>
            </repository>
            <title>In Harvard Dataverse Repository, three published datasets are in unpublished Dataverse collections</title>
            <url>https://github.com/IQSS/dataverse.harvard.edu/issues/186</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNzQwNTY1NTE=</id>
                <name>dataverse.harvard.edu</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>In Harvard Dataverse Repository, three published datasets are in unpublished Dataverse collections</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgD1WOI</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>jggautier</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>These datasets are published but are unable to be edited (through the GUI):
            - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/A3NWA7
            - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VYNLON
            - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/RC0WLY
            - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/28MPKM
            - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/NVMNMP
            - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/LTMCFR
            - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/79CRQJ
            - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DEAZAQ
            - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/XGA4CH
            - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/58YPIG
            - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/APJNDT
            - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/H2JL7A
            - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/AGJPZH
            - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/XPOLYI
            
            More info:
            - Logged in users with permission to edit the dataset see a "Publish in Progress" yellow warning banner:
              &lt;img width="1157" alt="Screen Shot 2022-12-05 at 11 00 17 AM" src="https://user-images.githubusercontent.com/18374574/205683400-8541454d-bc67-4745-92ff-fc7a0e6e8295.png"&gt;
            - The datasets' DOI URLs lead to the datasets
            - The datasets' files are downloadable by anyone ("guest" users)
            - The API endpoint for reporting dataset locks reports that there are finalizePublication locks on these dataset 
            
            @scolapasta and @landreev, I haven't "unlocked" these dataset in case seeing it in this state is helpful for a developer who can take a closer look at what's happening. But please let me know if that's not needed and I can use the endpoint to "unlock" this dataset to try to make it editable again.
            
            Definition of done:
            - These datasets are able to be edited, the "Publish in Progress" yellow warning banners are removed, and the finalizePublication locks are removed</body>
            <bodyText>These datasets are published but are unable to be edited (through the GUI):
            
            https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/A3NWA7
            https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VYNLON
            https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/RC0WLY
            https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/28MPKM
            https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/NVMNMP
            https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/LTMCFR
            https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/79CRQJ
            https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DEAZAQ
            https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/XGA4CH
            https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/58YPIG
            https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/APJNDT
            https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/H2JL7A
            https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/AGJPZH
            https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/XPOLYI
            
            More info:
            
            Logged in users with permission to edit the dataset see a "Publish in Progress" yellow warning banner:
            
            The datasets' DOI URLs lead to the datasets
            The datasets' files are downloadable by anyone ("guest" users)
            The API endpoint for reporting dataset locks reports that there are finalizePublication locks on these dataset
            
            @scolapasta and @landreev, I haven't "unlocked" these dataset in case seeing it in this state is helpful for a developer who can take a closer look at what's happening. But please let me know if that's not needed and I can use the endpoint to "unlock" this dataset to try to make it editable again.
            Definition of done:
            
            These datasets are able to be edited, the "Publish in Progress" yellow warning banners are removed, and the finalizePublication locks are removed</bodyText>
            <closed>True</closed>
            <closedAt>2023-02-09T20:30:31Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>150</number>
            <repository>
              <name>dataverse.harvard.edu</name>
            </repository>
            <title>Some datasets are uneditable, have finalizePublication lock, but DOIs work, "Draft"/"Unpublished" labels are missing</title>
            <url>https://github.com/IQSS/dataverse.harvard.edu/issues/150</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNzQwNTY1NTE=</id>
                <name>dataverse.harvard.edu</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Some datasets are uneditable, have finalizePublication lock, but DOIs work, "Draft"/"Unpublished" labels are missing</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgD1bqg</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-03-24T15:51:25Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>5962</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>8981</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Gdcc/Signposting</title>
            <url>https://github.com/IQSS/dataverse/pull/8981</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.14</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Gdcc/Signposting</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>External Commitments (Jim)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTdk</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>4959</number>
              </nodes>
              <nodes>
                <number>6933</number>
              </nodes>
              <totalCount>2</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>QDR</name>
              </nodes>
              <nodes>
                <name>JHU</name>
              </nodes>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>ASU</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>9204</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/4959-Support-By-Category-and-Folder-Grouping</title>
            <url>https://github.com/IQSS/dataverse/pull/9204</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>QDR</name>
                </nodes>
                <nodes>
                  <name>JHU</name>
                </nodes>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>ASU</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.14</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/4959-Support-By-Category-and-Folder-Grouping</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDsD5w</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <pageInfo>
          <endCursor>ODA</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>NzE</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9100</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>DANS</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9102</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/9100 OpenAire update for orgs</title>
            <url>https://github.com/IQSS/dataverse/pull/9102</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>DANS</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.14</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/9100 OpenAire update for orgs</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNnGc</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>landreev</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>Forwarded from the ticket:
            https://help.hmdc.harvard.edu/Ticket/Display.html?id=245607
            
            -------------------------------------------------------------------------
            Hello,
            I tried to validate two items exported to DDI from dataverse.harvard.edu with codebook.xsd (2.5) and got the same types of validation errors described below for item1 (below the line, should work as a well-formed xml-file):
            
            Item 1:https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/BAMCSI
            
            Item 2: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/P4JTOD 
            
            What could be done about it (else than meddling with the schema?)
            
            Best regards,
            
            Joakim Philipson
            Research Data Analyst, Ph.D., MLIS
            Stockholm University Library
            
            Stockholm University
            SE-106 91 Stockholm
            Sweden
            
            Tel: +46-8-16 29 50
            Mobile: +46-72-1464702
            E-mail: joakim.philipson@sub.su.se
            http://orcid.org/0000-0001-5699-994X
            --------------------------------------------------------------------
            &lt;?xml version="1.0" encoding="UTF-8"?&gt;
            
            &lt;!-- dataverse_1062_philipson error types: --&gt;
            
            &lt;root xmlns="ddi:codebook:2_5" xmlns:xs="http://www.w3.org/2001/XMLSchema-instance" xmlns:xhtml="http://www.w3.org/1999/xhtml"&gt;
                
            &lt;!-- Error type 1: 
            System ID: C:\Users\joph9849\Desktop\Dataverse\dataverse_1062_philipson.xml
            Main validation file: C:\Users\joph9849\Desktop\Dataverse\dataverse_1062_philipson.xml
            Schema: http://www.ddialliance.org/Specification/DDI-Codebook/2.5/XMLSchema/codebook.xsd
            Engine name: Xerces
            Severity: error
            Description: cvc-enumeration-valid: Value 'DVN' is not facet-valid with respect to enumeration '[archive, producer]'. It must be a value from the enumeration.
            Start location: 14:35
            URL: http://www.w3.org/TR/xmlschema-2/#cvc-enumeration-valid: --&gt; 
                
                &lt;docDscr&gt;
                &lt;citation&gt;
                    &lt;titlStmt&gt;
                        &lt;titl&gt;What’s in a name? : Sense and Reference in biodiversity information &lt;/titl&gt;
                        &lt;IDNo agency="DOI"&gt;doi:10.7910/DVN/BAMCSI&lt;/IDNo&gt;
                    &lt;/titlStmt&gt;
                    &lt;distStmt&gt;
                        &lt;distrbtr&gt;Harvard Dataverse&lt;/distrbtr&gt;
                        &lt;distDate&gt;2017-01-12&lt;/distDate&gt;
                    &lt;/distStmt&gt;
                    &lt;verStmt source="DVN"&gt;
                        &lt;version date="2017-01-12" type="RELEASED"&gt;1&lt;/version&gt;
                    &lt;/verStmt&gt;
                    &lt;biblCit&gt;Philipson, Joakim, 2017, "What’s in a name? : Sense and Reference in
                        biodiversity information", doi:10.7910/DVN/BAMCSI, Harvard Dataverse, V1&lt;/biblCit&gt;
                &lt;/citation&gt;
            &lt;/docDscr&gt;
            
            &lt;!-- In codebook.xsd: --&gt;
                    
            &lt;xs:attribute name="source" default="producer"&gt;
                &lt;xs:simpleType&gt;
                    &lt;xs:restriction base="xs:NMTOKEN"&gt;
                        &lt;xs:enumeration value="archive"/&gt;
                        &lt;xs:enumeration value="producer"/&gt;
                    &lt;/xs:restriction&gt;
                &lt;/xs:simpleType&gt;
            &lt;/xs:attribute&gt;
                
                
            &lt;!-- Error type 2:
            System ID: C:\Users\joph9849\Desktop\Dataverse\dataverse_1062_philipson.xml
            Main validation file: C:\Users\joph9849\Desktop\Dataverse\dataverse_1062_philipson.xml
            Schema: http://www.ddialliance.org/Specification/DDI-Codebook/2.5/XMLSchema/codebook.xsd
            Engine name: Xerces
            Severity: error
            Description: cvc-complex-type.3.2.2: Attribute 'URI' is not allowed to appear in element 'keyword'.
            Start location: 40:41
            End location: 40:44
            URL: http://www.w3.org/TR/xmlschema-1/#cvc-complex-type 
                //Comment: In the metadata form i recall clearly that the correponding fieldname was "vocabURI", so why is it erroneously converted to URI here? --&gt;    
                
                &lt;stdyInfo&gt;
                    &lt;subject&gt;
                        &lt;keyword&gt;Medicine, Health and Life Sciences&lt;/keyword&gt;
                        &lt;keyword&gt;Computer and Information Science&lt;/keyword&gt;
                        &lt;keyword vocab="casrai" URI="http://dictionary.casrai.org/Metadata"
                            &gt;Metadata&lt;/keyword&gt;
                        &lt;keyword vocab="casrai" URI="http://dictionary.casrai.org/PID_system"&gt;PID
                            system&lt;/keyword&gt;
                        &lt;keyword vocab="wikipedia" URI="https://en.wikipedia.org/wiki/Biodiversity"
                            &gt;Biodiversity&lt;/keyword&gt;
                        &lt;keyword vocab="smw-rda" URI="http://smw-rda.esc.rzg.mpg.de/index.php/Taxonomy"
                            &gt;Taxonomy&lt;/keyword&gt;
                    &lt;/subject&gt;
                    &lt;abstract&gt;"That which we call a rose by any other name would smell as sweet.”
                        Shakespeare has Juliet tell her Romeo that a name is just a convention without
                        meaning, what counts is the reference, the 'thing itself', to which the property of
                        smelling sweet pertains alone. Frege in his classical paper “Über Sinn und
                        Bedeutung” was not so sure, he assumed names can be inherently meaningful, even
                        without a known reference. And Wittgenstein later in Philosophical Investigations
                        (PI) seems to deny the sheer arbitrariness of names and reject looking for meaning
                        out of context, by pointing to our inability to just utter some random sounds and by
                        that really implying e.g. the door. The word cannot simply be separated from its
                        meaning, in the same way as the money from the cow that could be bought for them (PI
                        120). Scientific names of biota, in particular, are often descriptive of properties
                        pertaining to the organism or species itself. On the other hand, in semantic web
                        technology and Linked Open Data (LOD) there is an overall effort to replace names by
                        their references, in the form of web links or Uniform Resource Identifiers (URIs).
                        “Things, not strings” is the motto. But, even in view of the many "challenges with
                        using names to link digital biodiversity information" that were extensively
                        described in a recent paper, would it at all be possible or even desirable to
                        replace scientific names of biota with URIs? Or would it be sufficient to just
                        identify equivalence relationships between different variants of names of the same
                        biota, having the same reference, and then just link them to the same “thing”, by
                        means of a property sameAs(URI)? The Global Names Architecture (GNA) has a resolver
                        of scientific names that is already doing that kind of work, linking names of biota
                        such as Pinus thunbergii to global identifiers and URIs from other data sources,
                        such as Encyclopedia of Life (EOL) and uBio Namebank. But there may be other
                        challenges with going from a “natural language”, even from a not entirely coherent
                        system of scientific names, to a semantic web ontology, a solution to some of which
                        have been proposed recently by means of so called 'lexical bridges'.&lt;/abstract&gt;
                    &lt;sumDscr/&gt;
                    &lt;contact affiliation="Stockholm University" email="joakim.philipson@sub.su.se"
                        &gt;Philipson, Joakim&lt;/contact&gt;
                    &lt;depositr&gt;Philipson, Joakim&lt;/depositr&gt;
                    &lt;depDate&gt;2017-01-12&lt;/depDate&gt;
                &lt;/stdyInfo&gt;    
            
            &lt;!-- In codebook.xsd:  --&gt;
                
                &lt;xs:complexType name="keywordType" mixed="true"&gt;
                    &lt;xs:complexContent&gt;
                        &lt;xs:extension base="simpleTextType"&gt;
                            &lt;xs:attribute name="vocab" type="xs:string"/&gt;
                            &lt;xs:attribute name="vocabURI" type="xs:string"/&gt;
                        &lt;/xs:extension&gt;
                    &lt;/xs:complexContent&gt;
                &lt;/xs:complexType&gt;
                
            &lt;!-- Error type 3:
                    
            System ID: C:\Users\joph9849\Desktop\Dataverse\dataverse_1062_philipson.xml
            Main validation file: C:\Users\joph9849\Desktop\Dataverse\dataverse_1062_philipson.xml
            Schema: http://www.ddialliance.org/Specification/DDI-Codebook/2.5/XMLSchema/codebook.xsd
            Engine name: Xerces
            Severity: error
            Description: cvc-complex-type.2.4.a: Invalid content was found starting with element '{"ddi:codebook:2_5":contact}'. One of '{"ddi:codebook:2_5":sumDscr, "ddi:codebook:2_5":qualityStatement, "ddi:codebook:2_5":notes, "ddi:codebook:2_5":exPostEvaluation}' is expected.
            Start location: 77:14
            End location: 77:21
            URL: http://www.w3.org/TR/xmlschema-1/#cvc-complex-type --&gt; 
                
                &lt;sumDscr/&gt;
                &lt;contact affiliation="Stockholm University" email="joakim.philipson@sub.su.se"
                    &gt;Philipson, Joakim&lt;/contact&gt;
                
                &lt;!-- In codebook: --&gt;
                
                &lt;xs:complexType name="sumDscrType"&gt;
                    &lt;xs:complexContent&gt;
                        &lt;xs:extension base="baseElementType"&gt;
                            &lt;xs:sequence&gt;
                                &lt;xs:element ref="timePrd" minOccurs="0" maxOccurs="unbounded"/&gt;
                                &lt;xs:element ref="collDate" minOccurs="0" maxOccurs="unbounded"/&gt;
                                &lt;xs:element ref="nation" minOccurs="0" maxOccurs="unbounded"/&gt;
                                &lt;xs:element ref="geogCover" minOccurs="0" maxOccurs="unbounded"/&gt;
                                &lt;xs:element ref="geogUnit" minOccurs="0" maxOccurs="unbounded"/&gt;
                                &lt;xs:element ref="geoBndBox" minOccurs="0"/&gt;
                                &lt;xs:element ref="boundPoly" minOccurs="0" maxOccurs="unbounded"/&gt;
                                &lt;xs:element ref="anlyUnit" minOccurs="0" maxOccurs="unbounded"/&gt;
                                &lt;xs:element ref="universe" minOccurs="0" maxOccurs="unbounded"/&gt;
                                &lt;xs:element ref="dataKind" minOccurs="0" maxOccurs="unbounded"/&gt;
                            &lt;/xs:sequence&gt;
                        &lt;/xs:extension&gt;
                    &lt;/xs:complexContent&gt;
                &lt;/xs:complexType&gt;
                
                &lt;xs:element name="sumDscr" type="sumDscrType"&gt;
                    &lt;xs:annotation&gt;
                        &lt;xs:documentation&gt;
                            &lt;xhtml:div&gt;
                                &lt;xhtml:h1 class="element_title"&gt;Summary Data Description&lt;/xhtml:h1&gt;
                                &lt;xhtml:div&gt;
                                    &lt;xhtml:h2 class="section_header"&gt;Description&lt;/xhtml:h2&gt;
                                    &lt;xhtml:div class="description"&gt;Information about the and geographic coverage of the study and unit of analysis.&lt;/xhtml:div&gt;
                                &lt;/xhtml:div&gt;
                            &lt;/xhtml:div&gt;
                        &lt;/xs:documentation&gt;
                    &lt;/xs:annotation&gt;
                &lt;/xs:element&gt;
                
             &lt;!-- Error type 4 &amp; 5: 
            System ID: C:\Users\joph9849\Desktop\Dataverse\dataverse_1062_philipson.xml
            Main validation file: C:\Users\joph9849\Desktop\Dataverse\dataverse_1062_philipson.xml
            Schema: http://www.ddialliance.org/Specification/DDI-Codebook/2.5/XMLSchema/codebook.xsd
            Engine name: Xerces
            Severity: error
            Description: cvc-complex-type.2.4.a: Invalid content was found starting with element '{"ddi:codebook:2_5":useStmt}'. One of '{"ddi:codebook:2_5":method, "ddi:codebook:2_5":dataAccs, "ddi:codebook:2_5":othrStdyMat, "ddi:codebook:2_5":notes}' is expected.
            Start location: 86:10
            End location: 86:17
            URL: http://www.w3.org/TR/xmlschema-1/#cvc-complex-type
            
            System ID: C:\Users\joph9849\Desktop\Dataverse\dataverse_1062_philipson.xml
            Main validation file: C:\Users\joph9849\Desktop\Dataverse\dataverse_1062_philipson.xml
            Schema: http://www.ddialliance.org/Specification/DDI-Codebook/2.5/XMLSchema/codebook.xsd
            Engine name: Xerces
            Severity: error
            Description: cvc-complex-type.2.3: Element 'useStmt' cannot have character [children], because the type's content type is element-only.
            Start location: 86:18
            End location: 86:28
            URL: http://www.w3.org/TR/xmlschema-1/#cvc-complex-type
            --&gt;
                
                &lt;useStmt&gt;CC0 Waiver&lt;/useStmt&gt;
            &lt;/root&gt;
            
            [dataverse_1062_philipsonErrorTypes.txt](https://github.com/IQSS/dataverse/files/801878/dataverse_1062_philipsonErrorTypes.txt)
            </body>
            <bodyText>Forwarded from the ticket:
            https://help.hmdc.harvard.edu/Ticket/Display.html?id=245607
            
            Hello,
            I tried to validate two items exported to DDI from dataverse.harvard.edu with codebook.xsd (2.5) and got the same types of validation errors described below for item1 (below the line, should work as a well-formed xml-file):
            Item 1:https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/BAMCSI
            Item 2: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/P4JTOD
            What could be done about it (else than meddling with the schema?)
            Best regards,
            Joakim Philipson
            Research Data Analyst, Ph.D., MLIS
            Stockholm University Library
            Stockholm University
            SE-106 91 Stockholm
            Sweden
            Tel: +46-8-16 29 50
            Mobile: +46-72-1464702
            E-mail: joakim.philipson@sub.su.se
            http://orcid.org/0000-0001-5699-994X
            
            
            
             
            &lt;docDscr&gt;
            &lt;citation&gt;
                &lt;titlStmt&gt;
                    &lt;titl&gt;What’s in a name? : Sense and Reference in biodiversity information &lt;/titl&gt;
                    &lt;IDNo agency="DOI"&gt;doi:10.7910/DVN/BAMCSI&lt;/IDNo&gt;
                &lt;/titlStmt&gt;
                &lt;distStmt&gt;
                    &lt;distrbtr&gt;Harvard Dataverse&lt;/distrbtr&gt;
                    &lt;distDate&gt;2017-01-12&lt;/distDate&gt;
                &lt;/distStmt&gt;
                &lt;verStmt source="DVN"&gt;
                    &lt;version date="2017-01-12" type="RELEASED"&gt;1&lt;/version&gt;
                &lt;/verStmt&gt;
                &lt;biblCit&gt;Philipson, Joakim, 2017, "What’s in a name? : Sense and Reference in
                    biodiversity information", doi:10.7910/DVN/BAMCSI, Harvard Dataverse, V1&lt;/biblCit&gt;
            &lt;/citation&gt;
            
            
            
            &lt;xs:attribute name="source" default="producer"&gt;
            xs:simpleType
            &lt;xs:restriction base="xs:NMTOKEN"&gt;
            &lt;xs:enumeration value="archive"/&gt;
            &lt;xs:enumeration value="producer"/&gt;
            &lt;/xs:restriction&gt;
            &lt;/xs:simpleType&gt;
            &lt;/xs:attribute&gt;
                
            &lt;stdyInfo&gt;
                &lt;subject&gt;
                    &lt;keyword&gt;Medicine, Health and Life Sciences&lt;/keyword&gt;
                    &lt;keyword&gt;Computer and Information Science&lt;/keyword&gt;
                    &lt;keyword vocab="casrai" URI="http://dictionary.casrai.org/Metadata"
                        &gt;Metadata&lt;/keyword&gt;
                    &lt;keyword vocab="casrai" URI="http://dictionary.casrai.org/PID_system"&gt;PID
                        system&lt;/keyword&gt;
                    &lt;keyword vocab="wikipedia" URI="https://en.wikipedia.org/wiki/Biodiversity"
                        &gt;Biodiversity&lt;/keyword&gt;
                    &lt;keyword vocab="smw-rda" URI="http://smw-rda.esc.rzg.mpg.de/index.php/Taxonomy"
                        &gt;Taxonomy&lt;/keyword&gt;
                &lt;/subject&gt;
                &lt;abstract&gt;"That which we call a rose by any other name would smell as sweet.”
                    Shakespeare has Juliet tell her Romeo that a name is just a convention without
                    meaning, what counts is the reference, the 'thing itself', to which the property of
                    smelling sweet pertains alone. Frege in his classical paper “Über Sinn und
                    Bedeutung” was not so sure, he assumed names can be inherently meaningful, even
                    without a known reference. And Wittgenstein later in Philosophical Investigations
                    (PI) seems to deny the sheer arbitrariness of names and reject looking for meaning
                    out of context, by pointing to our inability to just utter some random sounds and by
                    that really implying e.g. the door. The word cannot simply be separated from its
                    meaning, in the same way as the money from the cow that could be bought for them (PI
                    120). Scientific names of biota, in particular, are often descriptive of properties
                    pertaining to the organism or species itself. On the other hand, in semantic web
                    technology and Linked Open Data (LOD) there is an overall effort to replace names by
                    their references, in the form of web links or Uniform Resource Identifiers (URIs).
                    “Things, not strings” is the motto. But, even in view of the many "challenges with
                    using names to link digital biodiversity information" that were extensively
                    described in a recent paper, would it at all be possible or even desirable to
                    replace scientific names of biota with URIs? Or would it be sufficient to just
                    identify equivalence relationships between different variants of names of the same
                    biota, having the same reference, and then just link them to the same “thing”, by
                    means of a property sameAs(URI)? The Global Names Architecture (GNA) has a resolver
                    of scientific names that is already doing that kind of work, linking names of biota
                    such as Pinus thunbergii to global identifiers and URIs from other data sources,
                    such as Encyclopedia of Life (EOL) and uBio Namebank. But there may be other
                    challenges with going from a “natural language”, even from a not entirely coherent
                    system of scientific names, to a semantic web ontology, a solution to some of which
                    have been proposed recently by means of so called 'lexical bridges'.&lt;/abstract&gt;
                &lt;sumDscr/&gt;
                &lt;contact affiliation="Stockholm University" email="joakim.philipson@sub.su.se"
                    &gt;Philipson, Joakim&lt;/contact&gt;
                &lt;depositr&gt;Philipson, Joakim&lt;/depositr&gt;
                &lt;depDate&gt;2017-01-12&lt;/depDate&gt;
            &lt;/stdyInfo&gt;    
            
            
            &lt;xs:complexType name="keywordType" mixed="true"&gt;
                &lt;xs:complexContent&gt;
                    &lt;xs:extension base="simpleTextType"&gt;
                        &lt;xs:attribute name="vocab" type="xs:string"/&gt;
                        &lt;xs:attribute name="vocabURI" type="xs:string"/&gt;
                    &lt;/xs:extension&gt;
                &lt;/xs:complexContent&gt;
            &lt;/xs:complexType&gt;
            
             
            &lt;sumDscr/&gt;
            &lt;contact affiliation="Stockholm University" email="joakim.philipson@sub.su.se"
                &gt;Philipson, Joakim&lt;/contact&gt;
            
            &lt;!-- In codebook: --&gt;
            
            &lt;xs:complexType name="sumDscrType"&gt;
                &lt;xs:complexContent&gt;
                    &lt;xs:extension base="baseElementType"&gt;
                        &lt;xs:sequence&gt;
                            &lt;xs:element ref="timePrd" minOccurs="0" maxOccurs="unbounded"/&gt;
                            &lt;xs:element ref="collDate" minOccurs="0" maxOccurs="unbounded"/&gt;
                            &lt;xs:element ref="nation" minOccurs="0" maxOccurs="unbounded"/&gt;
                            &lt;xs:element ref="geogCover" minOccurs="0" maxOccurs="unbounded"/&gt;
                            &lt;xs:element ref="geogUnit" minOccurs="0" maxOccurs="unbounded"/&gt;
                            &lt;xs:element ref="geoBndBox" minOccurs="0"/&gt;
                            &lt;xs:element ref="boundPoly" minOccurs="0" maxOccurs="unbounded"/&gt;
                            &lt;xs:element ref="anlyUnit" minOccurs="0" maxOccurs="unbounded"/&gt;
                            &lt;xs:element ref="universe" minOccurs="0" maxOccurs="unbounded"/&gt;
                            &lt;xs:element ref="dataKind" minOccurs="0" maxOccurs="unbounded"/&gt;
                        &lt;/xs:sequence&gt;
                    &lt;/xs:extension&gt;
                &lt;/xs:complexContent&gt;
            &lt;/xs:complexType&gt;
            
            &lt;xs:element name="sumDscr" type="sumDscrType"&gt;
                &lt;xs:annotation&gt;
                    &lt;xs:documentation&gt;
                        &lt;xhtml:div&gt;
                            &lt;xhtml:h1 class="element_title"&gt;Summary Data Description&lt;/xhtml:h1&gt;
                            &lt;xhtml:div&gt;
                                &lt;xhtml:h2 class="section_header"&gt;Description&lt;/xhtml:h2&gt;
                                &lt;xhtml:div class="description"&gt;Information about the and geographic coverage of the study and unit of analysis.&lt;/xhtml:div&gt;
                            &lt;/xhtml:div&gt;
                        &lt;/xhtml:div&gt;
                    &lt;/xs:documentation&gt;
                &lt;/xs:annotation&gt;
            &lt;/xs:element&gt;
            
             
            &lt;useStmt&gt;CC0 Waiver&lt;/useStmt&gt;
            
            
            dataverse_1062_philipsonErrorTypes.txt</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Feature: Metadata</name>
              </nodes>
              <nodes>
                <name>Type: Bug</name>
              </nodes>
              <nodes>
                <name>Feature: Harvesting</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.2.1</name>
              </nodes>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.2.1</name>
              </nodes>
              <totalCount>7</totalCount>
            </labels>
            <number>3648</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Make Dataverse produce valid DDI codebook 2.5 XML</title>
            <url>https://github.com/IQSS/dataverse/issues/3648</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Metadata</name>
                </nodes>
                <nodes>
                  <name>Type: Bug</name>
                </nodes>
                <nodes>
                  <name>Feature: Harvesting</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.2.1</name>
                </nodes>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.2.1</name>
                </nodes>
                <totalCount>7</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Make Dataverse produce valid DDI codebook 2.5 XML</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDy_uQ</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>**Description:**
            
            Determine how best to respond to this issue.
            
            Options include prioritizing the work to make file DOIs be off by default and able to be turned on per collection, and/or digging further into technical options and the tradeoffs involved in those. The conversation below covers the initial discussions (in email).
            
            
            
            **Context:**
            
            We received a report from Philipp (CC'd) of an issue registering file-level DOIs for a dataset with many files. From my understanding, there was an error publishing the dataset within Dataverse, but the DOIs were registered anyway. In this case, this resulted in almost 28,000 file-level DOIs being registered. Ultimately, the dataset was successfully published with a much smaller number of files, meaning most of the 28K DOIs were not necessary.
            
            As a result of this report, I was wondering about the timing of DOI registration relative to dataset publication in Dataverse. I remember when DataCite had the December 1 outage, there were reports of Dataverse users being unable to publish datasets due to failed DOI registration. 
            
            My thinking is that (ideally) DOIs shouldn't be registered if there is an error within Dataverse, and an error on DataCite's end shouldn't prevent dataset publication. Do you have any insight into how this works, and if there is any planned development in this area?
            </body>
            <bodyText>Description:
            Determine how best to respond to this issue.
            Options include prioritizing the work to make file DOIs be off by default and able to be turned on per collection, and/or digging further into technical options and the tradeoffs involved in those. The conversation below covers the initial discussions (in email).
            Context:
            We received a report from Philipp (CC'd) of an issue registering file-level DOIs for a dataset with many files. From my understanding, there was an error publishing the dataset within Dataverse, but the DOIs were registered anyway. In this case, this resulted in almost 28,000 file-level DOIs being registered. Ultimately, the dataset was successfully published with a much smaller number of files, meaning most of the 28K DOIs were not necessary.
            As a result of this report, I was wondering about the timing of DOI registration relative to dataset publication in Dataverse. I remember when DataCite had the December 1 outage, there were reports of Dataverse users being unable to publish datasets due to failed DOI registration.
            My thinking is that (ideally) DOIs shouldn't be registered if there is an error within Dataverse, and an error on DataCite's end shouldn't prevent dataset publication. Do you have any insight into how this works, and if there is any planned development in this area?</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <nodes>
                <name>D: Dataset: large number of files</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9272</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Spike: Datacite request to avoid creating unecessary file DOIs</title>
            <url>https://github.com/IQSS/dataverse/issues/9272</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <nodes>
                  <name>D: Dataset: large number of files</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Spike: Datacite request to avoid creating unecessary file DOIs</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEPdLg</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>landreev</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>Dataverses can harvest metadata in our custom json format from each other. Our own proprietary export and import are used in the process. 
            A side effect of this method is that the storageidentifier, the physical location of the datafile on the remote installation ends up being imported *verbatim* into the harvesting dataverse; instead of the url of the download API on the remote end. 
            We now have all these recently harvested files with strange storageidentifiers; 
            like this one:
            ```
            1784af576bf-27316028aabe
            ```
            (no driver prefix; must have been harvested from a pre-4.20 Dataverse)
            or this:
            ```
            s3://dataverse-prod-s3:178290c4c23-3a496b7152af
            ```
            (a file in somebody's S3 storage bucket...)
            These are of course completely useless for a harvesting installation. We want to handle these the same way as when we harvest DDI between Dataverses. I.e., the dvobjects for these harvested files need to be created with the remote download API url  in storageidentifier field (would be `https://dataverse.tdl.org/api/access/datafile/something-something` for the last file above, for example...)
            
            Aside from these entries being useless as imported, this is not urgent in that we don't use these remote locations for any practical purpose, as of now. (So that's why we haven't noticed until now). But it's still messy (I was completely weirded out when I saw the ones like the first one above; that looked entirely like a local storageidentifier, that somehow got created without a driver prefix...)  </body>
            <bodyText>Dataverses can harvest metadata in our custom json format from each other. Our own proprietary export and import are used in the process.
            A side effect of this method is that the storageidentifier, the physical location of the datafile on the remote installation ends up being imported verbatim into the harvesting dataverse; instead of the url of the download API on the remote end.
            We now have all these recently harvested files with strange storageidentifiers;
            like this one:
            1784af576bf-27316028aabe
            
            (no driver prefix; must have been harvested from a pre-4.20 Dataverse)
            or this:
            s3://dataverse-prod-s3:178290c4c23-3a496b7152af
            
            (a file in somebody's S3 storage bucket...)
            These are of course completely useless for a harvesting installation. We want to handle these the same way as when we harvest DDI between Dataverses. I.e., the dvobjects for these harvested files need to be created with the remote download API url  in storageidentifier field (would be https://dataverse.tdl.org/api/access/datafile/something-something for the last file above, for example...)
            Aside from these entries being useless as imported, this is not urgent in that we don't use these remote locations for any practical purpose, as of now. (So that's why we haven't noticed until now). But it's still messy (I was completely weirded out when I saw the ones like the first one above; that looked entirely like a local storageidentifier, that somehow got created without a driver prefix...)</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-24T16:31:29Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: Harvesting</name>
              </nodes>
              <nodes>
                <name>NIH OTA DC</name>
              </nodes>
              <nodes>
                <name>pm.epic.nih_harvesting</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.4.1</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.2</name>
              </nodes>
              <totalCount>7</totalCount>
            </labels>
            <number>7736</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Fix handling of storageidentifiers in dataverse_json harvests</title>
            <url>https://github.com/IQSS/dataverse/issues/7736</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Harvesting</name>
                </nodes>
                <nodes>
                  <name>NIH OTA DC</name>
                </nodes>
                <nodes>
                  <name>pm.epic.nih_harvesting</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.4.1</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.2</name>
                </nodes>
                <totalCount>7</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Fix handling of storageidentifiers in dataverse_json harvests</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPA2s</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>landreev</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>**What steps does it take to reproduce the issue?**
            As a superuser, going to the harvesting client section of the dashboard and trying to create a new client. The base URL is https://zenodo.org/oai2d OR https://www.zenodo.org/oai2d (only the first one is given by the official documentation at https://developers.zenodo.org).
            
            * When does this issue occur?
            After the first step of the setup wizard is completed (and the base URL has been specified).
            
            * Which page(s) does it occurs on?
            See above
            
            * What happens?
            The set list remains empty.
            The server.log registers the following lines :
            ```
            [2021-12-08T10:09:11.805+0100] [Payara 5.2020] [INFO] [] [edu.harvard.iq.dataverse.HarvestingClientsPage] [tid: _ThreadID=90 _ThreadName=http-thread-pool::jk-connector(5)] [timeMillis: 1638954551805] [levelValue: 800] [[
              metadataformats: success]]
            
            [2021-12-08T10:09:11.806+0100] [Payara 5.2020] [INFO] [] [edu.harvard.iq.dataverse.HarvestingClientsPage] [tid: _ThreadID=90 _ThreadName=http-thread-pool::jk-connector(5)] [timeMillis: 1638954551806] [levelValue: 800] [[
              10 metadata formats total.]]
            
            [2021-12-08T10:09:16.767+0100] [Payara 5.2020] [WARNING] [] [edu.harvard.iq.dataverse.HarvestingClientsPage] [tid: _ThreadID=90 _ThreadName=http-thread-pool::jk-connector(5)] [timeMillis: 1638954556767] [levelValue: 900] [[
              Failed to execute ListSets; com.lyncode.xoai.serviceprovider.exceptions.HttpException: Error querying service. Returned HTTP Status Code: 500]]
            ```
            Important note, a curl command entered on the same server (curl -X GET https://zenodo.org/oai2d/?verb=ListsSets) OR directly in a browser retrieves a partial list of sets (the querying error and 500 response are not reproduced in these cases).
            My opinion is it would help to know exactly what command is sent by Dataverse. I don't know any way to check this on my side.
            
            * To whom does it occur (all users, curators, superusers)?
            You have to be superuser to access the feature.
            
            * What did you expect to happen?
            See the set list populated at least partially.
            
            
            **Which version of Dataverse are you using?**
            5.2
            
            **Any related open or closed issues to this bug report?**
            #8267 for being able to get around this limitation by filling the "set" field through the API.
            #8290 for not being able to do so (makes Dataverse crash).</body>
            <bodyText>What steps does it take to reproduce the issue?
            As a superuser, going to the harvesting client section of the dashboard and trying to create a new client. The base URL is https://zenodo.org/oai2d OR https://www.zenodo.org/oai2d (only the first one is given by the official documentation at https://developers.zenodo.org).
            
            
            When does this issue occur?
            After the first step of the setup wizard is completed (and the base URL has been specified).
            
            
            Which page(s) does it occurs on?
            See above
            
            
            What happens?
            The set list remains empty.
            The server.log registers the following lines :
            
            
            [2021-12-08T10:09:11.805+0100] [Payara 5.2020] [INFO] [] [edu.harvard.iq.dataverse.HarvestingClientsPage] [tid: _ThreadID=90 _ThreadName=http-thread-pool::jk-connector(5)] [timeMillis: 1638954551805] [levelValue: 800] [[
              metadataformats: success]]
            
            [2021-12-08T10:09:11.806+0100] [Payara 5.2020] [INFO] [] [edu.harvard.iq.dataverse.HarvestingClientsPage] [tid: _ThreadID=90 _ThreadName=http-thread-pool::jk-connector(5)] [timeMillis: 1638954551806] [levelValue: 800] [[
              10 metadata formats total.]]
            
            [2021-12-08T10:09:16.767+0100] [Payara 5.2020] [WARNING] [] [edu.harvard.iq.dataverse.HarvestingClientsPage] [tid: _ThreadID=90 _ThreadName=http-thread-pool::jk-connector(5)] [timeMillis: 1638954556767] [levelValue: 900] [[
              Failed to execute ListSets; com.lyncode.xoai.serviceprovider.exceptions.HttpException: Error querying service. Returned HTTP Status Code: 500]]
            
            Important note, a curl command entered on the same server (curl -X GET https://zenodo.org/oai2d/?verb=ListsSets) OR directly in a browser retrieves a partial list of sets (the querying error and 500 response are not reproduced in these cases).
            My opinion is it would help to know exactly what command is sent by Dataverse. I don't know any way to check this on my side.
            
            
            To whom does it occur (all users, curators, superusers)?
            You have to be superuser to access the feature.
            
            
            What did you expect to happen?
            See the set list populated at least partially.
            
            
            Which version of Dataverse are you using?
            5.2
            Any related open or closed issues to this bug report?
            #8267 for being able to get around this limitation by filling the "set" field through the API.
            #8290 for not being able to do so (makes Dataverse crash).</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-21T21:21:45Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: Harvesting</name>
              </nodes>
              <nodes>
                <name>NIH OTA DC</name>
              </nodes>
              <nodes>
                <name>pm.epic.nih_harvesting</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.4.1</name>
              </nodes>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.2</name>
              </nodes>
              <totalCount>7</totalCount>
            </labels>
            <number>8289</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>The "ListSets" command fails during the creation of a harvesting client for Zenodo </title>
            <url>https://github.com/IQSS/dataverse/issues/8289</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Harvesting</name>
                </nodes>
                <nodes>
                  <name>NIH OTA DC</name>
                </nodes>
                <nodes>
                  <name>pm.epic.nih_harvesting</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.4.1</name>
                </nodes>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.2</name>
                </nodes>
                <totalCount>7</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>The "ListSets" command fails during the creation of a harvesting client for Zenodo </text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPA5I</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-02-10T17:27:44Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>1249</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Search/Browse</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9222</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Update dataverse.xhtml to add "read more/read less" buttons for dataverse descriptions</title>
            <url>https://github.com/IQSS/dataverse/pull/9222</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Search/Browse</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Update dataverse.xhtml to add "read more/read less" buttons for dataverse descriptions</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgD8XA4</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-04-06T13:55:05Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9183</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Type: Suggestion</name>
              </nodes>
              <nodes>
                <name>Feature: Code Infrastructure</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>9184</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Iqss/9183 terms of access validation fix</title>
            <url>https://github.com/IQSS/dataverse/pull/9184</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Type: Suggestion</name>
                </nodes>
                <nodes>
                  <name>Feature: Code Infrastructure</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Iqss/9183 terms of access validation fix</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEI4go</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-02-16T21:52:07Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8771</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Type: Suggestion</name>
              </nodes>
              <nodes>
                <name>Feature: Code Infrastructure</name>
              </nodes>
              <nodes>
                <name>User Role: Hackathon Participant</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>8970</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>class field can be replaced by local variable</title>
            <url>https://github.com/IQSS/dataverse/pull/8970</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Type: Suggestion</name>
                </nodes>
                <nodes>
                  <name>Feature: Code Infrastructure</name>
                </nodes>
                <nodes>
                  <name>User Role: Hackathon Participant</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.14</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>class field can be replaced by local variable</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTds</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9255</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Metadata</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9256</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Make Series multiple #9255</title>
            <url>https://github.com/IQSS/dataverse/pull/9256</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Metadata</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Make Series multiple #9255</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEJLes</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>landreev</login>
              </nodes>
              <nodes>
                <login>jggautier</login>
              </nodes>
              <totalCount>2</totalCount>
            </assignees>
            <body>Established Dataverse installations that have been operating for years might be reluctant to turn on Make Data Count (MDC) because the download counts will be reset to zero unless something is done to somehow copy the "classic" download counts into the new "datasetmetrics" database table that powers MDC download metrics. For example, Harvard Dataverse has over 10 million "classic" downloads:
            
            ![Screen Shot 2020-02-06 at 11 47 41 AM](https://user-images.githubusercontent.com/21006/73958876-8b91a280-48d6-11ea-865d-c0218a0979c8.png)
            
            Many Dataverse installations probably don't have all the Apache (or Glassfish or whatever) access logs from years ago lying around but the database table `filedownload` could be used as a source for timestamps of downloads from the "classic" system. After standup on 2020-02-05 @djbrooke @kcondon talked about this and I made the following diagram (best to open it in a new window since the text is so small):
            
            ![make-data-count](https://user-images.githubusercontent.com/21006/73873945-9be74600-4820-11ea-800b-04ca1f45e90b.png)
            
            source for the image above: [make-data-count.uml.txt](https://github.com/IQSS/dataverse/files/4166368/make-data-count.uml.txt)
            
            This is what I added to the diagram, which is based on http://guides.dataverse.org/en/4.19/admin/make-data-count.html#architecture
            
            ```
            == Historical Logging ==
            sysadmin --&gt; exportLogsApi : GET /api/admin/mdc/exportLogs
            exportLogsApi --&gt; log : all history from database
            main.py --&gt; log : read historical logs
            main.py --&gt; datasetMetrics : write metrics to datasetmetrics table (using SUSHI, as below)
            main.py --&gt; reports : send metrics to DataCite
            ```
            
            This is a bit hand wavy because we'd still use SUSHI as indicated by the `Log Processing` part of the diagram.
            
            Roughly, the idea is this:
            
            - Create a new Dataverse API for sysadmins to use to export from Dataverse a series logs that are compatible with Counter Processor (one per month for 10 years, for example)
            - Use Counter Processor to populate the new "datasetmetrics" table used by MDC by processing those logs that were exported.
            - Use Counter Processor to send the historical data to DataCite.
            
            See also pull request IQSS/dataverse#6543
            
            - classic table: http://phoenix.dataverse.org/schemaspy/latest/tables/filedownload.html
            - MDC table http://phoenix.dataverse.org/schemaspy/latest/tables/datasetmetrics.html</body>
            <bodyText>Established Dataverse installations that have been operating for years might be reluctant to turn on Make Data Count (MDC) because the download counts will be reset to zero unless something is done to somehow copy the "classic" download counts into the new "datasetmetrics" database table that powers MDC download metrics. For example, Harvard Dataverse has over 10 million "classic" downloads:
            
            Many Dataverse installations probably don't have all the Apache (or Glassfish or whatever) access logs from years ago lying around but the database table filedownload could be used as a source for timestamps of downloads from the "classic" system. After standup on 2020-02-05 @djbrooke @kcondon talked about this and I made the following diagram (best to open it in a new window since the text is so small):
            
            source for the image above: make-data-count.uml.txt
            This is what I added to the diagram, which is based on http://guides.dataverse.org/en/4.19/admin/make-data-count.html#architecture
            == Historical Logging ==
            sysadmin --&gt; exportLogsApi : GET /api/admin/mdc/exportLogs
            exportLogsApi --&gt; log : all history from database
            main.py --&gt; log : read historical logs
            main.py --&gt; datasetMetrics : write metrics to datasetmetrics table (using SUSHI, as below)
            main.py --&gt; reports : send metrics to DataCite
            
            This is a bit hand wavy because we'd still use SUSHI as indicated by the Log Processing part of the diagram.
            Roughly, the idea is this:
            
            Create a new Dataverse API for sysadmins to use to export from Dataverse a series logs that are compatible with Counter Processor (one per month for 10 years, for example)
            Use Counter Processor to populate the new "datasetmetrics" table used by MDC by processing those logs that were exported.
            Use Counter Processor to send the historical data to DataCite.
            
            See also pull request IQSS/dataverse#6543
            
            classic table: http://phoenix.dataverse.org/schemaspy/latest/tables/filedownload.html
            MDC table http://phoenix.dataverse.org/schemaspy/latest/tables/datasetmetrics.html</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>NIH OTA: 1.5.1</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.5.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.5.2</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>75</number>
            <repository>
              <name>dataverse.harvard.edu</name>
            </repository>
            <title>Spike: finalize the plan for transition to Make Data Count, how to display the metrics, how to handle legacy counts</title>
            <url>https://github.com/IQSS/dataverse.harvard.edu/issues/75</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>2</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNzQwNTY1NTE=</id>
                <name>dataverse.harvard.edu</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>NIH OTA: 1.5.1</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.5.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.5.2</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Spike: finalize the plan for transition to Make Data Count, how to display the metrics, how to handle legacy counts</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEPnvA</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>OTA</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>ODE</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8092</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Request Access Workflow</name>
              </nodes>
              <nodes>
                <name>DANS</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>9257</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>8092 timestamp of data access request</title>
            <url>https://github.com/IQSS/dataverse/pull/9257</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>2</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Request Access Workflow</name>
                </nodes>
                <nodes>
                  <name>DANS</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.14</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>8092 timestamp of data access request</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEJRAc</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-01-30T19:13:22Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Type: Suggestion</name>
              </nodes>
              <nodes>
                <name>Feature: API Guide</name>
              </nodes>
              <nodes>
                <name>User Role: API User</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>6183</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Fix at 'Show the dataset whose id is passed' section #6083</title>
            <url>https://github.com/IQSS/dataverse/pull/6183</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Type: Suggestion</name>
                </nodes>
                <nodes>
                  <name>Feature: API Guide</name>
                </nodes>
                <nodes>
                  <name>User Role: API User</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Fix at 'Show the dataset whose id is passed' section #6083</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNc9E</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>rtreacy</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>@pdurbin this is a placeholder issue your next step that you talked about.
            
            
            **Title**
            - A clear and relevant title (Problem Statement)
            
            **Description**
            - A description of what the user will experience or how the system will do.
            
            **Context**
            - Any context that sheds more light on the what or why or the history.
            
            **Acceptance Criteria**
            - A description or how we will know when we have completed this deliverable.
            
            **Size:**
            Small - this can be finished including testing in about a day.
            Medium - this can be finished including testing in 1 week.
            Large - STOP. this issue needs to be split in order to get pieces that can be completed in a week or less. (A large story is not "Ready")
            
            
            ---
            Product backlog:
            - https://github.com/orgs/IQSS/projects/32/views/22</body>
            <bodyText>@pdurbin this is a placeholder issue your next step that you talked about.
            Title
            
            A clear and relevant title (Problem Statement)
            
            Description
            
            A description of what the user will experience or how the system will do.
            
            Context
            
            Any context that sheds more light on the what or why or the history.
            
            Acceptance Criteria
            
            A description or how we will know when we have completed this deliverable.
            
            Size:
            Small - this can be finished including testing in about a day.
            Medium - this can be finished including testing in 1 week.
            Large - STOP. this issue needs to be split in order to get pieces that can be completed in a week or less. (A large story is not "Ready")
            
            Product backlog:
            
            https://github.com/orgs/IQSS/projects/32/views/22</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-15T18:22:04Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: File Upload &amp; Handling</name>
              </nodes>
              <nodes>
                <name>pm.netcdf-hdf5.d</name>
              </nodes>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>9147</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Draft design doc for NetCDF/HDF5/geospatial</title>
            <url>https://github.com/IQSS/dataverse/issues/9147</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: File Upload &amp; Handling</name>
                </nodes>
                <nodes>
                  <name>pm.netcdf-hdf5.d</name>
                </nodes>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Draft design doc for NetCDF/HDF5/geospatial</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>NIH NetCDF (Phil)</text>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDU1Dk</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>jggautier</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>The Harvard Dataverse Repository's license list includes only CC0. We'd like to add more licenses.
            
            During a curation team meeting we decided to add the Creative Commons licenses listed at https://creativecommons.org/about/cclicenses.
            
            To figure out what other licenses to add, we'd like to learn:
            - What are other Dataverse installations using?
            - Among deposits in Harvard's repo, what licenses have been entered in Terms of Use field when CC0 isn't used.
            
            Steps for adding and editing licenses is at https://guides.dataverse.org/en/latest/installation/config.html#configuring-licenses</body>
            <bodyText>The Harvard Dataverse Repository's license list includes only CC0. We'd like to add more licenses.
            During a curation team meeting we decided to add the Creative Commons licenses listed at https://creativecommons.org/about/cclicenses.
            To figure out what other licenses to add, we'd like to learn:
            
            What are other Dataverse installations using?
            Among deposits in Harvard's repo, what licenses have been entered in Terms of Use field when CC0 isn't used.
            
            Steps for adding and editing licenses is at https://guides.dataverse.org/en/latest/installation/config.html#configuring-licenses</bodyText>
            <closed>True</closed>
            <closedAt>2023-02-22T16:50:42Z</closedAt>
            <labels>
              <nodes>
                <name>Size: NoSprintCost</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>193</number>
            <repository>
              <name>dataverse.harvard.edu</name>
            </repository>
            <title>Spike: Add more licenses using multiple license feature</title>
            <url>https://github.com/IQSS/dataverse.harvard.edu/issues/193</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNzQwNTY1NTE=</id>
                <name>dataverse.harvard.edu</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: NoSprintCost</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Spike: Add more licenses using multiple license feature</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDTpWM</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>sekmiller</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>
            
            Very closely related to: 
            - #7430  
            
            **What steps does it take to reproduce the issue?** Link a Dataverse that contains datasets to another dataverse. We expect to see the linked Dataverse's datasets appear on the linking Dataverse's home page. We see the linked Dataverse, but not its datasets.
            
            * When does this issue occur? When  you link a Dataverse that contains datasets.
            
            
            * Which page(s) does it occurs on? Dataverse page
            
            
            * What happens? We don't see the datasets contained in the linked dataverse.
            
            
            * To whom does it occur (all users, curators, superusers)? The end result is seen (or not seen) by all users.
            
            
            * What did you expect to happen?
            We would expect to see the datasets contained in the linked Dataverse to show up on the linking Dataverse's page
            
            
            **Which version of Dataverse are you using?** 5.10
            
            
            
            **Any related open or closed issues to this bug report?**
            https://github.com/IQSS/dataverse/issues/7766
            
            
            **Screenshots:**
            
            No matter the issue, screenshots are always welcome.
            
            To add a screenshot, please use one of the following formats and/or methods described here:
            
            * https://help.github.com/en/articles/file-attachments-on-issues-and-pull-requests
            *
            </body>
            <bodyText>Very closely related to:
            
            #7430
            
            What steps does it take to reproduce the issue? Link a Dataverse that contains datasets to another dataverse. We expect to see the linked Dataverse's datasets appear on the linking Dataverse's home page. We see the linked Dataverse, but not its datasets.
            
            
            When does this issue occur? When  you link a Dataverse that contains datasets.
            
            
            Which page(s) does it occurs on? Dataverse page
            
            
            What happens? We don't see the datasets contained in the linked dataverse.
            
            
            To whom does it occur (all users, curators, superusers)? The end result is seen (or not seen) by all users.
            
            
            What did you expect to happen?
            We would expect to see the datasets contained in the linked Dataverse to show up on the linking Dataverse's page
            
            
            Which version of Dataverse are you using? 5.10
            Any related open or closed issues to this bug report?
            #7766
            Screenshots:
            No matter the issue, screenshots are always welcome.
            To add a screenshot, please use one of the following formats and/or methods described here:
            
            https://help.github.com/en/articles/file-attachments-on-issues-and-pull-requests</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-23T23:30:18Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>8724</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Linking Dataverse does not update child dataset indexes</title>
            <url>https://github.com/IQSS/dataverse/issues/8724</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Linking Dataverse does not update child dataset indexes</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTjA</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>We'd like deaccessioned datasets to be excluded from being harvested. I have tried to create an OAI set by setting the Solr field publicationStatus:Deaccessioned in the OAI set query; cf. [this thread](https://groups.google.com/forum/?hl=no#!topic/dataverse-community/hy_GlMdEBwU) in the Dataverse Google Group. Please have a look into this and enable deaccessioned datasets from harvesting. Thanks!
            </body>
            <bodyText>We'd like deaccessioned datasets to be excluded from being harvested. I have tried to create an OAI set by setting the Solr field publicationStatus:Deaccessioned in the OAI set query; cf. this thread in the Dataverse Google Group. Please have a look into this and enable deaccessioned datasets from harvesting. Thanks!</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-10T20:44:45Z</closedAt>
            <labels>
              <nodes>
                <name>Type: Suggestion</name>
              </nodes>
              <nodes>
                <name>Feature: Harvesting</name>
              </nodes>
              <nodes>
                <name>User Role: Superuser</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.4.1</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.2</name>
              </nodes>
              <totalCount>7</totalCount>
            </labels>
            <number>5112</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Exclude deaccessioned dataset from being harvested</title>
            <url>https://github.com/IQSS/dataverse/issues/5112</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Type: Suggestion</name>
                </nodes>
                <nodes>
                  <name>Feature: Harvesting</name>
                </nodes>
                <nodes>
                  <name>User Role: Superuser</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.4.1</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.2</name>
                </nodes>
                <totalCount>7</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Exclude deaccessioned dataset from being harvested</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPA3Q</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>donsizemore</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>Definition of done (stay within a size of 10 or a full day's work):
            
            - Resolve merge conflicts in PR #9116.
            - Poke around and look for next bug.
            - If the bug seems small, create a PR into PR #9116 to fix it.
            - If the bug seems large, create an issue and describe the bug well. Leave a comment in PR #9116 about the new issue.</body>
            <bodyText>Definition of done (stay within a size of 10 or a full day's work):
            
            Resolve merge conflicts in PR #9116.
            Poke around and look for next bug.
            If the bug seems small, create a PR into PR #9116 to fix it.
            If the bug seems large, create an issue and describe the bug well. Leave a comment in PR #9116 about the new issue.</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-25T20:45:48Z</closedAt>
            <labels>
              <nodes>
                <name>D: Payara 6 Upgrade</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9283</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Payara 6: resolve conflicts and look for next bug</title>
            <url>https://github.com/IQSS/dataverse/issues/9283</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>D: Payara 6 Upgrade</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Payara 6: resolve conflicts and look for next bug</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEQ-GQ</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>landreev</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>This is in support of:
            - an NIH grant ["The Harvard Dataverse repository: A generalist repository integrated with a Data Commons"](https://docs.google.com/document/d/1cFK8pdwMKIRZxNs8EZXL1cXmW0ho6Rx9ulCewJ1ZCFI/edit?usp=sharing), 
              - Aim 4: **Improve harvesting and packaging standards to share metadata and data across repositories**, 
            
            The first step is to figure out what has already been done by the dataverse team and by the community towards this aim and what still remains to be done. 
            
            For example:
            - [8139 Can't harvest when Dublin core field language is set](https://github.com/IQSS/dataverse/issues/8139#)
            
            And then to prioritize which issues are to be fixed.
            
            ### Def of done
            As completely as is reasonably possible in a 2 week period (sprint):
            - [ ] Search out previous related issues that are problems with the current implementation. Take an inventory.
            - [ ] Search out previous work done within the dataverse community as well.
            - [ ] prioritize which of the issues/PRs that should be moved forward.
            
            We need to keep in mind that to harvest something from a particular source requires that that source be bug free. Identify which sources have which bugs so that bugs for a particular source can be targeted. for example: ICPSR as an example. Zenodo is another.
            
            
            ### More information:
            
            There is a lot packaged into Aim 4
             1. Improved Harvesting via the  OAI-PMH standard
             1. Improved support for Bagit
             1. Improved support for Signposting
            
            The scope for this issue is Harvesting via the  OAI-PMH standard
            
            ### Aim 4: 
            
            **Improve harvesting and packaging standards to share metadata and data across repositories**
            
            Our proposed project will significantly improve the widely-used Harvard Dataverse repository to better support NIH-funded research. 
            
            **A critical measure of the [GREI program](https://www.iq.harvard.edu/news/dataverse-joins-nih-data-repository-initiative)’s success is to standardize the discoverability across generalist repositories**.
            
            To help with this, **we propose to improve the existing harvesting functionality in the Dataverse software based on the Open Archives Initiative Protocol for Metadata Harvesting **(OAI-PMH) standard**, and coordinate with other repository packaging standards to share or move metadata and data. **
            
            Dataverse already supports the Bags as defined by the Research Data Alliance (RDA) Research Data Repository Interoperability Working Group. Here we proposed to improve the support for **Bags**, test it for NIH-funded datasets, and explore and define the appropriate standard to use to move the metadata and data across generalist repositories. This will help with a sustainable and succession plan - if one repository cannot support anymore a specific dataset, it will allow to easily move the dataset to another repository without losing any information about the dataset. 
            
            Additionally we propose to implement **Signposting** in the Dataverse software.  By adding additional http link headers throughout the application, we can more easily support automated metadata and data discovery in the repository, and allow for other applications and services to more accurately and completely represent the content in the Harvard Dataverse repository. 
            
            
            
            ### Related documents
            - [Notes on Dataverse Deliverablas for NIH OTA](https://docs.google.com/document/d/1N9xgubVcHb2mQxnCrmusa0M7qVGiVvyvmODc4j4HvQ8/edit?usp=sharing)
            - [NIH OTA Progress Notes](https://docs.google.com/document/d/1k0XLOqYGCbV1O4eqUtOz67Hk4kXqhv4dKg_juabNVw0/edit?usp=sharing)
            - [NIH OTA](https://docs.google.com/document/d/1cFK8pdwMKIRZxNs8EZXL1cXmW0ho6Rx9ulCewJ1ZCFI/edit?usp=sharing)
            - [Exposing and harvesting metadata using the OAI metadata harvesting protocol: A tutoria (2001)](https://arxiv.org/pdf/cs/0106057.pdf)
            - [Getting Started with BagIt in 2018](https://patchbay.tech/blog/2018/03/14/getting-started-with-bagit-in-2018/)
            - [NIH OTA](https://docs.google.com/document/d/1cFK8pdwMKIRZxNs8EZXL1cXmW0ho6Rx9ulCewJ1ZCFI/edit?usp=sharing)
            - [bagit from Library of Congress video](https://www.youtube.com/watch?time_continue=11&amp;v=l3p3ao_JSfo&amp;feature=emb_logo)</body>
            <bodyText>This is in support of:
            
            an NIH grant "The Harvard Dataverse repository: A generalist repository integrated with a Data Commons",
            
            Aim 4: Improve harvesting and packaging standards to share metadata and data across repositories,
            
            
            
            The first step is to figure out what has already been done by the dataverse team and by the community towards this aim and what still remains to be done.
            For example:
            
            8139 Can't harvest when Dublin core field language is set
            
            And then to prioritize which issues are to be fixed.
            Def of done
            As completely as is reasonably possible in a 2 week period (sprint):
            
             Search out previous related issues that are problems with the current implementation. Take an inventory.
             Search out previous work done within the dataverse community as well.
             prioritize which of the issues/PRs that should be moved forward.
            
            We need to keep in mind that to harvest something from a particular source requires that that source be bug free. Identify which sources have which bugs so that bugs for a particular source can be targeted. for example: ICPSR as an example. Zenodo is another.
            More information:
            There is a lot packaged into Aim 4
            
            Improved Harvesting via the  OAI-PMH standard
            Improved support for Bagit
            Improved support for Signposting
            
            The scope for this issue is Harvesting via the  OAI-PMH standard
            Aim 4:
            Improve harvesting and packaging standards to share metadata and data across repositories
            Our proposed project will significantly improve the widely-used Harvard Dataverse repository to better support NIH-funded research.
            A critical measure of the GREI program’s success is to standardize the discoverability across generalist repositories.
            To help with this, **we propose to improve the existing harvesting functionality in the Dataverse software based on the Open Archives Initiative Protocol for Metadata Harvesting (OAI-PMH) standard, and coordinate with other repository packaging standards to share or move metadata and data. **
            Dataverse already supports the Bags as defined by the Research Data Alliance (RDA) Research Data Repository Interoperability Working Group. Here we proposed to improve the support for Bags, test it for NIH-funded datasets, and explore and define the appropriate standard to use to move the metadata and data across generalist repositories. This will help with a sustainable and succession plan - if one repository cannot support anymore a specific dataset, it will allow to easily move the dataset to another repository without losing any information about the dataset.
            Additionally we propose to implement Signposting in the Dataverse software.  By adding additional http link headers throughout the application, we can more easily support automated metadata and data discovery in the repository, and allow for other applications and services to more accurately and completely represent the content in the Harvard Dataverse repository.
            Related documents
            
            Notes on Dataverse Deliverablas for NIH OTA
            NIH OTA Progress Notes
            NIH OTA
            Exposing and harvesting metadata using the OAI metadata harvesting protocol: A tutoria (2001)
            Getting Started with BagIt in 2018
            NIH OTA
            bagit from Library of Congress video</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-25T20:17:07Z</closedAt>
            <labels>
              <nodes>
                <name>pm.GREI-d-1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.2</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>24</number>
            <repository>
              <name>dataverse-pm</name>
            </repository>
            <title>Spike: Inventory and prioritize all existing Harvesting related issues</title>
            <url>https://github.com/IQSS/dataverse-pm/issues/24</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOIwMRzQ</id>
                <name>dataverse-pm</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>pm.GREI-d-1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.2</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Spike: Inventory and prioritize all existing Harvesting related issues</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEN4RM</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>sekmiller</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>
            Very closely related to: 
            - #8724   
            
            - using version v. 5.1.1 build 221-1b59dac
            
            Our Dataverses hierarchy goes root - level 1 - level 2 - level 3. All three levels have multiple dataverses.
            
            Many linked dataverses dont appear in their linking dataverses. The link Dataverse API gives back 200 and a database entry is added properly, yet they don't show up being linked in those dataverses. Neither reindexing the linking dataverses nor a full reindex helps with this.
            
            Linking level 1 into level 1 works.
            Linking level 2 into level 1 works.
            Linking level 3 into level 1 works.
            
            Linking level 1 into level 3 doesnt work.
            Linking level 2 into level 3 doesnt work.
            Linking level 1 into level 2 doesnt work.
            Linking level 2 into level 2 doesnt work.
            Linking level 3 into level 3 doesnt work.
            Linking level 3 into level 2 doesnt work.
            
            We assume that linking a superior level dataverse into a subordinated dataverse does not work as a feature, since it's considered to be unlogical (please correct me if this should work).
            However this doesnt explain all of the "doesnt work" lines above. </body>
            <bodyText>Very closely related to:
            
            
            #8724
            
            
            using version v. 5.1.1 build 221-1b59dac
            
            
            Our Dataverses hierarchy goes root - level 1 - level 2 - level 3. All three levels have multiple dataverses.
            Many linked dataverses dont appear in their linking dataverses. The link Dataverse API gives back 200 and a database entry is added properly, yet they don't show up being linked in those dataverses. Neither reindexing the linking dataverses nor a full reindex helps with this.
            Linking level 1 into level 1 works.
            Linking level 2 into level 1 works.
            Linking level 3 into level 1 works.
            Linking level 1 into level 3 doesnt work.
            Linking level 2 into level 3 doesnt work.
            Linking level 1 into level 2 doesnt work.
            Linking level 2 into level 2 doesnt work.
            Linking level 3 into level 3 doesnt work.
            Linking level 3 into level 2 doesnt work.
            We assume that linking a superior level dataverse into a subordinated dataverse does not work as a feature, since it's considered to be unlogical (please correct me if this should work).
            However this doesnt explain all of the "doesnt work" lines above.</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-23T23:44:38Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 80</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>7430</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Linked dataverses dont (always) show up in their linking dataverses</title>
            <url>https://github.com/IQSS/dataverse/issues/7430</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 80</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Linked dataverses dont (always) show up in their linking dataverses</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTjQ</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>landreev</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>Decomposed from: 
            - [PR 9116](https://github.com/IQSS/dataverse/pull/9116) 
            
            This is exploratory work.
            It requires investigation, then code work.
            The logic works. In the best case the work here is correcting an incompatibility.
            
            
            You can create datasets in the API, as the API test suite passes.
            This issue is located around JSF (UI).
            Could this be that we are an old version of JSF or Jakarta compatibility?
            
            </body>
            <bodyText>Decomposed from:
            
            PR 9116
            
            This is exploratory work.
            It requires investigation, then code work.
            The logic works. In the best case the work here is correcting an incompatibility.
            You can create datasets in the API, as the API test suite passes.
            This issue is located around JSF (UI).
            Could this be that we are an old version of JSF or Jakarta compatibility?</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-11T16:06:52Z</closedAt>
            <labels>
              <nodes>
                <name>D: Payara 6 Upgrade</name>
              </nodes>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9214</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Bug: Fix dataset creation in the payara 6 branch</title>
            <url>https://github.com/IQSS/dataverse/issues/9214</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>D: Payara 6 Upgrade</name>
                </nodes>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Bug: Fix dataset creation in the payara 6 branch</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgD0MTE</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MTAw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>OTE</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>According to [OWASP](https://owasp.org/) 12 round bcrypt encryption for passwords is recommended. Dataverse currently uses only 10 round bcrypt which significantly easier to crack. It should be easy to add the new algorithm (actually just changing the # rounds from what's there now) and configure so that the existing password update mechanism would require everyone to re-login.
            
            I'm not sure what priority this needs - password encryption is done in case someone gets access to the db so nominally one has to have a breach before the encryption strength is an issue.</body>
            <bodyText>According to OWASP 12 round bcrypt encryption for passwords is recommended. Dataverse currently uses only 10 round bcrypt which significantly easier to crack. It should be easy to add the new algorithm (actually just changing the # rounds from what's there now) and configure so that the existing password update mechanism would require everyone to re-login.
            I'm not sure what priority this needs - password encryption is done in case someone gets access to the db so nominally one has to have a breach before the encryption strength is an issue.</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-11T15:18:43Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>29</number>
            <repository>
              <name>dataverse-security</name>
            </repository>
            <title>Password update to bcrypt12</title>
            <url>https://github.com/IQSS/dataverse-security/issues/29</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNzU2OTc3NTI=</id>
                <name>dataverse-security</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Password update to bcrypt12</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNXqw</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>(another sub-issue of #198)
            This is something Odum at UNC implemented on their site following problems with inappropriate activity similar to ours. 
            They chose to actually *delete* all such accounts (as opposed to _deactivate_), which by definition only works on completely unused accounts (for ex., downloading a single file and the resulting entry in the guestbook table makes an account "un-deletable"). We can do that, or choose to deactivate whatever accounts we deem abandoned; if we choose the latter, we can expand the definition of such. 
            
            Getting rid of unused accounts is generally a good practice. But it would also eliminate any malicious "sleeper" types. 
            </body>
            <bodyText>(another sub-issue of #198)
            This is something Odum at UNC implemented on their site following problems with inappropriate activity similar to ours.
            They chose to actually delete all such accounts (as opposed to deactivate), which by definition only works on completely unused accounts (for ex., downloading a single file and the resulting entry in the guestbook table makes an account "un-deletable"). We can do that, or choose to deactivate whatever accounts we deem abandoned; if we choose the latter, we can expand the definition of such.
            Getting rid of unused accounts is generally a good practice. But it would also eliminate any malicious "sleeper" types.</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-03T02:08:58Z</closedAt>
            <labels>
              <nodes>
                <name>ops: User Accounts</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>201</number>
            <repository>
              <name>dataverse.harvard.edu</name>
            </repository>
            <title>Purge unused user accounts (as in, first consider and discuss, then, potentially, purge)</title>
            <url>https://github.com/IQSS/dataverse.harvard.edu/issues/201</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNzQwNTY1NTE=</id>
                <name>dataverse.harvard.edu</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>ops: User Accounts</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Purge unused user accounts (as in, first consider and discuss, then, potentially, purge)</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDfLyU</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-07T22:38:07Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9106</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>DANS</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9107</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>fix for cvv and editMetadata replace=true, and test</title>
            <url>https://github.com/IQSS/dataverse/pull/9107</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>DANS</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>fix for cvv and editMetadata replace=true, and test</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 1, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNm-g</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-07T20:45:49Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8346</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9125</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>8346 License internationalizataion</title>
            <url>https://github.com/IQSS/dataverse/pull/9125</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>8346 License internationalizataion</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 1, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDQQ_E</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>landreev</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>The DOIs of two published datasets - doi:10.7910/DVN/26663 and doi:10.7910/DVN/29779 - fail to load:
            
            - https://doi.org/10.7910/DVN/26663 - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/26663
            - https://doi.org/10.7910/DVN/29779 - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/29779
            
            And the Native API endpoints for getting their metadata return different errors.
            
            - In Splunk, the log for incident ID returned when following https://dataverse.harvard.edu/api/datasets/:persistentId/versions?persistentId=doi:10.7910/DVN/26663 says `"Unmatched closing ')' near index 1"`
            - For https://dataverse.harvard.edu/api/datasets/:persistentId/versions?persistentId=doi:10.7910/DVN/29779, I saw `null java.lang.NullPointerException`
            
            Both datasets come up in searches using the UI and the Search API ([search for  doi:10.7910/DVN/26663](https://dataverse.harvard.edu/dataverse/harvard/?q=dsPersistentId:"doi:10.7910/DVN/26663"); [search for doi:10.7910/DVN/29779](https://dataverse.harvard.edu/dataverse/harvard/?q=dsPersistentId:"doi:10.7910/DVN/29779")), and all other datasets in their collections are accessible.
            
            I'm going to try to contact the data owners to let them know that the datasets' pages aren't accessible and that we're looking into it.
            
            @sbarbosadataverse Can restoring access to these datasets be considered in a prioritization meeting?
            
            
            
            Context: (from a discussion with @jggautier and @mreekie 
            - The depositors did not delete this data. This was not a failed attempt by the depositor or by a dev to delete the data.
            - At least some of the data files exist  when I tried to use the APIs to access them.
            - It's just that when you click on the links you get error pages and when you use the APIs to get the metadata it fails.
            
            How will we know it's done.
            - The data is reachable via the links.</body>
            <bodyText>The DOIs of two published datasets - doi:10.7910/DVN/26663 and doi:10.7910/DVN/29779 - fail to load:
            
            https://doi.org/10.7910/DVN/26663 - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/26663
            https://doi.org/10.7910/DVN/29779 - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/29779
            
            And the Native API endpoints for getting their metadata return different errors.
            
            In Splunk, the log for incident ID returned when following https://dataverse.harvard.edu/api/datasets/:persistentId/versions?persistentId=doi:10.7910/DVN/26663 says "Unmatched closing ')' near index 1"
            For https://dataverse.harvard.edu/api/datasets/:persistentId/versions?persistentId=doi:10.7910/DVN/29779, I saw null java.lang.NullPointerException
            
            Both datasets come up in searches using the UI and the Search API (search for  doi:10.7910/DVN/26663; search for doi:10.7910/DVN/29779), and all other datasets in their collections are accessible.
            I'm going to try to contact the data owners to let them know that the datasets' pages aren't accessible and that we're looking into it.
            @sbarbosadataverse Can restoring access to these datasets be considered in a prioritization meeting?
            Context: (from a discussion with @jggautier and @mreekie
            
            The depositors did not delete this data. This was not a failed attempt by the depositor or by a dev to delete the data.
            At least some of the data files exist  when I tried to use the APIs to access them.
            It's just that when you click on the links you get error pages and when you use the APIs to get the metadata it fails.
            
            How will we know it's done.
            
            The data is reachable via the links.</bodyText>
            <closed>True</closed>
            <closedAt>2022-12-01T20:32:38Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>Support</name>
              </nodes>
              <nodes>
                <name>Support: prod. data corruption</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>192</number>
            <repository>
              <name>dataverse.harvard.edu</name>
            </repository>
            <title>Restore access to two published datasets' whose pages fail to load; API endpoint for getting their dataset metadata fails</title>
            <url>https://github.com/IQSS/dataverse.harvard.edu/issues/192</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNzQwNTY1NTE=</id>
                <name>dataverse.harvard.edu</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>Support</name>
                </nodes>
                <nodes>
                  <name>Support: prod. data corruption</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Restore access to two published datasets' whose pages fail to load; API endpoint for getting their dataset metadata fails</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Pre December 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDTsGM</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-01T19:45:59Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8267</number>
              </nodes>
              <nodes>
                <number>8290</number>
              </nodes>
              <totalCount>2</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9174</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>8290 harvest client api</title>
            <url>https://github.com/IQSS/dataverse/pull/9174</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>8290 harvest client api</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Pre December 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDtA6o</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>Context:
            - This came out of the deliverable discussions
            Links:
            - [2 | 1.2.1 | Design and implement integration with controlled vocabularies | 5#9027](https://github.com/IQSS/dataverse-pm/issues/7)</body>
            <bodyText>Context:
            
            This came out of the deliverable discussions
            Links:
            2 | 1.2.1 | Design and implement integration with controlled vocabularies | 5#9027</bodyText>
            <closed>True</closed>
            <closedAt>2022-12-01T19:50:19Z</closedAt>
            <labels>
              <nodes>
                <name>NIH OTA: 1.2.1</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.2.1</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>9114</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Create a whitepaper for external vocabulary work 1.2.1</title>
            <url>https://github.com/IQSS/dataverse/issues/9114</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>NIH OTA: 1.2.1</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.2.1</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create a whitepaper for external vocabulary work 1.2.1</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Pre December 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNnqw</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>The oai server shows an internal server error when the metadataPrefix parameter contains an unknown value.</body>
            <bodyText>The oai server shows an internal server error when the metadataPrefix parameter contains an unknown value.</bodyText>
            <closed>True</closed>
            <closedAt>2022-11-28T18:57:16Z</closedAt>
            <labels>
              <nodes>
                <name>Type: Bug</name>
              </nodes>
              <nodes>
                <name>Feature: Harvesting</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.2</name>
              </nodes>
              <totalCount>6</totalCount>
            </labels>
            <number>3741</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>OAI server: metadataPrefix unknown: Internal server error</title>
            <url>https://github.com/IQSS/dataverse/issues/3741</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Type: Bug</name>
                </nodes>
                <nodes>
                  <name>Feature: Harvesting</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.2</name>
                </nodes>
                <totalCount>6</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.12.1</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>OAI server: metadataPrefix unknown: Internal server error</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Pre December 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPA1M</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>landreev</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>Hello,
            
            I ran into the issue described here: https://groups.google.com/g/dataverse-community/c/O-NdDtgFrI0/m/os_KjdLxAQAJ
            
            The process worked, but maybe it would be a good idea to have a button that would do the same thing on the harvest page? or maybe an API to reset stuck harvest?
            
            Here is what i've done: 
            #manually get the harvest job's id:
            select * from harvestingclient;
            
            #fix the issue - where {ID} is the database id of the harvesting client.
            UPDATE clientharvestrun SET harvestresult=0 WHERE harvestingclient_id={ID} AND harvestresult = 2;
            UPDATE harvestingclient SET harvestingnow = FALSE WHERE id={ID};
            
            #restart payara "just in case"
            systemctl restart payara
            
            Take care,
            
            Virgile</body>
            <bodyText>Hello,
            I ran into the issue described here: https://groups.google.com/g/dataverse-community/c/O-NdDtgFrI0/m/os_KjdLxAQAJ
            The process worked, but maybe it would be a good idea to have a button that would do the same thing on the harvest page? or maybe an API to reset stuck harvest?
            Here is what i've done:
            #manually get the harvest job's id:
            select * from harvestingclient;
            #fix the issue - where {ID} is the database id of the harvesting client.
            UPDATE clientharvestrun SET harvestresult=0 WHERE harvestingclient_id={ID} AND harvestresult = 2;
            UPDATE harvestingclient SET harvestingnow = FALSE WHERE id={ID};
            #restart payara "just in case"
            systemctl restart payara
            Take care,
            Virgile</bodyText>
            <closed>True</closed>
            <closedAt>2022-12-12T18:57:02Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: Harvesting</name>
              </nodes>
              <nodes>
                <name>NIH OTA DC</name>
              </nodes>
              <nodes>
                <name>pm.epic.nih_harvesting</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.2</name>
              </nodes>
              <totalCount>6</totalCount>
            </labels>
            <number>7940</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>[feature request] stop an harvest job in progress</title>
            <url>https://github.com/IQSS/dataverse/issues/7940</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Harvesting</name>
                </nodes>
                <nodes>
                  <name>NIH OTA DC</name>
                </nodes>
                <nodes>
                  <name>pm.epic.nih_harvesting</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.2</name>
                </nodes>
                <totalCount>6</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>[feature request] stop an harvest job in progress</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 1, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPA2E</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>There's already a "Securing Your Installation" section of Installation Guide at http://guides.dataverse.org/en/4.4/installation/config.html#securing-your-installation but its focus is installation time, not ongoing security.
            
            How should institutions who run Dataverse be alerted that they should upgrade as soon as possible to new versions of Dataverse that have security fixes?
            
            Both @Venki18 and @lwo have mentioned that perhaps there should be some sort of mailing list that they and others could subscribe to who are interested in security (I'm looking at you @donsizemore).
            
            Should the mailing list be "announce" style where people can't reply? This would be the Dataverse team sending security advisories. If the list is private, perhaps a pre-release announcement could be made that a security hole has been found and that a fix is being tested. This would give sysadmins a heads up that they should upgrade soon, once the release comes out.
            
            Should the mailing list be "discussion" style instead, where subscribers could privately share findings related to security, such as results from security scans? (These should absolutely be sent first to security@dataverse.org to open a private ticket as explained in [CONTRIBUTING.md](https://github.com/IQSS/dataverse/blob/develop/CONTRIBUTING.md) to start some tracking around the issue. This was originally [discussed](https://groups.google.com/forum/#!topic/dataverse-community/DhmMOdh_zHU) on the dataverse-community mailing list.)
            
            Should there be a page at http://dataverse.org dedicated to security that the Installation Guide links to? That's really what this issue is about... what resources to link to about ongoing security, how to subscribe to advisories, etc.
            
            First we need to decide if we should create any of the mailing lists or pages mentioned above. I'm sure others have ideas as well. Please leave comments here if you have any thoughts or suggestions!
            </body>
            <bodyText>There's already a "Securing Your Installation" section of Installation Guide at http://guides.dataverse.org/en/4.4/installation/config.html#securing-your-installation but its focus is installation time, not ongoing security.
            How should institutions who run Dataverse be alerted that they should upgrade as soon as possible to new versions of Dataverse that have security fixes?
            Both @Venki18 and @lwo have mentioned that perhaps there should be some sort of mailing list that they and others could subscribe to who are interested in security (I'm looking at you @donsizemore).
            Should the mailing list be "announce" style where people can't reply? This would be the Dataverse team sending security advisories. If the list is private, perhaps a pre-release announcement could be made that a security hole has been found and that a fix is being tested. This would give sysadmins a heads up that they should upgrade soon, once the release comes out.
            Should the mailing list be "discussion" style instead, where subscribers could privately share findings related to security, such as results from security scans? (These should absolutely be sent first to security@dataverse.org to open a private ticket as explained in CONTRIBUTING.md to start some tracking around the issue. This was originally discussed on the dataverse-community mailing list.)
            Should there be a page at http://dataverse.org dedicated to security that the Installation Guide links to? That's really what this issue is about... what resources to link to about ongoing security, how to subscribe to advisories, etc.
            First we need to decide if we should create any of the mailing lists or pages mentioned above. I'm sure others have ideas as well. Please leave comments here if you have any thoughts or suggestions!</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-03T20:11:59Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: Installation Guide</name>
              </nodes>
              <nodes>
                <name>postmortem</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>3215</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>"Securing Your Installation" section of Installation Guide could cover ongoing security, advisories, private discussion</title>
            <url>https://github.com/IQSS/dataverse/issues/3215</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Installation Guide</name>
                </nodes>
                <nodes>
                  <name>postmortem</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>"Securing Your Installation" section of Installation Guide could cover ongoing security, advisories, private discussion</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNX3s</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MTEw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MTAx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>sekmiller</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>A valid OAI request such as
            https://dataverse.unc.edu/oai?verb=ListIdentifiers&amp;set=census&amp;metadataPrefix=dc
            should return a response processable for OAI-PMH clients or HTTP 5XX.
            </body>
            <bodyText>A valid OAI request such as
            https://dataverse.unc.edu/oai?verb=ListIdentifiers&amp;set=census&amp;metadataPrefix=dc
            should return a response processable for OAI-PMH clients or HTTP 5XX.</bodyText>
            <closed>True</closed>
            <closedAt>2022-11-28T18:55:02Z</closedAt>
            <labels>
              <nodes>
                <name>Type: Bug</name>
              </nodes>
              <nodes>
                <name>Feature: Harvesting</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.2</name>
              </nodes>
              <totalCount>6</totalCount>
            </labels>
            <number>3797</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>OAI-PMH responses indicating errors should be processable by OAI-PMH clients</title>
            <url>https://github.com/IQSS/dataverse/issues/3797</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Type: Bug</name>
                </nodes>
                <nodes>
                  <name>Feature: Harvesting</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.2</name>
                </nodes>
                <totalCount>6</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.12.1</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>OAI-PMH responses indicating errors should be processable by OAI-PMH clients</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Pre December 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPAzU</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>sekmiller</login>
              </nodes>
              <nodes>
                <login>scolapasta</login>
              </nodes>
              <totalCount>2</totalCount>
            </assignees>
            <body>&lt;!--
            Thank you for contributing to the Dataverse Project through the creation of a bug report!
            
            WARNING: If this is a security issue it should be reported privately to security@dataverse.org
            
            More information on bug issues and contributions can be found in the "Contributing to Dataverse" page:
            https://github.com/IQSS/dataverse/blob/develop/CONTRIBUTING.md#bug-reportsissues
            
            Please fill out as much of the template as you can.
            Start below this comment section.
            --&gt;
            **What steps does it take to reproduce the issue?** With Primefaces 11 popups are responsive to changing the size of the browser (shrink to fit) Viewing certain popups in a narrowed browser window cuts off text rather than wrapping it.
            
            * When does this issue occur? One known popup where you can see this effect it the Access Popup which is shown to the dataset admin when they restrict a file. (screen shots are included below) there may be others.
            
            
            * Which page(s) does it occurs on? Access popup on the dataset page and edit files page
            
            
            * What happens? as described above. 
            
            
            * To whom does it occur (all users, curators, superusers)? curators and super users. general users would not see this popup
            
            
            * What did you expect to happen? we would like the info text to wrap so that all of it can be read, instead of "falling off the edge"
            
            
            
            **Which version of Dataverse are you using?** 5.10.1 dev
            
            
            
            **Any related open or closed issues to this bug report?** #8456 upgrade PrimeFaces
            
            
            **Screenshots:**
            Before narrowing the browser window:
            
            &lt;img width="751" alt="Screen Shot 2022-04-25 at 2 16 32 PM" src="https://user-images.githubusercontent.com/2364928/165530076-06f9b2ab-4dea-4aa0-b16a-dfb47b2987e4.png"&gt;
            
            After narrowing the browser window:
            
            &lt;img width="600" alt="Screen Shot 2022-04-25 at 2 16 47 PM" src="https://user-images.githubusercontent.com/2364928/165530144-91d5d71f-be12-4218-9309-f449ebeb1767.png"&gt;
            
            No matter the issue, screenshots are always welcome.
            
            To add a screenshot, please use one of the following formats and/or methods described here:
            
            * https://help.github.com/en/articles/file-attachments-on-issues-and-pull-requests
            *
            </body>
            <bodyText>What steps does it take to reproduce the issue? With Primefaces 11 popups are responsive to changing the size of the browser (shrink to fit) Viewing certain popups in a narrowed browser window cuts off text rather than wrapping it.
            
            
            When does this issue occur? One known popup where you can see this effect it the Access Popup which is shown to the dataset admin when they restrict a file. (screen shots are included below) there may be others.
            
            
            Which page(s) does it occurs on? Access popup on the dataset page and edit files page
            
            
            What happens? as described above.
            
            
            To whom does it occur (all users, curators, superusers)? curators and super users. general users would not see this popup
            
            
            What did you expect to happen? we would like the info text to wrap so that all of it can be read, instead of "falling off the edge"
            
            
            Which version of Dataverse are you using? 5.10.1 dev
            Any related open or closed issues to this bug report? #8456 upgrade PrimeFaces
            Screenshots:
            Before narrowing the browser window:
            
            After narrowing the browser window:
            
            No matter the issue, screenshots are always welcome.
            To add a screenshot, please use one of the following formats and/or methods described here:
            
            https://help.github.com/en/articles/file-attachments-on-issues-and-pull-requests</bodyText>
            <closed>True</closed>
            <closedAt>2022-11-02T17:30:00Z</closedAt>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>8656</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Popup text can be hidden under Primefaces 11</title>
            <url>https://github.com/IQSS/dataverse/issues/8656</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>2</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Popup text can be hidden under Primefaces 11</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Pre December 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNX3I</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-03-24T13:23:16Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>9426</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Payara 6 testing</title>
            <url>https://github.com/IQSS/dataverse/pull/9426</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Payara 6 testing</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Upgrades in Prep for DV6</name>
            </nodes>
            <totalCount>3</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFSpqA</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>As a "bklog: Deliverable" This is decomposed into smaller issues, grouped under [D: Payara 6 Upgrade](https://github.com/IQSS/dataverse/labels/D%3A%20Payara%206%20Upgrade)
            
            ---
            
            Hat tip to @poikilotherm who [posted][] in chat a link to a video in which Steve Millidge, founder of Payara, answered a question about how long Payara 5 Community Edition (which we recommend in the guides) will receive security patches: https://youtu.be/juD0XNNq344?t=1972
            
            [posted]: https://matrix.to/#/!AmypvmJtUjBesRrnLM:matrix.org/$YqXmiwT6hoyVLfyKuH7rQVKrOFFRHBGFoJqfXR-wjM0
            
            I've transcribed the question and answer:
            
            Q: "For the Community Edition, when will v5 stop getting security patches?"
            
            A: "Payara 5 in Community was basically... when we switch the main branch over to 6, which will be on the point of 6 release, then Community will march forward on Payara 6. So Payara 5 patches, if you like, will stop at that point through Community. So then it will be Enterprise where you'll get patches and security fixes for Payara 5. Payara Community essentially is a marching version so whenever the latest release is the latest release."
            
            I didn't watch the whole video but @poikilotherm says Payara plans to switch the main branch to 6 in Q2/2022.
            
            (By the way, #8064 is the issue where we're tracking the next 5.x upgrade from Payara. As of this writing we are advising installations to use Payara 5.2021.5: https://guides.dataverse.org/en/5.9/installation/prerequisites.html#payara )</body>
            <bodyText>As a "bklog: Deliverable" This is decomposed into smaller issues, grouped under D: Payara 6 Upgrade
            
            Hat tip to @poikilotherm who posted in chat a link to a video in which Steve Millidge, founder of Payara, answered a question about how long Payara 5 Community Edition (which we recommend in the guides) will receive security patches: https://youtu.be/juD0XNNq344?t=1972
            I've transcribed the question and answer:
            Q: "For the Community Edition, when will v5 stop getting security patches?"
            A: "Payara 5 in Community was basically... when we switch the main branch over to 6, which will be on the point of 6 release, then Community will march forward on Payara 6. So Payara 5 patches, if you like, will stop at that point through Community. So then it will be Enterprise where you'll get patches and security fixes for Payara 5. Payara Community essentially is a marching version so whenever the latest release is the latest release."
            I didn't watch the whole video but @poikilotherm says Payara plans to switch the main branch to 6 in Q2/2022.
            (By the way, #8064 is the issue where we're tracking the next 5.x upgrade from Payara. As of this writing we are advising installations to use Payara 5.2021.5: https://guides.dataverse.org/en/5.9/installation/prerequisites.html#payara )</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>bklog: Deliverable</name>
              </nodes>
              <nodes>
                <name>D: Payara 6 Upgrade</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>8305</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>bklog: Deliverable - Upgrade to Payara 6 and from EE 8 to EE 10 (end of Payara 5 Community Edition security patches Q2/2022)</title>
            <url>https://github.com/IQSS/dataverse/issues/8305</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>bklog: Deliverable</name>
                </nodes>
                <nodes>
                  <name>D: Payara 6 Upgrade</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>2</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>bklog: Deliverable - Upgrade to Payara 6 and from EE 8 to EE 10 (end of Payara 5 Community Edition security patches Q2/2022)</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Upgrades in Prep for DV6</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEwBGE</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8305</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Code Infrastructure</name>
              </nodes>
              <nodes>
                <name>Feature: Installer</name>
              </nodes>
              <nodes>
                <name>Feature: Installation Guide</name>
              </nodes>
              <nodes>
                <name>D: Payara 6 Upgrade</name>
              </nodes>
              <nodes>
                <name>Size: Queued</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>9116</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>8305 Upgrade to Jakarta EE 10 and Payara 6</title>
            <url>https://github.com/IQSS/dataverse/pull/9116</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Code Infrastructure</name>
                </nodes>
                <nodes>
                  <name>Feature: Installer</name>
                </nodes>
                <nodes>
                  <name>Feature: Installation Guide</name>
                </nodes>
                <nodes>
                  <name>D: Payara 6 Upgrade</name>
                </nodes>
                <nodes>
                  <name>Size: Queued</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>8305 Upgrade to Jakarta EE 10 and Payara 6</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Upgrades in Prep for DV6</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDO5cU</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-11-30T18:51:53Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8937</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>9026</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>GDCC/Harvesting server it test failing</title>
            <url>https://github.com/IQSS/dataverse/pull/9026</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>GDCC/Harvesting server it test failing</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Pre December 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNnM0</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>qqmyers</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>**Overview of the Feature Request**
            Harvard is interested in extending current Globus functionality in two ways:
            
            - Simplify/support the process of referencing a file(s) on a remote endpoint. Nominally this is possible now via the RemoteOverlay store, but there is no support for selecting an endpoint and adding all of the individual files at that endpoint or, optionally, selecting which files within an endpoint should be in the dataset.
            - Provide better support for endpoints over tape stores. Tape storage would already have a posix/file endpoint, so adding an S3 endpoint is extra work. Further since tape stores can have delays in retrieving files, Dataverse's internal requests for files (i.e. for thumbnails, ingest, mime determination, read/write of aux files, downloads via S3 (which are still enabled now along side the ability to transfer out via Globus) could all have trouble.
            
            This Issue/task is to create a requirements/design document that will flesh out these issues and propose design ideas for how to meet the requirements. Community input will be requested. The output will be used to decide future work.
            </body>
            <bodyText>Overview of the Feature Request
            Harvard is interested in extending current Globus functionality in two ways:
            
            Simplify/support the process of referencing a file(s) on a remote endpoint. Nominally this is possible now via the RemoteOverlay store, but there is no support for selecting an endpoint and adding all of the individual files at that endpoint or, optionally, selecting which files within an endpoint should be in the dataset.
            Provide better support for endpoints over tape stores. Tape storage would already have a posix/file endpoint, so adding an S3 endpoint is extra work. Further since tape stores can have delays in retrieving files, Dataverse's internal requests for files (i.e. for thumbnails, ingest, mime determination, read/write of aux files, downloads via S3 (which are still enabled now along side the ability to transfer out via Globus) could all have trouble.
            
            This Issue/task is to create a requirements/design document that will flesh out these issues and propose design ideas for how to meet the requirements. Community input will be requested. The output will be used to decide future work.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>NIH OTA: 1.1.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.1.1</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9123</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Enhance Globus support for remote endpoints and tape stores</title>
            <url>https://github.com/IQSS/dataverse/issues/9123</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>NIH OTA: 1.1.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.1.1</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Enhance Globus support for remote endpoints and tape stores</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>NIH bklog items (Stefano)</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDQBHg</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>This is a followup issue for IQSS/dataverse#8372 (PR IQSS/dataverse#8753). 
            Once that is merged we can proceed cleaning up and refactoring the remaining old OAI code. 
            Some of that code predates Dataverse and was copy-and-pasted from the implementation in DVN. 
            In the process it created in some extra layers of code that duplicate each other, and should probably be significantly simplified. (That is on top of a significant amount of old code that we used to maintain on the Dataverse side, but got rid of in Step. 1 when switching to the new gdcc/xoai library). 
            Major pieces: 
            - Server: the object implementing XOAI "items" (DataverseXoaiItem) acts as a wrapper around the entity class storing the record in the database (OAIRecord). The XOAI items should instead implement both. There's a similar situation with the Set objects. 
            - Client: OaiHandler may not be necessary/may be duplicating the functionality provided by the XOAI library; should be possible to further streamline the implementation.
            
            Aside from that, the overall code needs to be cleaned up and modernized. 
            </body>
            <bodyText>This is a followup issue for #8372 (PR #8753).
            Once that is merged we can proceed cleaning up and refactoring the remaining old OAI code.
            Some of that code predates Dataverse and was copy-and-pasted from the implementation in DVN.
            In the process it created in some extra layers of code that duplicate each other, and should probably be significantly simplified. (That is on top of a significant amount of old code that we used to maintain on the Dataverse side, but got rid of in Step. 1 when switching to the new gdcc/xoai library).
            Major pieces:
            
            Server: the object implementing XOAI "items" (DataverseXoaiItem) acts as a wrapper around the entity class storing the record in the database (OAIRecord). The XOAI items should instead implement both. There's a similar situation with the Set objects.
            Client: OaiHandler may not be necessary/may be duplicating the functionality provided by the XOAI library; should be possible to further streamline the implementation.
            
            Aside from that, the overall code needs to be cleaned up and modernized.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Feature: Harvesting</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.4.1</name>
              </nodes>
              <nodes>
                <name>Size: Queued</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>8842</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Refactor the OAI code, Step 2</title>
            <url>https://github.com/IQSS/dataverse/issues/8842</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Harvesting</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.4.1</name>
                </nodes>
                <nodes>
                  <name>Size: Queued</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Refactor the OAI code, Step 2</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>NIH bklog items (Stefano)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPA5g</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>pdurbin</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>GeoJSON is not included specifically as a tool in the "file previewers" page of the guide, but it should be.
            
            </body>
            <bodyText>GeoJSON is not included specifically as a tool in the "file previewers" page of the guide, but it should be.</bodyText>
            <closed>True</closed>
            <closedAt>2023-02-10T16:24:30Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: Developer Guide</name>
              </nodes>
              <nodes>
                <name>Feature: Admin Guide</name>
              </nodes>
              <nodes>
                <name>Feature: User Guide</name>
              </nodes>
              <nodes>
                <name>Feature: External Tool</name>
              </nodes>
              <nodes>
                <name>Feature: Geospatial</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>6</totalCount>
            </labels>
            <number>8984</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Update GUIDE to include GeoJSON</title>
            <url>https://github.com/IQSS/dataverse/issues/8984</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Developer Guide</name>
                </nodes>
                <nodes>
                  <name>Feature: Admin Guide</name>
                </nodes>
                <nodes>
                  <name>Feature: User Guide</name>
                </nodes>
                <nodes>
                  <name>Feature: External Tool</name>
                </nodes>
                <nodes>
                  <name>Feature: Geospatial</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>6</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Update GUIDE to include GeoJSON</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEXba0</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>When I log in and have access to the file, this issue is not visible.
            
            Dataset for example: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/AJHKU6
            
            &lt;img width="2348" alt="Screen Shot 2021-05-07 at 4 17 24 PM" src="https://user-images.githubusercontent.com/8322346/117506964-70d43080-af54-11eb-8d4b-bb93e4f3a487.png"&gt;
            
            </body>
            <bodyText>When I log in and have access to the file, this issue is not visible.
            Dataset for example: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/AJHKU6</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-19T16:30:13Z</closedAt>
            <labels>
              <nodes>
                <name>bug</name>
              </nodes>
              <nodes>
                <name>enhancement</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>110</number>
            <repository>
              <name>dataverse.harvard.edu</name>
            </repository>
            <title>file tab display of image for "restricted file" is cluttered when not logged in for access</title>
            <url>https://github.com/IQSS/dataverse.harvard.edu/issues/110</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNzQwNTY1NTE=</id>
                <name>dataverse.harvard.edu</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>bug</name>
                </nodes>
                <nodes>
                  <name>enhancement</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>file tab display of image for "restricted file" is cluttered when not logged in for access</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 11, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Harvard Dataverse Instance (Sonia)</text>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgD1cao</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MTIw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MTEx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>While reviewing the "Anonymous Private URL" feature (https://github.com/IQSS/dataverse/issues/1724), members of the Harvard Dataverse Repository curation team saw that some researchers were unsure of the difference between the "Private URL" and the "Anonymous Private URL". In particular, one or more researchers weren't sure if the feature would let them share an anonymized version of the data in a dataset's data files.
            
            The feature only removes from the page dataset metadata that the repository administrators have decided could reveal the dataset author's identity. The User Guides [mention this (item 4)](https://guides.dataverse.org/en/5.7/user/dataset-management.html#private-url-to-review-unpublished-dataset), and the popup includes a link that points to that section of the User Guides.
            
            But it's unclear if most users will click on that link or if that User Guide section makes the purpose of the Anonymous Private URL clear enough.</body>
            <bodyText>While reviewing the "Anonymous Private URL" feature (#1724), members of the Harvard Dataverse Repository curation team saw that some researchers were unsure of the difference between the "Private URL" and the "Anonymous Private URL". In particular, one or more researchers weren't sure if the feature would let them share an anonymized version of the data in a dataset's data files.
            The feature only removes from the page dataset metadata that the repository administrators have decided could reveal the dataset author's identity. The User Guides mention this (item 4), and the popup includes a link that points to that section of the User Guides.
            But it's unclear if most users will click on that link or if that User Guide section makes the purpose of the Anonymous Private URL clear enough.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Status: UX &amp; UI</name>
              </nodes>
              <nodes>
                <name>Size: Queued</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>8185</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Some researchers unsure of difference between "Private URL" and "Anonymous Private URL"</title>
            <url>https://github.com/IQSS/dataverse/issues/8185</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Status: UX &amp; UI</name>
                </nodes>
                <nodes>
                  <name>Size: Queued</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Some researchers unsure of difference between "Private URL" and "Anonymous Private URL"</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Harvard Dataverse Instance (Sonia)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDRr8A</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/2USIUM
            
            This dataset "versions" tab load page is taking approximately 50 seconds. There are 73 versions at this time with plans for continued versioning. </body>
            <bodyText>https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/2USIUM
            This dataset "versions" tab load page is taking approximately 50 seconds. There are 73 versions at this time with plans for continued versioning.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Type: Feature</name>
              </nodes>
              <nodes>
                <name>Type: Bug</name>
              </nodes>
              <nodes>
                <name>Feature: Publishing &amp; Versions</name>
              </nodes>
              <nodes>
                <name>Size: Queued</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>8328</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>versioning: optimize load time for dataset with multiple versions</title>
            <url>https://github.com/IQSS/dataverse/issues/8328</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Type: Feature</name>
                </nodes>
                <nodes>
                  <name>Type: Bug</name>
                </nodes>
                <nodes>
                  <name>Feature: Publishing &amp; Versions</name>
                </nodes>
                <nodes>
                  <name>Size: Queued</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>versioning: optimize load time for dataset with multiple versions</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Harvard Dataverse Instance (Sonia)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDU9A0</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>We recently re registered Harvard Dataverse as a DataCite service provider for 2023 and they sent us a badge. Stefano suggested adding it to the site, and Julian suggested on the home page footer. (Details to be worked out with Julian)
            
            This zip contains what they sent:
            [datacite_service_provider_badge.zip](https://github.com/IQSS/dataverse.harvard.edu/files/10512502/datacite_service_provider_badge.zip)
            
            
            The zip contains the badge in two different colors and two different formats:
            
            ![DataCite-Logos_DC badge_ServiceProvider_grey](https://user-images.githubusercontent.com/4268292/214924738-a14a1141-b4ab-4a01-b4a1-995b2cdca9e5.png)
            
            ![DataCite-Logos_DC badge_ServiceProvider](https://user-images.githubusercontent.com/4268292/214924888-30d81fc1-78de-4ded-8e3c-32f2cf704c60.png)
            
            ![DataCite-Logos_DC badge_ServiceProvider_grey](https://user-images.githubusercontent.com/4268292/214925286-50de6fc7-012a-45b3-a59f-45a8abb87a37.svg)
            
            ![DataCite-Logos_DC badge_ServiceProvider](https://user-images.githubusercontent.com/4268292/214925318-a98f0258-cf05-4d94-aa66-e3a0b9de3101.svg)
            
            </body>
            <bodyText>We recently re registered Harvard Dataverse as a DataCite service provider for 2023 and they sent us a badge. Stefano suggested adding it to the site, and Julian suggested on the home page footer. (Details to be worked out with Julian)
            This zip contains what they sent:
            datacite_service_provider_badge.zip
            The zip contains the badge in two different colors and two different formats:</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>210</number>
            <repository>
              <name>dataverse.harvard.edu</name>
            </repository>
            <title>Add Badge for DataCite registration provider</title>
            <url>https://github.com/IQSS/dataverse.harvard.edu/issues/210</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNzQwNTY1NTE=</id>
                <name>dataverse.harvard.edu</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add Badge for DataCite registration provider</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEh5Xc</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>The Harvard Dataverse Model for supporting file-level DOIs will support collection level instead of production-wide file-level PIDs.
            This requires the ability to enable file-level PIDs at the collection level. Eventually, we may discuss enabling at dataset level, if needed.
            --&gt;
            
            **Overview of the Feature Request**
            
            
            **What kind of user is the feature intended for?**
            SUPERUSER/INSTALLATION ADMIN
            
            
            **What inspired the request?**
            THE COST OF PROVIDING FILE LEVEL PIDs FOR GENERALIST, OPEN REPOSITORIES
            
            **What existing behavior do you want changed?**
            MANAGED FILE LEVEL PIDs distribution
            
            **Any brand new behavior do you want to add to Dataverse?**
            
            
            **Any related open or closed issues to this feature request?**
            NO
            
            @scolapasta </body>
            <bodyText>The Harvard Dataverse Model for supporting file-level DOIs will support collection level instead of production-wide file-level PIDs.
            This requires the ability to enable file-level PIDs at the collection level. Eventually, we may discuss enabling at dataset level, if needed.
            --&gt;
            Overview of the Feature Request
            What kind of user is the feature intended for?
            SUPERUSER/INSTALLATION ADMIN
            What inspired the request?
            THE COST OF PROVIDING FILE LEVEL PIDs FOR GENERALIST, OPEN REPOSITORIES
            What existing behavior do you want changed?
            MANAGED FILE LEVEL PIDs distribution
            Any brand new behavior do you want to add to Dataverse?
            Any related open or closed issues to this feature request?
            NO
            @scolapasta</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Feature: DOI &amp; Handle</name>
              </nodes>
              <nodes>
                <name>Size: 80</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>8889</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Feature Request: Enable file PIDs at Dataverse Collection Level</title>
            <url>https://github.com/IQSS/dataverse/issues/8889</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: DOI &amp; Handle</name>
                </nodes>
                <nodes>
                  <name>Size: 80</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Feature Request: Enable file PIDs at Dataverse Collection Level</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTeE</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-11-04T22:01:41Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>7527</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>7631</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>7527 redetect api error</title>
            <url>https://github.com/IQSS/dataverse/pull/7631</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>2</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>1</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>7527 redetect api error</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Pre December 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTj8</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-02-01T23:17:09Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8957</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>hdc</name>
              </nodes>
              <nodes>
                <name>3a</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>8958</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/8957 JWT creation test for DRS Archiver</title>
            <url>https://github.com/IQSS/dataverse/pull/8958</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>hdc</name>
                </nodes>
                <nodes>
                  <name>3a</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/8957 JWT creation test for DRS Archiver</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>External Commitments (Jim)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTd0</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-02-02T16:28:05Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9020</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9061</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/9020- Fix for Update current version issue when a file is the dataset thumb</title>
            <url>https://github.com/IQSS/dataverse/pull/9061</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/9020- Fix for Update current version issue when a file is the dataset thumb</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTcw</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>Has been observed a couple of times on Jenkins since the PR #9227 was merged. Meaning, it's intermittent, the test passes on most runs. 
            The error happens in the new test that's somewhat extensive and runs a real harvest of an external archive. However, the 500 below happens before anything heavy is attempted, merely when creating the new harvesting client: 
            ```
            java.lang.AssertionError: expected:201 but was:500
            at edu.harvard.iq.dataverse.api.HarvestingClientsIT.testHarvestingClientRun(HarvestingClients0T.java:184)
            ```
            which is really a cheapest operation you can think of. This makes me think that this is another weird timing condition caused by an overall load of a full restassured run on the system. I expect it to be straightforward to fix/work around. </body>
            <bodyText>Has been observed a couple of times on Jenkins since the PR #9227 was merged. Meaning, it's intermittent, the test passes on most runs.
            The error happens in the new test that's somewhat extensive and runs a real harvest of an external archive. However, the 500 below happens before anything heavy is attempted, merely when creating the new harvesting client:
            java.lang.AssertionError: expected:201 but was:500
            at edu.harvard.iq.dataverse.api.HarvestingClientsIT.testHarvestingClientRun(HarvestingClients0T.java:184)
            
            which is really a cheapest operation you can think of. This makes me think that this is another weird timing condition caused by an overall load of a full restassured run on the system. I expect it to be straightforward to fix/work around.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>NIH OTA: 1.4.1</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.1</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>9240</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Intermittent error from the new Harvesting Clients test </title>
            <url>https://github.com/IQSS/dataverse/issues/9240</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>NIH OTA: 1.4.1</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.1</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Intermittent error from the new Harvesting Clients test </text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEgRmM</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>We have merged the PR #9310 without waiting for the official, final 5.0.0 release of XOAI. So our develop branch is currently being built with develop, 5.0.0-SNAPSHOT versions of it. Once the release is made, a quick PR will need to be made updating the version number in modules/dataverse-parent/pom.xml. So I'm opening this issue to keep track of that/make sure we remember to do this. 
            
            It would be nice, to have this done before 5.13. But, thinking about it, it's NOT going to be a problem in any practical way, if we build and release from the develop branch as is, with the snapshots either. So this should not be considered a blocker or especially urgent.
            
            On the XOAI side, this is tracked in https://github.com/gdcc/xoai/issues/59.</body>
            <bodyText>We have merged the PR #9310 without waiting for the official, final 5.0.0 release of XOAI. So our develop branch is currently being built with develop, 5.0.0-SNAPSHOT versions of it. Once the release is made, a quick PR will need to be made updating the version number in modules/dataverse-parent/pom.xml. So I'm opening this issue to keep track of that/make sure we remember to do this.
            It would be nice, to have this done before 5.13. But, thinking about it, it's NOT going to be a problem in any practical way, if we build and release from the develop branch as is, with the snapshots either. So this should not be considered a blocker or especially urgent.
            On the XOAI side, this is tracked in gdcc/xoai#59.</bodyText>
            <closed>True</closed>
            <closedAt>2023-02-01T21:52:18Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9339</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Update Dataverse pom file to build with the 5.0.0 release of XOAI library</title>
            <url>https://github.com/IQSS/dataverse/issues/9339</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Update Dataverse pom file to build with the 5.0.0 release of XOAI library</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEjA8A</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>**Overview of the Feature Request**
            
            
            **What kind of user is the feature intended for?**
            API User, Curator, Superuser, Sysadmin
            
            
            **What inspired the request?**
            Noticing that after the multiple license update (v.5.10) was applied to the Harvard Dataverse Repository, some datasets have been published using the Dataverse APIs without a license (CC0 is the only one available in the dropdown for now) and with nothing entered in the Terms of Use field.
            
            The GUI enforces the requirement to choose a license from the License/Data Use Agreement dropdown or enter something in the Terms of Use field, in order to ensure that the metadata includes some information that makes explicit how the data can be used, but the API doesn't enforce this requirement.
            
            **What existing behavior do you want changed?**
            Depositors publishing datasets using the APIs must include a license or add something in the Terms of Use field, to match the rules enforced by the GUI.
            
            **Any related open or closed issues to this feature request?**
            https://github.com/IQSS/dataverse/issues/7440</body>
            <bodyText>Overview of the Feature Request
            What kind of user is the feature intended for?
            API User, Curator, Superuser, Sysadmin
            What inspired the request?
            Noticing that after the multiple license update (v.5.10) was applied to the Harvard Dataverse Repository, some datasets have been published using the Dataverse APIs without a license (CC0 is the only one available in the dropdown for now) and with nothing entered in the Terms of Use field.
            The GUI enforces the requirement to choose a license from the License/Data Use Agreement dropdown or enter something in the Terms of Use field, in order to ensure that the metadata includes some information that makes explicit how the data can be used, but the API doesn't enforce this requirement.
            What existing behavior do you want changed?
            Depositors publishing datasets using the APIs must include a license or add something in the Terms of Use field, to match the rules enforced by the GUI.
            Any related open or closed issues to this feature request?
            #7440</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Feature: API</name>
              </nodes>
              <nodes>
                <name>Feature: Terms &amp; Licensing</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>9148</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Feature Request/Idea: As a curator or collection manager, I'd like to ensure that datasets published using the Dataverse APIs include a license or have Terms of Use</title>
            <url>https://github.com/IQSS/dataverse/issues/9148</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: API</name>
                </nodes>
                <nodes>
                  <name>Feature: Terms &amp; Licensing</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Feature Request/Idea: As a curator or collection manager, I'd like to ensure that datasets published using the Dataverse APIs include a license or have Terms of Use</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDU-iA</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MTMw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MTIx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-11-02T13:16:34Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8305</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>8774</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Upgrade from Payara 5 to 6</title>
            <url>https://github.com/IQSS/dataverse/pull/8774</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Upgrade from Payara 5 to 6</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Pre December 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTjg</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>This README is for the Dataverse "Community Backlog" column at https://github.com/orgs/IQSS/projects/34/views/1
            
            (We are also working on a customized view of just this column at https://github.com/orgs/IQSS/projects/34/views/6 .)
            
            Please note the funnel in the diagram below:
            
            &lt;img width="2560" alt="Screen Shot 2022-11-02 at 9 47 35 PM" src="https://user-images.githubusercontent.com/21006/199633769-5150da95-90ce-48fd-bc08-ddbe73307ccd.png"&gt;
            
            You, the community, are the stakeholders. You are opening issues and pull requests of various size (effort) and value ($$). Thank you! The feedback is a gift and we love code! 😄 
            
            I'm listening to you and making recommendations on what should go into the the backlog (the funnel) and (sadly) what should probably not. 👍 👎 
            
            Note that issues and pull requests are broken down into smaller sizes as they go through the funnel.
            
            (By the way, not pictured are all the other funnels that also lead to the dev team. Many of these funnels contain grant deliverables that get priority. 🤔 )
            
            If my recommendations are approved, the issues and pull requests will go to the dev team (which includes me) to be coded up or reviewed or tweaked, and eventually merged and released. 🎉 🚀  That's the goal anyway.
            
            As releases go out to you, the stakeholders, you'll get additional ideas and write more code, allowing the cycle to continue. 🎉 🚀 
            
            As show in the diagram, we all should communicate throughout this adventure. Let's all talk in real time (timezones permitting) at https://chat.dataverse.org or asynchronously on Dataverse mailing list at https://groups.google.com/g/dataverse-community 🐱 💬 🐶 💬  
            
            At the moment, the [Community Backlog](https://github.com/orgs/IQSS/projects/34/views/1) column is mostly full of pull requests rather than issues. This is because we have many open pull requests (77 as of this writing) and I feel that we should make a decision about them. Move them forward or close them. I've put smaller pull requests that I think provide good value at the top of the column. Large, thorny pull requests are not at the top. 😄 Again, let's keep talking! This process is brand new.
            
            p.s. The diagram above comes from an absolutely fabulous video called [Agile Product Ownership in a Nutshell](https://blog.crisp.se/2012/10/25/henrikkniberg/agile-product-ownership-in-a-nutshell) by Henrik Kniberg. I highly recommend watching it!</body>
            <bodyText>This README is for the Dataverse "Community Backlog" column at https://github.com/orgs/IQSS/projects/34/views/1
            (We are also working on a customized view of just this column at https://github.com/orgs/IQSS/projects/34/views/6 .)
            Please note the funnel in the diagram below:
            
            You, the community, are the stakeholders. You are opening issues and pull requests of various size (effort) and value ($$). Thank you! The feedback is a gift and we love code! 😄
            I'm listening to you and making recommendations on what should go into the the backlog (the funnel) and (sadly) what should probably not. 👍 👎
            Note that issues and pull requests are broken down into smaller sizes as they go through the funnel.
            (By the way, not pictured are all the other funnels that also lead to the dev team. Many of these funnels contain grant deliverables that get priority. 🤔 )
            If my recommendations are approved, the issues and pull requests will go to the dev team (which includes me) to be coded up or reviewed or tweaked, and eventually merged and released. 🎉 🚀  That's the goal anyway.
            As releases go out to you, the stakeholders, you'll get additional ideas and write more code, allowing the cycle to continue. 🎉 🚀
            As show in the diagram, we all should communicate throughout this adventure. Let's all talk in real time (timezones permitting) at https://chat.dataverse.org or asynchronously on Dataverse mailing list at https://groups.google.com/g/dataverse-community 🐱 💬 🐶 💬
            At the moment, the Community Backlog column is mostly full of pull requests rather than issues. This is because we have many open pull requests (77 as of this writing) and I feel that we should make a decision about them. Move them forward or close them. I've put smaller pull requests that I think provide good value at the top of the column. Large, thorny pull requests are not at the top. 😄 Again, let's keep talking! This process is brand new.
            p.s. The diagram above comes from an absolutely fabulous video called Agile Product Ownership in a Nutshell by Henrik Kniberg. I highly recommend watching it!</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>68</number>
            <repository>
              <name>dataverse.org</name>
            </repository>
            <title>README for the Dataverse Community Backlog</title>
            <url>https://github.com/IQSS/dataverse.org/issues/68</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkyNDcyMjc2MQ==</id>
                <name>dataverse.org</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>README for the Dataverse Community Backlog</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>3</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPbg8</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9488</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Internationalization</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9493</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>9488 internationlization issues</title>
            <url>https://github.com/IQSS/dataverse/pull/9493</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Internationalization</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>9488 internationlization issues</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgF623M</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>As a "bklog: Deliverable" This is decomposed into smaller issues.
            - Each of the smaller issues gets the label "[D: ImproveJsonValidation](https://github.com/IQSS/dataverse/labels/D%3A%20ImproveJsonValidation)".  
            - This issue, the only issue to have both labels (bklog: Deliverable, D: ImproveJsonValidation), will stay in the Dataverse_Global_Backlog project forever.
            - It will stay in it's present column until the team feels like the issue has no smaller issues that need need to be broken off in order to resolve this issue
            - At that point, this issue stays in the Dataverse_Global_backlog, but changes it's status to: "Clear of the Backlog"
            
            ---
            
            This is related to AUSSDA/pyDataverse#48 and to `dvcli` as a CLI tool for Dataverse. (Tagging @skasberger here)
            On the Dataverse side of life, this is related to all mighty IQSS/dataverse#6030 and loosley coupled to IQSS/dataverse#4451 (which might make the creation of the schema easier).
            
            When creating a new dataset via the web UI, you will be provided with a nice interface and validation before a dataset is created. What is required, what is available as a field, etc is nicely integrated into the UI both for users and curators.
            
            However, this is not the case with uploading new datasets via API. Before you send a JSON representation, there is not possibility to validate the dataset in terms of metadata schemas, required fields, etc.
            
            It would be nice to provide an API endpoint to retrieve a [JSON Schema](https://json-schema.org/) for a given Dataverse, that contains precise constraints and requirements, what your dataset JSON has to look like and what other fields might be available.
            
            This is useful not only for pre-creation validation, but also for automatic creation of options on command lines (think autocompletion, ncurses interfaces, ...) or [client-side forms](https://json-schema.org/implementations.html#web-ui-generation).</body>
            <bodyText>As a "bklog: Deliverable" This is decomposed into smaller issues.
            
            Each of the smaller issues gets the label "D: ImproveJsonValidation".
            This issue, the only issue to have both labels (bklog: Deliverable, D: ImproveJsonValidation), will stay in the Dataverse_Global_Backlog project forever.
            It will stay in it's present column until the team feels like the issue has no smaller issues that need need to be broken off in order to resolve this issue
            At that point, this issue stays in the Dataverse_Global_backlog, but changes it's status to: "Clear of the Backlog"
            
            
            This is related to AUSSDA/pyDataverse#48 and to dvcli as a CLI tool for Dataverse. (Tagging @skasberger here)
            On the Dataverse side of life, this is related to all mighty IQSS/dataverse#6030 and loosley coupled to IQSS/dataverse#4451 (which might make the creation of the schema easier).
            When creating a new dataset via the web UI, you will be provided with a nice interface and validation before a dataset is created. What is required, what is available as a field, etc is nicely integrated into the UI both for users and curators.
            However, this is not the case with uploading new datasets via API. Before you send a JSON representation, there is not possibility to validate the dataset in terms of metadata schemas, required fields, etc.
            It would be nice to provide an API endpoint to retrieve a JSON Schema for a given Dataverse, that contains precise constraints and requirements, what your dataset JSON has to look like and what other fields might be available.
            This is useful not only for pre-creation validation, but also for automatic creation of options on command lines (think autocompletion, ncurses interfaces, ...) or client-side forms.</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-27T18:41:29Z</closedAt>
            <labels>
              <nodes>
                <name>D: ImproveJsonValidation</name>
              </nodes>
              <nodes>
                <name>bklog: Deliverable</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>26</number>
            <repository>
              <name>dataverse-pm</name>
            </repository>
            <title>bklog: Deliverable - As a system integrator, I would appreciate a JSON Schema for validating my dataset JSON before uploading via API</title>
            <url>https://github.com/IQSS/dataverse-pm/issues/26</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOIwMRzQ</id>
                <name>dataverse-pm</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>D: ImproveJsonValidation</name>
                </nodes>
                <nodes>
                  <name>bklog: Deliverable</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>bklog: Deliverable - As a system integrator, I would appreciate a JSON Schema for validating my dataset JSON before uploading via API</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>HERMES (Oliver)</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Not-In-This-List</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDyp34</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-02-06T20:34:35Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9224</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>HERMES</name>
              </nodes>
              <nodes>
                <name>hdc</name>
              </nodes>
              <nodes>
                <name>2</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>9225</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>9224 - revert workflow metadata block in Solr schema</title>
            <url>https://github.com/IQSS/dataverse/pull/9225</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>HERMES</name>
                </nodes>
                <nodes>
                  <name>hdc</name>
                </nodes>
                <nodes>
                  <name>2</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>9224 - revert workflow metadata block in Solr schema</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgD4phc</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-03-10T14:42:02Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Admin Guide</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9395</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Add GitLab, iRODS, and RedCap (via rdm-integrations) to "Getting Data In" documentation (list of integrations) and as a GUI uploader</title>
            <url>https://github.com/IQSS/dataverse/pull/9395</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Admin Guide</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add GitLab, iRODS, and RedCap (via rdm-integrations) to "Getting Data In" documentation (list of integrations) and as a GUI uploader</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Community Backlog (Phil)</text>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFAUPA</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9394</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Internationalization</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9451</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Replaced hard coded strings in File Access button by new Bundle properties</title>
            <url>https://github.com/IQSS/dataverse/pull/9451</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Internationalization</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Replaced hard coded strings in File Access button by new Bundle properties</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFhC8U</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9404</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Search/Browse</name>
              </nodes>
              <nodes>
                <name>Feature: Internationalization</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>9406</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>#9404 Added Harvesting key to customize facet label</title>
            <url>https://github.com/IQSS/dataverse/pull/9406</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Search/Browse</name>
                </nodes>
                <nodes>
                  <name>Feature: Internationalization</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>#9404 Added Harvesting key to customize facet label</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFJKHU</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9428</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>9440</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>9428 alternative title</title>
            <url>https://github.com/IQSS/dataverse/pull/9440</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>9428 alternative title</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>3</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgF6ghs</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9398</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Metadata</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9399</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>#9398 - fixing issues with metadata language inherited option label</title>
            <url>https://github.com/IQSS/dataverse/pull/9399</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Metadata</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>#9398 - fixing issues with metadata language inherited option label</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFARxw</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <pageInfo>
          <endCursor>MTQw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MTMx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9378</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Update native-api.rst</title>
            <url>https://github.com/IQSS/dataverse/pull/9378</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Update native-api.rst</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFvCw0</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Terms &amp; Licensing</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9302</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>add custom license for France to the Dataverse Doc</title>
            <url>https://github.com/IQSS/dataverse/pull/9302</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Terms &amp; Licensing</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>2</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>add custom license for France to the Dataverse Doc</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEuT6o</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8512</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: Queued</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9262</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>8512 standardize license configuration</title>
            <url>https://github.com/IQSS/dataverse/pull/9262</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: Queued</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>8512 standardize license configuration</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEKRMQ</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-03-28T22:52:21Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>3913</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: API</name>
              </nodes>
              <nodes>
                <name>Feature: File Upload &amp; Handling</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>9383</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Support for deleting files using native API</title>
            <url>https://github.com/IQSS/dataverse/pull/9383</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: API</name>
                </nodes>
                <nodes>
                  <name>Feature: File Upload &amp; Handling</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Support for deleting files using native API</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Community Backlog (Phil)</text>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgE0dq8</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8573</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Account &amp; User Info</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9461</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>8573 Add Shib attribute characterset conversion to getValueFromAssertion</title>
            <url>https://github.com/IQSS/dataverse/pull/9461</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Account &amp; User Info</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>8573 Add Shib attribute characterset conversion to getValueFromAssertion</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFvC_U</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: Queued</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>8357</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>issue #5277: first implementation step for exporting related publicat…</title>
            <url>https://github.com/IQSS/dataverse/pull/8357</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>2</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: Queued</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>issue #5277: first implementation step for exporting related publicat…</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNX3g</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8739</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>9013</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Harvest: map publisher tag to distributorName</title>
            <url>https://github.com/IQSS/dataverse/pull/9013</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Harvest: map publisher tag to distributorName</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>3</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTc8</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>8982</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>GitHub Workflows security hardening</title>
            <url>https://github.com/IQSS/dataverse/pull/8982</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>1</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>GitHub Workflows security hardening</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTdc</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>Short version: "Harvested files" are currently stored as DvObject/DataFile/FileMetadata/etc. entities, just like "real" files. I don't think they should be handled so. 
            
            (I feel like I have a memory of opening an issue for this, but looks like I never did - ?)
            
            History: "Harvested Files" are created locally when a Harvesting client imports DDI or native JSON dataset metadata records with file entries from other Dataverses (DC format does not have a mechanism for encoding files or any kinds of child objects). The reason they become DataFiles/DvObjects is a throwback to or legacy of the old implementation in DVN v2-3. Back then they were treated as actual files - users could download them locally; they stored the remote location (url) in place of the physical file name, and DVN would make an HTTP call to get and proxy the content, transparently to the user. We abandoned that scheme as overly complicated (the problem with authentication was never fully resolved, among other things). So in the current scheme these "files" are used *only for indexing*. We still attempt to store a link to the remote object (as the `storageidentifier` of the DvObject), but it is never used practically. When search hits for harvested files are displayed, no attempt is made to redirect the user specifically to that file - clicking on the card always sends them to the remote location of the dataset to which the file belongs. This really doesn't justify maintaining the same DvObject hierarchy of entities as for "real" files, IMO. 
            
            The concept of a "remote file", something that transparently appears as a DataFile to the local user, with the byte content stored elsewhere/remotely, is now being revisited (#7324). Once we have that, we may consider, as an optional/configurable harvesting feature, being able to turn harvested files into these "remotely stored" files locally. But when harvesting file records solely for indexing, I believe we should instead introduce some "HarvestedFileMetadata" entity for storing them. 
            
            
            **Definition of done:**
            - [ ] discuss during a tech hour.
            - [ ] decide whether to move forward on this.
              - [ ] if we decide to implement this, create the corresponding issues that are associated with it.
            </body>
            <bodyText>Short version: "Harvested files" are currently stored as DvObject/DataFile/FileMetadata/etc. entities, just like "real" files. I don't think they should be handled so.
            (I feel like I have a memory of opening an issue for this, but looks like I never did - ?)
            History: "Harvested Files" are created locally when a Harvesting client imports DDI or native JSON dataset metadata records with file entries from other Dataverses (DC format does not have a mechanism for encoding files or any kinds of child objects). The reason they become DataFiles/DvObjects is a throwback to or legacy of the old implementation in DVN v2-3. Back then they were treated as actual files - users could download them locally; they stored the remote location (url) in place of the physical file name, and DVN would make an HTTP call to get and proxy the content, transparently to the user. We abandoned that scheme as overly complicated (the problem with authentication was never fully resolved, among other things). So in the current scheme these "files" are used only for indexing. We still attempt to store a link to the remote object (as the storageidentifier of the DvObject), but it is never used practically. When search hits for harvested files are displayed, no attempt is made to redirect the user specifically to that file - clicking on the card always sends them to the remote location of the dataset to which the file belongs. This really doesn't justify maintaining the same DvObject hierarchy of entities as for "real" files, IMO.
            The concept of a "remote file", something that transparently appears as a DataFile to the local user, with the byte content stored elsewhere/remotely, is now being revisited (#7324). Once we have that, we may consider, as an optional/configurable harvesting feature, being able to turn harvested files into these "remotely stored" files locally. But when harvesting file records solely for indexing, I believe we should instead introduce some "HarvestedFileMetadata" entity for storing them.
            Definition of done:
            
             discuss during a tech hour.
             decide whether to move forward on this.
            
             if we decide to implement this, create the corresponding issues that are associated with it.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Feature: Harvesting</name>
              </nodes>
              <nodes>
                <name>pm.epic.nih_harvesting_framework</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.4.1</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.2</name>
              </nodes>
              <totalCount>6</totalCount>
            </labels>
            <number>8629</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Revisit/reimplement the concept of a "Harvested file". </title>
            <url>https://github.com/IQSS/dataverse/issues/8629</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Harvesting</name>
                </nodes>
                <nodes>
                  <name>pm.epic.nih_harvesting_framework</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.4.1</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.2</name>
                </nodes>
                <totalCount>6</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Revisit/reimplement the concept of a "Harvested file". </text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>NIH bklog items (Stefano)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPA6Y</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>&lt;!--
            Thank you for contributing to the Dataverse Project through the creation of a feature request!
            
            More information on ideas/feature requests and contributions can be found in the "Contributing to Dataverse" page:
            https://github.com/IQSS/dataverse/blob/develop/CONTRIBUTING.md#ideasfeature-requests
            
            Please fill out as much of the template as you can.
            Start below this comment section.
            --&gt;
            
            **Overview of the Feature Request**
            
            In pull request #8106 we documented the SERVER side of the harvesting API: https://guides.dataverse.org/en/5.8/api/native-api.html#managing-harvesting-server-and-sets
            
            This issue is for documenting the CLIENT side of the harvesting API
            
            **What kind of user is the feature intended for?**
            
            API User, Sysadmin
            
            **What inspired the request?**
            
            Thomas Jouneau asked about it at https://groups.google.com/g/dataverse-community/c/BK2IIc1QUY4/m/DpmiDF-DBgAJ
            
            **Any related open or closed issues to this feature request?**
            
            - Documentation: Document Harvesting/OAI set endpoints #4514</body>
            <bodyText>Overview of the Feature Request
            In pull request #8106 we documented the SERVER side of the harvesting API: https://guides.dataverse.org/en/5.8/api/native-api.html#managing-harvesting-server-and-sets
            This issue is for documenting the CLIENT side of the harvesting API
            What kind of user is the feature intended for?
            API User, Sysadmin
            What inspired the request?
            Thomas Jouneau asked about it at https://groups.google.com/g/dataverse-community/c/BK2IIc1QUY4/m/DpmiDF-DBgAJ
            Any related open or closed issues to this feature request?
            
            Documentation: Document Harvesting/OAI set endpoints #4514</bodyText>
            <closed>True</closed>
            <closedAt>2022-12-01T19:46:00Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: Harvesting</name>
              </nodes>
              <nodes>
                <name>Feature: API Guide</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.4.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>8267</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Feature Request/Idea: Documentation for the API to create and edit harvesting clients</title>
            <url>https://github.com/IQSS/dataverse/issues/8267</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Harvesting</name>
                </nodes>
                <nodes>
                  <name>Feature: API Guide</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.4.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Feature Request/Idea: Documentation for the API to create and edit harvesting clients</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Pre December 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPA34</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MTUw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MTQx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9002</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>9003</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>9002 allow direct upload setting</title>
            <url>https://github.com/IQSS/dataverse/pull/9003</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>9002 allow direct upload setting</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>3</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTdI</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8994</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>8995</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>allow slash in check permissions api request</title>
            <url>https://github.com/IQSS/dataverse/pull/8995</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>allow slash in check permissions api request</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>3</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTdY</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-11-30T19:56:21Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8907</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>8908</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Improve archiving api error handling</title>
            <url>https://github.com/IQSS/dataverse/pull/8908</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Improve archiving api error handling</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Pre December 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNnSQ</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>According to Wikipedia [NetCDF](https://en.wikipedia.org/wiki/NetCDF) and [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) have magic numbers that should let us detect these file types more easily and reliably than guessing based on file extensions.
            
            ## NetCDF magic number
            
            ```
            CDF\001
            \211HDF\r\n\032\n
            ```
            
            ## HDF5 magic number
            
            ```
            \211HDF\r\n\032\n
            ```
            
            I brought this up at standup today and here are some notes from the discussion:
            
            - We should see if JHOVE can detect them.
            - Normally, detecting file types by seeking into files is part of detecting tabular files, specifically.
            - Given that NetCDF can be big, this might be a case where switching to a ranged request to find the signature might be important.
            
            We should add some NetCDF and HDF5 files to https://github.com/IQSS/dataverse-sample-data to test with, at some point.
            
            Related:
            
            - https://github.com/IQSS/dataverse.harvard.edu/issues/23</body>
            <bodyText>According to Wikipedia NetCDF and HDF5 have magic numbers that should let us detect these file types more easily and reliably than guessing based on file extensions.
            NetCDF magic number
            CDF\001
            \211HDF\r\n\032\n
            
            HDF5 magic number
            \211HDF\r\n\032\n
            
            I brought this up at standup today and here are some notes from the discussion:
            
            We should see if JHOVE can detect them.
            Normally, detecting file types by seeking into files is part of detecting tabular files, specifically.
            Given that NetCDF can be big, this might be a case where switching to a ranged request to find the signature might be important.
            
            We should add some NetCDF and HDF5 files to https://github.com/IQSS/dataverse-sample-data to test with, at some point.
            Related:
            
            IQSS/dataverse.harvard.edu#23</bodyText>
            <closed>True</closed>
            <closedAt>2022-11-22T19:35:04Z</closedAt>
            <labels>
              <nodes>
                <name>pm.netcdf-hdf5.d</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9117</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Improve file type detection of NetCDF and HDF5</title>
            <url>https://github.com/IQSS/dataverse/issues/9117</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>pm.netcdf-hdf5.d</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Improve file type detection of NetCDF and HDF5</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Pre December 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>NIH NetCDF (Phil)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDO1K4</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>landreev</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>After testing of the metadata block is finished, we'll need to add the metadata block to the Harvard Dataverse Repository, to be available only in the repository's SAEF collection (https://dataverse.harvard.edu/dataverse/saef)
            
            
            A working draft of the metadata block's TSV file is at https://docs.google.com/spreadsheets/d/1Uv8jlADIKgQ6DfgrXiZ14POrR1YQvpfBXgLadIlEz9Y#gid=1851768194</body>
            <bodyText>After testing of the metadata block is finished, we'll need to add the metadata block to the Harvard Dataverse Repository, to be available only in the repository's SAEF collection (https://dataverse.harvard.edu/dataverse/saef)
            A working draft of the metadata block's TSV file is at https://docs.google.com/spreadsheets/d/1Uv8jlADIKgQ6DfgrXiZ14POrR1YQvpfBXgLadIlEz9Y#gid=1851768194</bodyText>
            <closed>True</closed>
            <closedAt>2022-10-31T15:05:43Z</closedAt>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>185</number>
            <repository>
              <name>dataverse.harvard.edu</name>
            </repository>
            <title>Add SAEF metadata block to Harvard Dataverse Repository</title>
            <url>https://github.com/IQSS/dataverse.harvard.edu/issues/185</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNzQwNTY1NTE=</id>
                <name>dataverse.harvard.edu</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add SAEF metadata block to Harvard Dataverse Repository</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 1, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Harvard Dataverse Instance (Sonia)</text>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPGK4</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>6810</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Code Infrastructure</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>7261</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>6810 - refactor JSON deps</title>
            <url>https://github.com/IQSS/dataverse/pull/7261</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Code Infrastructure</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>6810 - refactor JSON deps</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPaks</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>6456</number>
              </nodes>
              <nodes>
                <number>6970</number>
              </nodes>
              <totalCount>2</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Type: Feature</name>
              </nodes>
              <nodes>
                <name>Feature: Permissions</name>
              </nodes>
              <nodes>
                <name>Feature: Metrics + Reports</name>
              </nodes>
              <nodes>
                <name>Feature: Admin Guide</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>6977</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>6970 proxy client ip</title>
            <url>https://github.com/IQSS/dataverse/pull/6977</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Type: Feature</name>
                </nodes>
                <nodes>
                  <name>Feature: Permissions</name>
                </nodes>
                <nodes>
                  <name>Feature: Metrics + Reports</name>
                </nodes>
                <nodes>
                  <name>Feature: Admin Guide</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>2</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>6970 proxy client ip</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDPalE</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8778</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>8786</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>8778 harvester ddi exporter</title>
            <url>https://github.com/IQSS/dataverse/pull/8786</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>8778 harvester ddi exporter</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDQgGg</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>RSpace ELN uses the Dataverse API to submit research data to Dataverse. It has a minimal UI for metadata fields such as title, subject, description, authors, contacts and this works on various Dataverses till now.
            
            One of our RSpace customers has their own Dataverse as well - 4.19. They have configured Dataverse to require additional metadata when submitting a Dataset. RSpace doesn't know these fields are mandatory and submission fails:
            
            `Deposit failed: ERROR2020-06-09T10:58:26ZProcessing failedCouldn't update dataset edu.harvard.iq.dataverse.engine.command.exception.IllegalCommandException: Validation Failed: Producer Name is required. (Invalid value:edu.harvard.iq.dataverse.DatasetField[ id=null ]), Distributor Name is required. (Invalid value:edu.harvard.iq.dataverse.DatasetField[ id=null ]), Description Date is required. (Invalid value:edu.harvard.iq.dataverse.DatasetField[ id=null ]), Keyword Term is required. (Invalid value:edu.harvard.iq.dataverse.DatasetField[ id=null ]), Deposit Date is required. (Invalid value:edu.harvard.iq.dataverse.DatasetField[ id=null ]).`
            
            This corresponds exactly to what are the required properties as sent by the Dataverse admin, that are not set by RSpace
            - Author - Name
            - Contact - Name
            - Contact - Email
            - Description - Text
            - Description - Date
            - Keyword - Term
            - Producer - Name
            - Distributor - Name (In our default templates, this is always the name of the (sub-)dataverse. I'm not sure how this should be handled when a dataset is created from RSpace.)
            - Deposit Date (In Dataverse, this is generated by the system.)
            
            If this list never changes, then RSpace could develop a solution where it reads a list of mandatory fields from a configuration file. But if it does change from time to time, it would be great if there was an API method in Dataverse to get a list of mandatory metadata fields .Then, a client could programmatically generate input fields for these properties so that the end-user could make a valid submission.</body>
            <bodyText>RSpace ELN uses the Dataverse API to submit research data to Dataverse. It has a minimal UI for metadata fields such as title, subject, description, authors, contacts and this works on various Dataverses till now.
            One of our RSpace customers has their own Dataverse as well - 4.19. They have configured Dataverse to require additional metadata when submitting a Dataset. RSpace doesn't know these fields are mandatory and submission fails:
            Deposit failed: ERROR2020-06-09T10:58:26ZProcessing failedCouldn't update dataset edu.harvard.iq.dataverse.engine.command.exception.IllegalCommandException: Validation Failed: Producer Name is required. (Invalid value:edu.harvard.iq.dataverse.DatasetField[ id=null ]), Distributor Name is required. (Invalid value:edu.harvard.iq.dataverse.DatasetField[ id=null ]), Description Date is required. (Invalid value:edu.harvard.iq.dataverse.DatasetField[ id=null ]), Keyword Term is required. (Invalid value:edu.harvard.iq.dataverse.DatasetField[ id=null ]), Deposit Date is required. (Invalid value:edu.harvard.iq.dataverse.DatasetField[ id=null ]).
            This corresponds exactly to what are the required properties as sent by the Dataverse admin, that are not set by RSpace
            
            Author - Name
            Contact - Name
            Contact - Email
            Description - Text
            Description - Date
            Keyword - Term
            Producer - Name
            Distributor - Name (In our default templates, this is always the name of the (sub-)dataverse. I'm not sure how this should be handled when a dataset is created from RSpace.)
            Deposit Date (In Dataverse, this is generated by the system.)
            
            If this list never changes, then RSpace could develop a solution where it reads a list of mandatory fields from a configuration file. But if it does change from time to time, it would be great if there was an API method in Dataverse to get a list of mandatory metadata fields .Then, a client could programmatically generate input fields for these properties so that the end-user could make a valid submission.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Feature: API</name>
              </nodes>
              <nodes>
                <name>User Role: API User</name>
              </nodes>
              <nodes>
                <name>HERMES</name>
              </nodes>
              <nodes>
                <name>Hackathon: More APIs</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>6978</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Query Dataverse for mandatory metadata fields via API</title>
            <url>https://github.com/IQSS/dataverse/issues/6978</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: API</name>
                </nodes>
                <nodes>
                  <name>User Role: API User</name>
                </nodes>
                <nodes>
                  <name>HERMES</name>
                </nodes>
                <nodes>
                  <name>Hackathon: More APIs</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Query Dataverse for mandatory metadata fields via API</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNX3o</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>7043</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>7044</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>fix mimetype of error pages</title>
            <url>https://github.com/IQSS/dataverse/pull/7044</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>1</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>fix mimetype of error pages</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTkY</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <pageInfo>
          <endCursor>MTYw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MTUx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>7632</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>7636</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Exclusions to remove module/classpath warnings</title>
            <url>https://github.com/IQSS/dataverse/pull/7636</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Exclusions to remove module/classpath warnings</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>3</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTj4</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>5505</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>5506</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS-5505 - only update DOI metadata at PIDprovider when it changes</title>
            <url>https://github.com/IQSS/dataverse/pull/5506</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS-5505 - only update DOI metadata at PIDprovider when it changes</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>3</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTkE</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>5621</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>use dataset thumbnail if available</title>
            <url>https://github.com/IQSS/dataverse/pull/5621</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>use dataset thumbnail if available</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>3</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTkQ</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>7068</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>7334</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/7068 Reserve File Pids</title>
            <url>https://github.com/IQSS/dataverse/pull/7334</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/7068 Reserve File Pids</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>3</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNTkM</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>As a data steward for an organization producing and publishing data, we would like to see the [Research Organization Registry](https://ror.org/) ID option added to the Citation metadata block. Perhaps as an addition to the list of Identifier Schemes for authors, or attached to the Affiliation, Producer, Distributor, or similar. As can be seen [here](https://ror.org/supporters/), a respectable list of supporters and signatories have already committed to the adoption and use of RORs going forward.
            </body>
            <bodyText>As a data steward for an organization producing and publishing data, we would like to see the Research Organization Registry ID option added to the Citation metadata block. Perhaps as an addition to the list of Identifier Schemes for authors, or attached to the Affiliation, Producer, Distributor, or similar. As can be seen here, a respectable list of supporters and signatories have already committed to the adoption and use of RORs going forward.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Type: Suggestion</name>
              </nodes>
              <nodes>
                <name>Feature: Metadata</name>
              </nodes>
              <nodes>
                <name>User Role: Curator</name>
              </nodes>
              <nodes>
                <name>User Role: Depositor</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.5.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.5.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.5.2</name>
              </nodes>
              <totalCount>7</totalCount>
            </labels>
            <number>6640</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Support Research Organization Registry (ROR) IDs</title>
            <url>https://github.com/IQSS/dataverse/issues/6640</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Type: Suggestion</name>
                </nodes>
                <nodes>
                  <name>Feature: Metadata</name>
                </nodes>
                <nodes>
                  <name>User Role: Curator</name>
                </nodes>
                <nodes>
                  <name>User Role: Depositor</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.5.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.5.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.5.2</name>
                </nodes>
                <totalCount>7</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Support Research Organization Registry (ROR) IDs</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Harvard Dataverse Instance (Sonia)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDRr3k</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>The native API currently allows file update (and now file replace) operations but it doesn't appear to allow file delete. This means that because replace only works on *published* files, it is not possible to update the file contents of a draft dataset without going through the GUI to manually delete the staged file or to delete the entire draft (all files and metadata) through the API. It would be great to be able to delete both unpublished/draft files and to delete files generally from a version (in the way that is currently possible through the GUI).</body>
            <bodyText>The native API currently allows file update (and now file replace) operations but it doesn't appear to allow file delete. This means that because replace only works on published files, it is not possible to update the file contents of a draft dataset without going through the GUI to manually delete the staged file or to delete the entire draft (all files and metadata) through the API. It would be great to be able to delete both unpublished/draft files and to delete files generally from a version (in the way that is currently possible through the GUI).</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-28T22:52:23Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: API</name>
              </nodes>
              <nodes>
                <name>User Role: API User</name>
              </nodes>
              <nodes>
                <name>Hackathon: More APIs</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>3913</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Is a delete file endpoint available?</title>
            <url>https://github.com/IQSS/dataverse/issues/3913</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: API</name>
                </nodes>
                <nodes>
                  <name>User Role: API User</name>
                </nodes>
                <nodes>
                  <name>Hackathon: More APIs</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Is a delete file endpoint available?</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Community Backlog (Phil)</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDx6M8</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <title>Dataverse Java API Package</title>
          </content>
          <fieldValues>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Dataverse Java API Package</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>HERMES (Oliver)</name>
            </nodes>
            <totalCount>2</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDyry4</id>
          <type>DRAFT_ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <title>Schema Data Binds / Model Mappings (DataCite Kernel Update)</title>
          </content>
          <fieldValues>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Schema Data Binds / Model Mappings (DataCite Kernel Update)</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>HERMES (Oliver)</name>
            </nodes>
            <totalCount>2</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDyru8</id>
          <type>DRAFT_ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <title>Renewed DataCite Exporter</title>
          </content>
          <fieldValues>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Renewed DataCite Exporter</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>HERMES (Oliver)</name>
            </nodes>
            <totalCount>2</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDyrxI</id>
          <type>DRAFT_ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-12-09T17:38:17Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>1510</number>
              </nodes>
              <nodes>
                <number>8944</number>
              </nodes>
              <totalCount>2</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9213</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>#8944 - Extend 'metadatablocks/{block_id}' endpoint JSON output</title>
            <url>https://github.com/IQSS/dataverse/pull/9213</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>#8944 - Extend 'metadatablocks/{block_id}' endpoint JSON output</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 1, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDzmkQ</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <pageInfo>
          <endCursor>MTcw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MTYx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>mreekie</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>This was  a top 3 out of the retrospective, but we didn't have time to discuss it very deeply there. 
            I'm taking a shot at it here.
            
            This has not gotten the discussion it needs.
            - is this referring to the idea that we could have done more PRs?
            - or are folks feeling like QA wasn't busy enough?
            - or are we sizing our issues too big so that there are gaps?
            
            This is important as a team discussion as well because it touches on the idea of a the pull model.  Does the QA team feel it had enough work? QA pulls in the same way dev does.
            
            
            
            
            </body>
            <bodyText>This was  a top 3 out of the retrospective, but we didn't have time to discuss it very deeply there.
            I'm taking a shot at it here.
            This has not gotten the discussion it needs.
            
            is this referring to the idea that we could have done more PRs?
            or are folks feeling like QA wasn't busy enough?
            or are we sizing our issues too big so that there are gaps?
            
            This is important as a team discussion as well because it touches on the idea of a the pull model.  Does the QA team feel it had enough work? QA pulls in the same way dev does.</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-25T14:30:15Z</closedAt>
            <labels>
              <nodes>
                <name>Sprint Retrospective</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>2</number>
            <repository>
              <name>dataverse-pm</name>
            </repository>
            <title>Spike: During some sprints we end the sprint with a few days with QA empty</title>
            <url>https://github.com/IQSS/dataverse-pm/issues/2</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOIwMRzQ</id>
                <name>dataverse-pm</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Sprint Retrospective</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Spike: During some sprints we end the sprint with a few days with QA empty</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgD6FlA</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>mreekie</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>This was a top 3 out of the retrospective, but we didn't have time to discuss it very deeply there.
            I'm taking a shot at it here.  I'm combining 2 of the top 3 items that came out of the retrospective.
            
            I'm guessing that this is mostly aimed at the growth in the number and length of meetings since I've come onboard so I think this likely falls within my bailiwick anyway. 🤔 
            
            If that assumption is true, then the best way to address this is through quantifying things.  
            I'm not going to assign this a size and if it bleeds over into the first January sprint that's fine.
            
            ### Definition of done:
            - [x] I'll keep track for January of meetings running over time and running within time, and we can take a look at the next retrospective.
            - [x] I am working out a cadence for meetings. I propose that we see how this works in the January sprint (after the holidays) and revisit it at the retrospective that follows as well.
            
            
            ### Adjacent items
            
            **Here's where I'm aiming for individual meetings:**
            - Define the end time of the meeting at the beginning.
            - Have an agenda for the meeting
              -  where it's a repeating thing (e.g. issue sizing meetings, retrospective, etc), I will keep us on track with a checklist
            - End the main agenda at 10 minutes before the meeting to determine next steps
            - I will end meetings early if we make it through our agenda.
            
            **Meeting tools:**
            - Make use of the [decider protocol](https://thecoreprotocols.org/protocols/decider) to keep meetings moving and limit over communication (especially by me).  This is the thumbs up, thumbs down, hand thing.
            - Continue to make use of tools such as the retrospective game to make meetings efficient.
            - Perhaps look at other tools such as [lean coffee](https://miro.com/miroverse/lean-coffee-richard/) to keep topic discussions bounded.
            
            **For repeating meetings I am working on establishing a cadence.**
            This includes:
            - sizing meetings
            - triaging new issues
            - Backlog stewards prioritizing and sizing.
            
            **Keeping track of meeting times**
            - As much as possible as I work out those cadences to keep our sprint related meetings to the 11AM-12PM band. 
            - Last minute meetings will when required will if at all possible be held during the 11-12 time period.</body>
            <bodyText>This was a top 3 out of the retrospective, but we didn't have time to discuss it very deeply there.
            I'm taking a shot at it here.  I'm combining 2 of the top 3 items that came out of the retrospective.
            I'm guessing that this is mostly aimed at the growth in the number and length of meetings since I've come onboard so I think this likely falls within my bailiwick anyway. 🤔
            If that assumption is true, then the best way to address this is through quantifying things.
            I'm not going to assign this a size and if it bleeds over into the first January sprint that's fine.
            Definition of done:
            
             I'll keep track for January of meetings running over time and running within time, and we can take a look at the next retrospective.
             I am working out a cadence for meetings. I propose that we see how this works in the January sprint (after the holidays) and revisit it at the retrospective that follows as well.
            
            Adjacent items
            Here's where I'm aiming for individual meetings:
            
            Define the end time of the meeting at the beginning.
            Have an agenda for the meeting
            
            where it's a repeating thing (e.g. issue sizing meetings, retrospective, etc), I will keep us on track with a checklist
            
            
            End the main agenda at 10 minutes before the meeting to determine next steps
            I will end meetings early if we make it through our agenda.
            
            Meeting tools:
            
            Make use of the decider protocol to keep meetings moving and limit over communication (especially by me).  This is the thumbs up, thumbs down, hand thing.
            Continue to make use of tools such as the retrospective game to make meetings efficient.
            Perhaps look at other tools such as lean coffee to keep topic discussions bounded.
            
            For repeating meetings I am working on establishing a cadence.
            This includes:
            
            sizing meetings
            triaging new issues
            Backlog stewards prioritizing and sizing.
            
            Keeping track of meeting times
            
            As much as possible as I work out those cadences to keep our sprint related meetings to the 11AM-12PM band.
            Last minute meetings will when required will if at all possible be held during the 11-12 time period.</bodyText>
            <closed>True</closed>
            <closedAt>2023-01-11T23:36:03Z</closedAt>
            <labels>
              <nodes>
                <name>Sprint Retrospective</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>3</number>
            <repository>
              <name>dataverse-pm</name>
            </repository>
            <title>Spike: Improvement - End meetings on time &amp; Schedule meetings more than a few hours ahead</title>
            <url>https://github.com/IQSS/dataverse-pm/issues/3</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOIwMRzQ</id>
                <name>dataverse-pm</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Sprint Retrospective</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Spike: Improvement - End meetings on time &amp; Schedule meetings more than a few hours ahead</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>December 15, 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgD6IHY</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>5864</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>DataverseNO</name>
              </nodes>
              <nodes>
                <name>Size: Queued</name>
              </nodes>
              <nodes>
                <name>bklog: NeedsDiscussion</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>9245</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Client-side multifile zip download</title>
            <url>https://github.com/IQSS/dataverse/pull/9245</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>DataverseNO</name>
                </nodes>
                <nodes>
                  <name>Size: Queued</name>
                </nodes>
                <nodes>
                  <name>bklog: NeedsDiscussion</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Client-side multifile zip download</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>External Commitments (Jim)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEBgMI</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>6902</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Work-in-Progress: 2043-guestbook-at-request code review requested</title>
            <url>https://github.com/IQSS/dataverse/pull/6902</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>2</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Work-in-Progress: 2043-guestbook-at-request code review requested</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>External Commitments (Jim)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNc8g</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8349</number>
              </nodes>
              <nodes>
                <number>9268</number>
              </nodes>
              <totalCount>2</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Code Infrastructure</name>
              </nodes>
              <nodes>
                <name>Feature: Performance &amp; Stability</name>
              </nodes>
              <nodes>
                <name>Feature: Installation Guide</name>
              </nodes>
              <nodes>
                <name>Containers &amp; Cloud</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.7.1 (reArchitecture)</name>
              </nodes>
              <nodes>
                <name>Testing: API</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>8</totalCount>
            </labels>
            <number>9273</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>9268 mpconfig OIDC provider</title>
            <url>https://github.com/IQSS/dataverse/pull/9273</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Code Infrastructure</name>
                </nodes>
                <nodes>
                  <name>Feature: Performance &amp; Stability</name>
                </nodes>
                <nodes>
                  <name>Feature: Installation Guide</name>
                </nodes>
                <nodes>
                  <name>Containers &amp; Cloud</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.7.1 (reArchitecture)</name>
                </nodes>
                <nodes>
                  <name>Testing: API</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>8</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>9268 mpconfig OIDC provider</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Re-arch: Auth MVP (Phil)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgETjO8</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-02-21T15:12:05Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: API</name>
              </nodes>
              <nodes>
                <name>User Role: API User</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.7.1 (reArchitecture)</name>
              </nodes>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>9303</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>9293 - New filter-based design for the API authentication mechanisms (1/2)</title>
            <url>https://github.com/IQSS/dataverse/pull/9303</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>2</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: API</name>
                </nodes>
                <nodes>
                  <name>User Role: API User</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.7.1 (reArchitecture)</name>
                </nodes>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.14</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>9293 - New filter-based design for the API authentication mechanisms (1/2)</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEZbvc</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9223</number>
              </nodes>
              <nodes>
                <number>9229</number>
              </nodes>
              <totalCount>2</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: API</name>
              </nodes>
              <nodes>
                <name>Feature: Permissions</name>
              </nodes>
              <nodes>
                <name>Feature: Account &amp; User Info</name>
              </nodes>
              <nodes>
                <name>Feature: API Guide</name>
              </nodes>
              <nodes>
                <name>Feature: Admin Guide</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.7.1 (reArchitecture)</name>
              </nodes>
              <nodes>
                <name>Size: Queued</name>
              </nodes>
              <nodes>
                <name>bklog: NeedsDiscussion</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>9</totalCount>
            </labels>
            <number>9230</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>9229 - enable OIDC bearer token API access</title>
            <url>https://github.com/IQSS/dataverse/pull/9230</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: API</name>
                </nodes>
                <nodes>
                  <name>Feature: Permissions</name>
                </nodes>
                <nodes>
                  <name>Feature: Account &amp; User Info</name>
                </nodes>
                <nodes>
                  <name>Feature: API Guide</name>
                </nodes>
                <nodes>
                  <name>Feature: Admin Guide</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.7.1 (reArchitecture)</name>
                </nodes>
                <nodes>
                  <name>Size: Queued</name>
                </nodes>
                <nodes>
                  <name>bklog: NeedsDiscussion</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>9</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>9229 - enable OIDC bearer token API access</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Re-arch: Auth MVP (Phil)</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgD5u7U</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>Can we please install the ZIP Previewer &amp; File Downloader on https://demo.dataverse.org and https://dataverse.harvard.edu ?
            
            This:
            
            - https://github.com/gdcc/dataverse-previewers/pull/9
            
            Thanks!!</body>
            <bodyText>Can we please install the ZIP Previewer &amp; File Downloader on https://demo.dataverse.org and https://dataverse.harvard.edu ?
            This:
            
            gdcc/dataverse-previewers#9
            
            Thanks!!</bodyText>
            <closed>True</closed>
            <closedAt>2023-02-28T17:13:03Z</closedAt>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>196</number>
            <repository>
              <name>dataverse.harvard.edu</name>
            </repository>
            <title>Add ZIP Previewer &amp; File Downloader to demo and prod</title>
            <url>https://github.com/IQSS/dataverse.harvard.edu/issues/196</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNzQwNTY1NTE=</id>
                <name>dataverse.harvard.edu</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add ZIP Previewer &amp; File Downloader to demo and prod</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Community Backlog (Phil)</text>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEXLTs</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>rtreacy</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body></body>
            <bodyText></bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <nodes>
                <name>D: SonarQubeCleanup</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9311</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>In SystemConfig.java use try-with-resources for JsonReader jsonReader = Json.createReader(new StringReader(setting)); in method getCurationLabels()</title>
            <url>https://github.com/IQSS/dataverse/issues/9311</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <nodes>
                  <name>D: SonarQubeCleanup</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>In SystemConfig.java use try-with-resources for JsonReader jsonReader = Json.createReader(new StringReader(setting)); in method getCurationLabels()</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEdYyA</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body></body>
            <bodyText></bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: Queued</name>
              </nodes>
              <nodes>
                <name>D: SonarQubeCleanup</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9314</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>In JsonParser.java use try-with-resource for JsonReader jsonReader = Json.createReader(new StringReader(jsonString)); in method remapGeographicCoverage(...)</title>
            <url>https://github.com/IQSS/dataverse/issues/9314</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: Queued</name>
                </nodes>
                <nodes>
                  <name>D: SonarQubeCleanup</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>In JsonParser.java use try-with-resource for JsonReader jsonReader = Json.createReader(new StringReader(jsonString)); in method remapGeographicCoverage(...)</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SonarQube cleanup (Gustavo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEdhY0</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MTgw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MTcx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body></body>
            <bodyText></bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: Queued</name>
              </nodes>
              <nodes>
                <name>D: SonarQubeCleanup</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9313</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>In JSONLDUtil.java use try-with-resources for JsonObject jsonld = Json.createReader(rdr).readObject(); in method decontextualizeJsonLD(...)</title>
            <url>https://github.com/IQSS/dataverse/issues/9313</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: Queued</name>
                </nodes>
                <nodes>
                  <name>D: SonarQubeCleanup</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>In JSONLDUtil.java use try-with-resources for JsonObject jsonld = Json.createReader(rdr).readObject(); in method decontextualizeJsonLD(...)</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SonarQube cleanup (Gustavo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEdngA</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body></body>
            <bodyText></bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: Queued</name>
              </nodes>
              <nodes>
                <name>D: SonarQubeCleanup</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9315</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>In JsonUtil.java use try-with-resources for return Json.createReader(rdr).readObject(); in method getJsonObject(...) and return Json.createReader(rdr).readArray(); in method getJsonArray(...)</title>
            <url>https://github.com/IQSS/dataverse/issues/9315</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: Queued</name>
                </nodes>
                <nodes>
                  <name>D: SonarQubeCleanup</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>In JsonUtil.java use try-with-resources for return Json.createReader(rdr).readObject(); in method getJsonObject(...) and return Json.createReader(rdr).readArray(); in method getJsonArray(...)</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SonarQube cleanup (Gustavo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEdnhQ</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>pdurbin</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>@atrisovic and I exchanged emails with @plesubc and he has inspired us to use GDAL, ogrinfo or similar to try extracting latitude and longitude from a NetCDF file.
            
            As this is just a spike, some discovery, we're sizing this as 10 or 1 day.
            
            Here's part of the email from Paul (this file happens to span the entire globe):
            
            "Metadata extraction is a relatively simple process assuming you’re using GDAL. The GDAL suite exports file metadata to stdout, so all you really need to do is capture and process the text. Of course, differing formats have differing outputs, because life is never that simple.
            
            So, for example, imagine you downloaded a netcdf from here:
            
            https://data.ceda.ac.uk/badc/ukmo-hadobs/data/derived/MOHC/HadOBS/HadEX3/v3-0-2 (HadEX3-0-2_cwd_ann_1901-2018.nc). This isn’t some special data set, it’s the result of a google for spatial netcdf files.
            
            Basically, filtering this file through ogrinfo (one of the utilities in GDAL), you get something like this as output:
            
            ```
            ogrinfo *nc
            INFO: Open of `HadEX3-0-2_cwd_ann_1901-2018.nc'
                  using driver `netCDF' successful.
            Metadata:
              NC_GLOBAL#acknowledgement=RJHD was supported by Met Office Hadley Centre Climate Programme funded by BEIS and Defra
              NC_GLOBAL#CDI=Climate Data Interface version 1.9.9rc1 (https://mpimet.mpg.de/cdi)
              NC_GLOBAL#cdm_data_type=grid
              NC_GLOBAL#CDO=Climate Data Operators version 1.9.9rc1 (https://mpimet.mpg.de/cdo)
              [NC_GLOBAL#creator_email=robert.dunn@metoffice.gov.uk](mailto:NC_GLOBAL#creator_email=robert.dunn@metoffice.gov.uk)
              NC_GLOBAL#creator_name=Robert Dunn
              NC_GLOBAL#creator_url=[www.metoffice.gov.uk](http://www.metoffice.gov.uk/)
              NC_GLOBAL#dataset_version=3.0.2
              NC_GLOBAL#date_created=Mon Oct 26, 12:10 2020
              NC_GLOBAL#DOI=https://doi.org/10.1029/2019JD032263
              NC_GLOBAL#geospatial_lat_max=90
              NC_GLOBAL#geospatial_lat_min=-90
              NC_GLOBAL#geospatial_lat_resolution=1.25
              NC_GLOBAL#geospatial_lat_units=degrees
              NC_GLOBAL#geospatial_lon_max=360
              NC_GLOBAL#geospatial_lon_min=0
              NC_GLOBAL#geospatial_lon_resolution=1.875
              NC_GLOBAL#geospatial_lon_units=degrees
              NC_GLOBAL#institution=Met Office Hadley Centre, Exeter, UK
              NC_GLOBAL#keywords=extremes indices, gridded, temperature, precipitation, ETCCDI
              NC_GLOBAL#licence=HadEX3 is distributed under the Open Government Licence: http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/. The data are available for use with attribution to the data providers. Please cite Dunn et al (2020) and state the version used. This product may contain data which are governed by WMO Policy following WMO Resolution 40 Annex 1 alongside additional data that may have restrictions placed on their commercial use by the data owners. Any redistribution of this product should be accompanied by a similar statement of usage policy.
              NC_GLOBAL#Metadata_Conventions=Unidata Dataset Discovery v1.0,CF Discrete Sampling Geometries Conventions
              NC_GLOBAL#NCO=netCDF Operators version 4.7.5 (Homepage = http://nco.sf.net/, Code = http://github.com/nco/nco)
              NC_GLOBAL#processing_level=Daily TX, TN and P observations, converted to ETCCDI indices, and then gridded
              NC_GLOBAL#references=Dunn, Alexander et al. 2020, Journal of Geophysical Research - Atmospheres, https://doi.org/10.1029/2019JD032263
              NC_GLOBAL#source=HadEX3 data product
              NC_GLOBAL#summary=Gridded dataset of extremes indices
              NC_GLOBAL#time_coverage_end=2019-01-01T00:00Z
              NC_GLOBAL#time_coverage_resolution=Monthly
              NC_GLOBAL#time_coverage_start=1901-01-01T00:00Z
              NC_GLOBAL#title=CWD
            ```</body>
            <bodyText>@atrisovic and I exchanged emails with @plesubc and he has inspired us to use GDAL, ogrinfo or similar to try extracting latitude and longitude from a NetCDF file.
            As this is just a spike, some discovery, we're sizing this as 10 or 1 day.
            Here's part of the email from Paul (this file happens to span the entire globe):
            "Metadata extraction is a relatively simple process assuming you’re using GDAL. The GDAL suite exports file metadata to stdout, so all you really need to do is capture and process the text. Of course, differing formats have differing outputs, because life is never that simple.
            So, for example, imagine you downloaded a netcdf from here:
            https://data.ceda.ac.uk/badc/ukmo-hadobs/data/derived/MOHC/HadOBS/HadEX3/v3-0-2 (HadEX3-0-2_cwd_ann_1901-2018.nc). This isn’t some special data set, it’s the result of a google for spatial netcdf files.
            Basically, filtering this file through ogrinfo (one of the utilities in GDAL), you get something like this as output:
            ogrinfo *nc
            INFO: Open of `HadEX3-0-2_cwd_ann_1901-2018.nc'
                  using driver `netCDF' successful.
            Metadata:
              NC_GLOBAL#acknowledgement=RJHD was supported by Met Office Hadley Centre Climate Programme funded by BEIS and Defra
              NC_GLOBAL#CDI=Climate Data Interface version 1.9.9rc1 (https://mpimet.mpg.de/cdi)
              NC_GLOBAL#cdm_data_type=grid
              NC_GLOBAL#CDO=Climate Data Operators version 1.9.9rc1 (https://mpimet.mpg.de/cdo)
              [NC_GLOBAL#creator_email=robert.dunn@metoffice.gov.uk](mailto:NC_GLOBAL#creator_email=robert.dunn@metoffice.gov.uk)
              NC_GLOBAL#creator_name=Robert Dunn
              NC_GLOBAL#creator_url=[www.metoffice.gov.uk](http://www.metoffice.gov.uk/)
              NC_GLOBAL#dataset_version=3.0.2
              NC_GLOBAL#date_created=Mon Oct 26, 12:10 2020
              NC_GLOBAL#DOI=https://doi.org/10.1029/2019JD032263
              NC_GLOBAL#geospatial_lat_max=90
              NC_GLOBAL#geospatial_lat_min=-90
              NC_GLOBAL#geospatial_lat_resolution=1.25
              NC_GLOBAL#geospatial_lat_units=degrees
              NC_GLOBAL#geospatial_lon_max=360
              NC_GLOBAL#geospatial_lon_min=0
              NC_GLOBAL#geospatial_lon_resolution=1.875
              NC_GLOBAL#geospatial_lon_units=degrees
              NC_GLOBAL#institution=Met Office Hadley Centre, Exeter, UK
              NC_GLOBAL#keywords=extremes indices, gridded, temperature, precipitation, ETCCDI
              NC_GLOBAL#licence=HadEX3 is distributed under the Open Government Licence: http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/. The data are available for use with attribution to the data providers. Please cite Dunn et al (2020) and state the version used. This product may contain data which are governed by WMO Policy following WMO Resolution 40 Annex 1 alongside additional data that may have restrictions placed on their commercial use by the data owners. Any redistribution of this product should be accompanied by a similar statement of usage policy.
              NC_GLOBAL#Metadata_Conventions=Unidata Dataset Discovery v1.0,CF Discrete Sampling Geometries Conventions
              NC_GLOBAL#NCO=netCDF Operators version 4.7.5 (Homepage = http://nco.sf.net/, Code = http://github.com/nco/nco)
              NC_GLOBAL#processing_level=Daily TX, TN and P observations, converted to ETCCDI indices, and then gridded
              NC_GLOBAL#references=Dunn, Alexander et al. 2020, Journal of Geophysical Research - Atmospheres, https://doi.org/10.1029/2019JD032263
              NC_GLOBAL#source=HadEX3 data product
              NC_GLOBAL#summary=Gridded dataset of extremes indices
              NC_GLOBAL#time_coverage_end=2019-01-01T00:00Z
              NC_GLOBAL#time_coverage_resolution=Monthly
              NC_GLOBAL#time_coverage_start=1901-01-01T00:00Z
              NC_GLOBAL#title=CWD</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>spike</name>
              </nodes>
              <nodes>
                <name>pm.netcdf-hdf5.d</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>9331</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Extracting lat/long and insert into geospatial bounding box fields</title>
            <url>https://github.com/IQSS/dataverse/issues/9331</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>spike</name>
                </nodes>
                <nodes>
                  <name>pm.netcdf-hdf5.d</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Extracting lat/long and insert into geospatial bounding box fields</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>NIH NetCDF (Phil)</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 15, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEh6f4</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>rtreacy</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>In DataConverter.java use try-with-resources for convertedFileStream = Channels.newInputStream((ReadableByteChannel) storageIO.openAuxChannel(formatRequested)); and convertedFileStream = new FileInputStream(formatConvertedFile); in method performFormatConversion(…)</body>
            <bodyText>In DataConverter.java use try-with-resources for convertedFileStream = Channels.newInputStream((ReadableByteChannel) storageIO.openAuxChannel(formatRequested)); and convertedFileStream = new FileInputStream(formatConvertedFile); in method performFormatConversion(…)</bodyText>
            <closed>True</closed>
            <closedAt>2023-02-09T18:04:13Z</closedAt>
            <labels>
              <nodes>
                <name>Tech Debt</name>
              </nodes>
              <nodes>
                <name>Size: Queued</name>
              </nodes>
              <nodes>
                <name>D: SonarQubeCleanup</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>9281</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>In DataConverter.java use try-with-resources for convertedFileStream</title>
            <url>https://github.com/IQSS/dataverse/issues/9281</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Tech Debt</name>
                </nodes>
                <nodes>
                  <name>Size: Queued</name>
                </nodes>
                <nodes>
                  <name>D: SonarQubeCleanup</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>In DataConverter.java use try-with-resources for convertedFileStream</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>SonarQube cleanup (Gustavo)</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEQ3Fc</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-02-22T15:14:04Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9293</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: API</name>
              </nodes>
              <nodes>
                <name>User Role: API User</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.7.1 (reArchitecture)</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>9360</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>9293 - Apply filter-based auth for all API endpoints (2/2)</title>
            <url>https://github.com/IQSS/dataverse/pull/9360</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: API</name>
                </nodes>
                <nodes>
                  <name>User Role: API User</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.7.1 (reArchitecture)</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.14</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>9293 - Apply filter-based auth for all API endpoints (2/2)</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEp_QQ</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>GPortas</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            In order to manage frontend issues within a workflow similar to the one we follow for the main Dataverse repository, it is necessary to define an appropriate QA process that suits the needs of a React SPA, which may differ from those of the Dataverse backend.
            
            The goal is to define a QA process guideline that allows the Dataverse QA team to perform the appropriate actions on the Dataverse frontend, before merging any PR.
            
            ## What kind of user is the feature intended for?
            Dataverse frontend developers and QA
            
            ## What inspired the request?
            - Current opened PR #4 
            - Discussion with @pdurbin, @mreekie and @kcondon
            
            ## What existing behavior do you want changed?
            N/A
            
            ## Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            
            ## Any related open or closed issues to this feature request?
            
            - #1 
            - #2 
            - #3 </body>
            <bodyText>Overview of the Feature Request
            In order to manage frontend issues within a workflow similar to the one we follow for the main Dataverse repository, it is necessary to define an appropriate QA process that suits the needs of a React SPA, which may differ from those of the Dataverse backend.
            The goal is to define a QA process guideline that allows the Dataverse QA team to perform the appropriate actions on the Dataverse frontend, before merging any PR.
            What kind of user is the feature intended for?
            Dataverse frontend developers and QA
            What inspired the request?
            
            Current opened PR #4
            Discussion with @pdurbin, @mreekie and @kcondon
            
            What existing behavior do you want changed?
            N/A
            Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            Any related open or closed issues to this feature request?
            
            #1
            #2
            #3</bodyText>
            <closed>True</closed>
            <closedAt>2023-02-24T15:14:44Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>5</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Define and establish the Dataverse frontend QA process</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/5</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Define and establish the Dataverse frontend QA process</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgE8wwQ</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>MellyGray</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            Even though this issue is created without having established the full scope of the SPA MVP first milestone beforehand, we already know that we need this first issue to establish the skeleton of the React application.
            
            The goal is to create a primitive React SPA, empty in terms of Dataverse features, with a simple "Hello Dataverse" message. This will initialize the codebase for this project, which we will evolve in subsequent issues.
            
            ## What kind of user is the feature intended for?
            Dataverse frontend developers
            
            ## What inspired the request?
            - Current work on SPA MVP Strategy
            - MVP Strategy document: [link](https://docs.google.com/document/d/1vOSsIGGCbgal4f_lSp1yInQifBcmo5vZ-Z9pfkVDyG4)
            
            ## What existing behavior do you want changed?
            N/A
            
            ## Any brand new behavior do you want to add to Dataverse Frontend?
            React application setup with "Hello Dataverse" message
            
            ## Any related open or closed issues to this feature request?
            
            - https://github.com/IQSS/dataverse/issues/9347
            </body>
            <bodyText>Overview of the Feature Request
            Even though this issue is created without having established the full scope of the SPA MVP first milestone beforehand, we already know that we need this first issue to establish the skeleton of the React application.
            The goal is to create a primitive React SPA, empty in terms of Dataverse features, with a simple "Hello Dataverse" message. This will initialize the codebase for this project, which we will evolve in subsequent issues.
            What kind of user is the feature intended for?
            Dataverse frontend developers
            What inspired the request?
            
            Current work on SPA MVP Strategy
            MVP Strategy document: link
            
            What existing behavior do you want changed?
            N/A
            Any brand new behavior do you want to add to Dataverse Frontend?
            React application setup with "Hello Dataverse" message
            Any related open or closed issues to this feature request?
            
            IQSS/dataverse#9347</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-07T10:56:19Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>1</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Create the skeleton of the React application</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/1</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create the skeleton of the React application</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Not-In-This-List</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgExTWA</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>MellyGray</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            [Storybook](https://storybook.js.org/) is an open source frontend tool for building UI components and pages in isolation. This tool has many useful features that we can use for the SPA development, such as enhanced testability, easy components reutilization, documentation, etc.
            
            The goal of this issue is to setup Storybook in the project and prepare it for the development of upcoming frontend features.
            
            ## What kind of user is the feature intended for?
            Dataverse frontend developers and QA
            
            ## What inspired the request?
            - Current work on SPA MVP Strategy
            - MVP Strategy document: [link](https://docs.google.com/document/d/1vOSsIGGCbgal4f_lSp1yInQifBcmo5vZ-Z9pfkVDyG4)
            
            ## What existing behavior do you want changed?
            N/A
            
            ## Any brand new behavior do you want to add to Dataverse Frontend?
            Storybook setup
            
            ## Any related open or closed issues to this feature request?
            
            - https://github.com/IQSS/dataverse-frontend/issues/2</body>
            <bodyText>Overview of the Feature Request
            Storybook is an open source frontend tool for building UI components and pages in isolation. This tool has many useful features that we can use for the SPA development, such as enhanced testability, easy components reutilization, documentation, etc.
            The goal of this issue is to setup Storybook in the project and prepare it for the development of upcoming frontend features.
            What kind of user is the feature intended for?
            Dataverse frontend developers and QA
            What inspired the request?
            
            Current work on SPA MVP Strategy
            MVP Strategy document: link
            
            What existing behavior do you want changed?
            N/A
            Any brand new behavior do you want to add to Dataverse Frontend?
            Storybook setup
            Any related open or closed issues to this feature request?
            
            #2</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-07T10:57:03Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>3</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Storybook setup</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/3</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Storybook setup</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgE2tZM</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>GPortas</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            The code repository does not have the appropriate tools and resources to properly categorize/tag the created issues, as well as issue templates to standardize its creation and structure.
            
            These tools are necessary to be able to manage and visualize the evolution of the project, as well as the prioritization and monitoring of its issues in the backlog boards.
            
            We can consider the existing tools of this nature that the Dataverse GitHub repository already has. (For example: I have already copied the sizing tags in this repository).
            
            ## What kind of user is the feature intended for?
            Dataverse developers and PMs
            
            ## What inspired the request?
            Creating first dataverse-frontend issue #1
            
            ## What existing behavior do you want changed?
            Repository management tooling
            
            ## Any brand new behavior do you want to add to Dataverse Frontend?
            New tags and issue templates, as well as any other helpful tool.
            
            ## Any related open or closed issues to this feature request?
            No</body>
            <bodyText>Overview of the Feature Request
            The code repository does not have the appropriate tools and resources to properly categorize/tag the created issues, as well as issue templates to standardize its creation and structure.
            These tools are necessary to be able to manage and visualize the evolution of the project, as well as the prioritization and monitoring of its issues in the backlog boards.
            We can consider the existing tools of this nature that the Dataverse GitHub repository already has. (For example: I have already copied the sizing tags in this repository).
            What kind of user is the feature intended for?
            Dataverse developers and PMs
            What inspired the request?
            Creating first dataverse-frontend issue #1
            What existing behavior do you want changed?
            Repository management tooling
            Any brand new behavior do you want to add to Dataverse Frontend?
            New tags and issue templates, as well as any other helpful tool.
            Any related open or closed issues to this feature request?
            No</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-08T20:27:23Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>2</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Configure the GitHub repository for its administration and evolution</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/2</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Configure the GitHub repository for its administration and evolution</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgExWOM</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>ekraffmiller</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            On March 14th Storybook is going to officially release Storybook 7. We are currently using the SB v7 Beta in the project knowing that this date was close so now it's time to do the upgrade.
            
            ## What kind of user is the feature intended for?
            
            Developers and QA. 
            
            ## What inspired the request?
            We are currently using the SB v7 Beta in the project because it was the best way to migrate Storybook to Vite and we knew the release date was close, now is time to do the upgrade.
            
            ## What existing behavior do you want changed?
            We want to change the package json Storybook versions from beta to oficial v7 and any other necessary change for the upgrade
            
            ## Any brand new behavior do you want to add to Dataverse?
            No
            
            ## Any open or closed issues related to this feature request?
            https://github.com/IQSS/dataverse-frontend/issues/10</body>
            <bodyText>Overview of the Feature Request
            On March 14th Storybook is going to officially release Storybook 7. We are currently using the SB v7 Beta in the project knowing that this date was close so now it's time to do the upgrade.
            What kind of user is the feature intended for?
            Developers and QA.
            What inspired the request?
            We are currently using the SB v7 Beta in the project because it was the best way to migrate Storybook to Vite and we knew the release date was close, now is time to do the upgrade.
            What existing behavior do you want changed?
            We want to change the package json Storybook versions from beta to oficial v7 and any other necessary change for the upgrade
            Any brand new behavior do you want to add to Dataverse?
            No
            Any open or closed issues related to this feature request?
            #10</bodyText>
            <closed>True</closed>
            <closedAt>2023-04-06T13:41:56Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>20</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Upgrade Storybook from v7-beta to v7</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/20</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Upgrade Storybook from v7-beta to v7</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 29, 2023</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFbBOc</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MTkw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MTgx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>GPortas</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            This issue is part of the scope of #6.
            
            The goal is to create a mechanism that allows deploying the frontend application to a remote S3 bucket. While this will not be the only and standard solution for frontend deployment, this mechanism provides value for test or QA environments where we use S3. This can also be useful for future installations that also use S3.
            
            ## What kind of user is the feature intended for?
            Dataverse frontend developers and QA
            
            ## What inspired the request?
            - Working on #6 
            - Discussion with @pdurbin about splitting #6 
            
            ## What existing behavior do you want changed?
            N/A
            
            ## Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            
            ## Any related open or closed issues to this feature request?
            - #6 </body>
            <bodyText>Overview of the Feature Request
            This issue is part of the scope of #6.
            The goal is to create a mechanism that allows deploying the frontend application to a remote S3 bucket. While this will not be the only and standard solution for frontend deployment, this mechanism provides value for test or QA environments where we use S3. This can also be useful for future installations that also use S3.
            What kind of user is the feature intended for?
            Dataverse frontend developers and QA
            What inspired the request?
            
            Working on #6
            Discussion with @pdurbin about splitting #6
            
            What existing behavior do you want changed?
            N/A
            Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            Any related open or closed issues to this feature request?
            
            #6</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-21T21:16:42Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 1</name>
              </nodes>
              <nodes>
                <name>D: Infra &amp; Deployment Setup</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>17</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Add a mechanism for automated deployment to S3</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/17</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 1</name>
                </nodes>
                <nodes>
                  <name>D: Infra &amp; Deployment Setup</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add a mechanism for automated deployment to S3</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFa90Q</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>MellyGray</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            The goal is to set up a mechanism to measure the test coverage of the frontend application code.
            
            A minimum coverage percentage must be set and the measurement must run in an automated way (possibly in a commit-triggered action) to verify that the code equals or exceeds the minimum coverage. The successful verification must be a requirement for a PR to be approved.
            
            ## What kind of user is the feature intended for?
            Dataverse frontend developers and QA
            
            ## What inspired the request?
            - Discussion with @MellyGray
            - Dataverse core repository test coverage measurement
            
            ## What existing behavior do you want changed?
            N/A
            
            ## Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            
            ## Any related open or closed issues to this feature request?
            N/A</body>
            <bodyText>Overview of the Feature Request
            The goal is to set up a mechanism to measure the test coverage of the frontend application code.
            A minimum coverage percentage must be set and the measurement must run in an automated way (possibly in a commit-triggered action) to verify that the code equals or exceeds the minimum coverage. The successful verification must be a requirement for a PR to be approved.
            What kind of user is the feature intended for?
            Dataverse frontend developers and QA
            What inspired the request?
            
            Discussion with @MellyGray
            Dataverse core repository test coverage measurement
            
            What existing behavior do you want changed?
            N/A
            Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            Any related open or closed issues to this feature request?
            N/A</bodyText>
            <closed>True</closed>
            <closedAt>2023-04-10T11:36:20Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>19</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Add a test coverage measurement mechanism</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/19</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add a test coverage measurement mechanism</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFbAAM</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>GPortas</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            This issue is part of the scope of #6.
            
            The goal is to create a mechanism that allows deploying the frontend application to a remote Payara server. This will allow the Dataverse frontend to be installed in an "all in one" way alongside the Dataverse backend. The option to deploy to Payara should appear next to the S3 option when triggering the "deploy" GitHub workflow.
            
            ## What kind of user is the feature intended for?
            Dataverse frontend developers and QA
            
            ## What inspired the request?
            - Working on #6 
            - Discussion with @pdurbin about splitting #6 
            
            ## What existing behavior do you want changed?
            N/A
            
            ## Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            
            ## Any related open or closed issues to this feature request?
            - #6 
            - #17 </body>
            <bodyText>Overview of the Feature Request
            This issue is part of the scope of #6.
            The goal is to create a mechanism that allows deploying the frontend application to a remote Payara server. This will allow the Dataverse frontend to be installed in an "all in one" way alongside the Dataverse backend. The option to deploy to Payara should appear next to the S3 option when triggering the "deploy" GitHub workflow.
            What kind of user is the feature intended for?
            Dataverse frontend developers and QA
            What inspired the request?
            
            Working on #6
            Discussion with @pdurbin about splitting #6
            
            What existing behavior do you want changed?
            N/A
            Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            Any related open or closed issues to this feature request?
            
            #6
            #17</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-27T20:19:10Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 1</name>
              </nodes>
              <nodes>
                <name>D: Infra &amp; Deployment Setup</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>18</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Add a mechanism for automated deployment to Payara</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/18</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 1</name>
                </nodes>
                <nodes>
                  <name>D: Infra &amp; Deployment Setup</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add a mechanism for automated deployment to Payara</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFbAH8</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>ekraffmiller</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            As part of our testing efforts, we want to analyze the capabilities of Storybook for UI testing integration. The aim is to determine if it makes sense to integrate UI tests with Storybook, and if so , how should we do it.
            
            A part from that we want to check if Cypress tests can be automatically generated using Storybook
            
            We already have unit tests with Vite and e2e tests with Cypress. We also have the coverage check using Vitest report. We need to check if it makes sense to change this tools by Storybook testing tools.
            
            ## What kind of user is the feature intended for?
            
            
            ## What inspired the request?
            - [Storybook 7 event ](https://www.youtube.com/watch?v=P0hJm5v8TJw)
            - Frontend subgroup weekly meeting
            
            ## What existing behavior do you want changed?
            This issue want change any behaviour, it's an analysis.
            
            ## Any brand new behavior do you want to add to Dataverse?
            None
            
            ## Any open or closed issues related to this feature request?
            
            - #20 
            - #19 </body>
            <bodyText>Overview of the Feature Request
            As part of our testing efforts, we want to analyze the capabilities of Storybook for UI testing integration. The aim is to determine if it makes sense to integrate UI tests with Storybook, and if so , how should we do it.
            A part from that we want to check if Cypress tests can be automatically generated using Storybook
            We already have unit tests with Vite and e2e tests with Cypress. We also have the coverage check using Vitest report. We need to check if it makes sense to change this tools by Storybook testing tools.
            What kind of user is the feature intended for?
            What inspired the request?
            
            Storybook 7 event 
            Frontend subgroup weekly meeting
            
            What existing behavior do you want changed?
            This issue want change any behaviour, it's an analysis.
            Any brand new behavior do you want to add to Dataverse?
            None
            Any open or closed issues related to this feature request?
            
            #20
            #19</bodyText>
            <closed>True</closed>
            <closedAt>2023-04-05T15:04:20Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>27</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Analyze Storybook Testing Capabilities for UI Testing Integration</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/27</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Analyze Storybook Testing Capabilities for UI Testing Integration</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 29, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFiCag</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>MellyGray</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            For the development of the different Dataverse functionalities, we need to identify the common UI primitives shared across the application, such as generic buttons, text fields, etc, that will be part of the Dataverse Design System.
            
            Since the Dataverse UI is already developed in JSF and there is already documentation related to this topic (https://guides.dataverse.org/en/latest/style/patterns.html), the ultimate goal of this issue is to analyze the existing UI and resources to identify and create issues corresponding to the implementation of the different UI elements.
            
            Considerations:
            
            - There may be elements that, in addition to being used directly, also compound other larger elements that are also used in different places.
            - We must focus only on the components within the scope of the MVP functionalities
            - App-specific components that contain business logic should not be included
            
            Design system elements don't need to be atoms they can also be molecules as long as they are not business specific
            Example atom (a button):
            ![image](https://user-images.githubusercontent.com/23359572/224773247-f706cbe3-ff88-4f38-a4fd-8e06932da276.png)
            Example molecule (a modal):
            ![image](https://user-images.githubusercontent.com/23359572/224772756-5b651297-97dd-416d-a168-4a113eb88b48.png)
            
            A part from that, we'll use this issue to think about UI components documentation Guidelines. Using for example the Storybook docs capabilities
            
            ## What kind of user is the feature intended for?
            Dataverse frontend developers
            
            ## What inspired the request?
            - MVP Strategy document: [link](https://docs.google.com/document/d/1vOSsIGGCbgal4f_lSp1yInQifBcmo5vZ-Z9pfkVDyG4)
            - Frontend team meeting about initial contributions
            
            ## What existing behavior do you want changed?
            N/A
            
            ## Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            
            ## Any related open or closed issues to this feature request?
            N/A</body>
            <bodyText>Overview of the Feature Request
            For the development of the different Dataverse functionalities, we need to identify the common UI primitives shared across the application, such as generic buttons, text fields, etc, that will be part of the Dataverse Design System.
            Since the Dataverse UI is already developed in JSF and there is already documentation related to this topic (https://guides.dataverse.org/en/latest/style/patterns.html), the ultimate goal of this issue is to analyze the existing UI and resources to identify and create issues corresponding to the implementation of the different UI elements.
            Considerations:
            
            There may be elements that, in addition to being used directly, also compound other larger elements that are also used in different places.
            We must focus only on the components within the scope of the MVP functionalities
            App-specific components that contain business logic should not be included
            
            Design system elements don't need to be atoms they can also be molecules as long as they are not business specific
            Example atom (a button):
            
            Example molecule (a modal):
            
            A part from that, we'll use this issue to think about UI components documentation Guidelines. Using for example the Storybook docs capabilities
            What kind of user is the feature intended for?
            Dataverse frontend developers
            What inspired the request?
            
            MVP Strategy document: link
            Frontend team meeting about initial contributions
            
            What existing behavior do you want changed?
            N/A
            Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            Any related open or closed issues to this feature request?
            N/A</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: Design System</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>14</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Identify UI elements for the Dataverse Design System and create issues for their development</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/14</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: Design System</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Identify UI elements for the Dataverse Design System and create issues for their development</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 29, 2023</name>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFTjSo</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>GPortas</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            Since the early discussions about modularity in the Dataverse SPA, we suggested the idea of creating a Dataverse API Client module / library, which would encapsulate the Dataverse API access logic so that it can be reused by other applications other than the Dataverse SPA.
            
            Currently there is already an npm module for this: https://www.npmjs.com/package/js-dataverse.
            Actually, this module is not heavily used and is a bit old. We need to analyze it in more detail to decide whether to build on top of it and continue its evolution, or redo it from scratch considering the design and functionality that the module already provides.
            
            ## What kind of user is the feature intended for?
            Dataverse frontend developers
            
            ## What inspired the request?
            - MVP Strategy document: [link](https://docs.google.com/document/d/1vOSsIGGCbgal4f_lSp1yInQifBcmo5vZ-Z9pfkVDyG4)
            - New potential issues requiring connectivity to the Dataverse API
            
            ## What existing behavior do you want changed?
            N/A
            
            ## Any brand new behavior do you want to add to Dataverse Frontend?
            - API Client / Data Access Layer
            
            ## Any related open or closed issues to this feature request?
            - #12 </body>
            <bodyText>Overview of the Feature Request
            Since the early discussions about modularity in the Dataverse SPA, we suggested the idea of creating a Dataverse API Client module / library, which would encapsulate the Dataverse API access logic so that it can be reused by other applications other than the Dataverse SPA.
            Currently there is already an npm module for this: https://www.npmjs.com/package/js-dataverse.
            Actually, this module is not heavily used and is a bit old. We need to analyze it in more detail to decide whether to build on top of it and continue its evolution, or redo it from scratch considering the design and functionality that the module already provides.
            What kind of user is the feature intended for?
            Dataverse frontend developers
            What inspired the request?
            
            MVP Strategy document: link
            New potential issues requiring connectivity to the Dataverse API
            
            What existing behavior do you want changed?
            N/A
            Any brand new behavior do you want to add to Dataverse Frontend?
            
            API Client / Data Access Layer
            
            Any related open or closed issues to this feature request?
            
            #12</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-27T08:13:38Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: API connectivity</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>13</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Analyze js-dataverse module and decide whether to build on top of it or redo it from scratch</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/13</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: API connectivity</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Analyze js-dataverse module and decide whether to build on top of it or redo it from scratch</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 15, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFThGM</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>GPortas</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            The goal is to create a npm module to include the Dataverse API access logic, decoupled from the frontend application, so it can be reused from other applications and future plugins.
            
            This module is similar to the exiting [js-dataverse module](https://github.com/IQSS/dataverse-client-javascript), but with a more advanced design. In the analysis done in #13, we can find the necessary aspects for the new module. [See the analysis document](https://docs.google.com/document/d/1s_ZPr3BRlCuL5Jch8qJ3odncIgkmo6krSn2tMVv5e44)
            
            This npm module will have an associated GitHub repository, as well as independent versioning. The module will be installed on the Dataverse Frontend application, as well as any other application which needs to use it.
            
            In the scope of this issue, and to cover an initial API endpoint within the module, we'll focus on covering endpoints related to version number retrieval, which is required for #12.
            
            ## What kind of user is the feature intended for?
            Dataverse frontend developers
            
            ## What inspired the request?
            - #13 
            
            ## What existing behavior do you want changed?
            N/A
            
            ## Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            
            ## Any related open or closed issues to this feature request?
            - #13 
            - #12  
            - #28</body>
            <bodyText>Overview of the Feature Request
            The goal is to create a npm module to include the Dataverse API access logic, decoupled from the frontend application, so it can be reused from other applications and future plugins.
            This module is similar to the exiting js-dataverse module, but with a more advanced design. In the analysis done in #13, we can find the necessary aspects for the new module. See the analysis document
            This npm module will have an associated GitHub repository, as well as independent versioning. The module will be installed on the Dataverse Frontend application, as well as any other application which needs to use it.
            In the scope of this issue, and to cover an initial API endpoint within the module, we'll focus on covering endpoints related to version number retrieval, which is required for #12.
            What kind of user is the feature intended for?
            Dataverse frontend developers
            What inspired the request?
            
            #13
            
            What existing behavior do you want changed?
            N/A
            Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            Any related open or closed issues to this feature request?
            
            #13
            #12
            #28</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 80</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: API connectivity</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>39</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Create a npm module for a Dataverse API client so the frontend application and other community applications can use it</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/39</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 80</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: API connectivity</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create a npm module for a Dataverse API client so the frontend application and other community applications can use it</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFuG7E</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-02-01T21:52:16Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9339</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>9354</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>pom file update to build XOAI-5.0.0 #9339</title>
            <url>https://github.com/IQSS/dataverse/pull/9354</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>pom file update to build XOAI-5.0.0 #9339</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEqK2w</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-02-06T22:13:58Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>dependencies</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9188</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Bump postgresql from 42.5.0 to 42.5.1 in /modules/dataverse-parent</title>
            <url>https://github.com/IQSS/dataverse/pull/9188</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>dependencies</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Bump postgresql from 42.5.0 to 42.5.1 in /modules/dataverse-parent</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>January 25, 2023</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEucfE</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>The best guess so far on this that it's related to usage limits.
            We don't know why however.
            
            
            Quick summary:
            We had a Github Actions outage starting on January 27th.
            It was reported by @pdurbin &amp; @kuriwaki in [GitHub Actions failing due to spending limits #125](https://github.com/IQSS/dataverse-client-r/issues/125)
            It ended on February 1st 
            
            The thing that correlates to the recovery was the start of the new month.
            We don't understand what exactly caused the issue which means it could happen again.
            
            There is information on the incident on [this thread](https://iqss.slack.com/archives/C03R1E7T4KA/p1674840525617389) in Slack</body>
            <bodyText>The best guess so far on this that it's related to usage limits.
            We don't know why however.
            Quick summary:
            We had a Github Actions outage starting on January 27th.
            It was reported by @pdurbin &amp; @kuriwaki in GitHub Actions failing due to spending limits #125
            It ended on February 1st
            The thing that correlates to the recovery was the start of the new month.
            We don't understand what exactly caused the issue which means it could happen again.
            There is information on the incident on this thread in Slack</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-09T16:35:52Z</closedAt>
            <labels>
              <nodes>
                <name>DevOps: Problem</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9355</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Spike: Discover Root cause of GitHub actions stoppage in January (Before the end of February!)</title>
            <url>https://github.com/IQSS/dataverse/issues/9355</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>DevOps: Problem</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Spike: Discover Root cause of GitHub actions stoppage in January (Before the end of February!)</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Not-In-This-List</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEuf6A</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MjAw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MTkx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>Scope: try to ingest a DV dataset into our demo instance of Google Data Commons (GDC).
            
            - how to import data into GDC explained [here](https://github.com/datacommonsorg/data/blob/master/docs/README.md);
            
            - test data set is [here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/SEGOVA). This data has both geographical and temporal resolution using standardized identifiers.
            
            expected output should be:
            - getting this data indexed into our [instance](https://gdc.dataverse.org) of GDC
            - back reference to Dataverse (see red oval in img below) 
            
            ![Image](https://user-images.githubusercontent.com/5621970/219062033-8221918e-09dc-476a-b720-17199c9578cd.png)
            
            
            
            Stefano, Julian and ? (I need a dev).
            </body>
            <bodyText>Scope: try to ingest a DV dataset into our demo instance of Google Data Commons (GDC).
            
            
            how to import data into GDC explained here;
            
            
            test data set is here. This data has both geographical and temporal resolution using standardized identifiers.
            
            
            expected output should be:
            
            getting this data indexed into our instance of GDC
            back reference to Dataverse (see red oval in img below)
            
            
            Stefano, Julian and ? (I need a dev).</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>D: GDC: Interop With DV</name>
              </nodes>
              <nodes>
                <name>bklog: Deliverable</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>17</number>
            <repository>
              <name>dataverse-pm</name>
            </repository>
            <title>Deliverable: Investigate interoperability between datacommons and dataverse</title>
            <url>https://github.com/IQSS/dataverse-pm/issues/17</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOIwMRzQ</id>
                <name>dataverse-pm</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>D: GDC: Interop With DV</name>
                </nodes>
                <nodes>
                  <name>bklog: Deliverable</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Deliverable: Investigate interoperability between datacommons and dataverse</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Datacommons/DV Interop</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEuge8</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>sekmiller</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>work to get testing ingestions of dataverse data into google datacommons.
            
            Re-adding info from 9368
            
            - how to import data into GDC explained [here](https://github.com/datacommonsorg/data/blob/master/docs/README.md);
            
            - test data set is [here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/SEGOVA). This data has both geographical and temporal resolution using standardized identifiers.
            
            expected output should be:
            - getting this data indexed into our [instance](https://gdc.dataverse.org) of GDC
            - back reference to Dataverse (see red oval in img below) 
            
            ![Image](https://user-images.githubusercontent.com/5621970/219062033-8221918e-09dc-476a-b720-17199c9578cd.png)
            
            
            
            Stefano, Julian and ? (I need a dev).
            </body>
            <bodyText>work to get testing ingestions of dataverse data into google datacommons.
            Re-adding info from 9368
            
            
            how to import data into GDC explained here;
            
            
            test data set is here. This data has both geographical and temporal resolution using standardized identifiers.
            
            
            expected output should be:
            
            getting this data indexed into our instance of GDC
            back reference to Dataverse (see red oval in img below)
            
            
            Stefano, Julian and ? (I need a dev).</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-15T20:51:27Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 80</name>
              </nodes>
              <nodes>
                <name>D: GDC: Interop With DV</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9385</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Spike: Investigate interoperability between google datacommons and dataverse</title>
            <url>https://github.com/IQSS/dataverse/issues/9385</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 80</name>
                </nodes>
                <nodes>
                  <name>D: GDC: Interop With DV</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Spike: Investigate interoperability between google datacommons and dataverse</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Datacommons/DV Interop</text>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgE3FFs</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9194</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>QDR</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9195</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/9194-fix curate command validation</title>
            <url>https://github.com/IQSS/dataverse/pull/9195</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>QDR</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/9194-fix curate command validation</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEvuKs</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9185</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>QDR</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9186</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/9185 contact email updates</title>
            <url>https://github.com/IQSS/dataverse/pull/9186</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>QDR</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/9185 contact email updates</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEv1A8</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>This deliverable defines our support for the 5 core pids.  
            
            For most of the 5, we offer support already.
            - we will document what that support is.
            
            For the others:
            - We will define how we intend to support it right now.
            - We will implement that support.
            
            
            This came out of our meeting on Jan 31st, 2023. We discussed how we are going to define our support for each of these PIDs through a definition of "we support this type of data", "for this type of field"
            
            
            ![image](https://user-images.githubusercontent.com/47538814/217355188-2cda0013-123d-4dcb-a14b-76c1103d1623.png)
            
            
            
            Includes...
            - https://github.com/IQSS/dataverse/issues/9150
            - https://github.com/IQSS/dataverse/issues/9151
            - https://github.com/IQSS/dataverse/issues/7285
            - https://github.com/IQSS/dataverse/issues/9370
            
            ---
            Just a reminder that this is a "deliverable" issue. It does not go on the sprint board.  It's a group of other issues that represent the delivery of some objective for us to get to or functionality delivered. 
            
            </body>
            <bodyText>This deliverable defines our support for the 5 core pids.
            For most of the 5, we offer support already.
            
            we will document what that support is.
            
            For the others:
            
            We will define how we intend to support it right now.
            We will implement that support.
            
            This came out of our meeting on Jan 31st, 2023. We discussed how we are going to define our support for each of these PIDs through a definition of "we support this type of data", "for this type of field"
            
            Includes...
            
            IQSS/dataverse#9150
            IQSS/dataverse#9151
            IQSS/dataverse#7285
            IQSS/dataverse#9370
            
            
            Just a reminder that this is a "deliverable" issue. It does not go on the sprint board.  It's a group of other issues that represent the delivery of some objective for us to get to or functionality delivered.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>D: 5 Core PIDs</name>
              </nodes>
              <nodes>
                <name>bklog: Deliverable</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>19</number>
            <repository>
              <name>dataverse-pm</name>
            </repository>
            <title>Deliverable: Support the  5 core persistent identifiers in Dataverse</title>
            <url>https://github.com/IQSS/dataverse-pm/issues/19</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOIwMRzQ</id>
                <name>dataverse-pm</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>D: 5 Core PIDs</name>
                </nodes>
                <nodes>
                  <name>bklog: Deliverable</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Deliverable: Support the  5 core persistent identifiers in Dataverse</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>5 Core PIDs</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEv_Uw</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>In Harvard Dataverse,  we have a group of Shib groups. However granting a role assignment to this group doesn't seem to work.
            
            If I add a user to that group, that user does get access, so it's not a group issue. 
            
            Similarly if I give the shib group access directly, it also works.
            
            </body>
            <bodyText>In Harvard Dataverse,  we have a group of Shib groups. However granting a role assignment to this group doesn't seem to work.
            If I add a user to that group, that user does get access, so it's not a group issue.
            Similarly if I give the shib group access directly, it also works.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9369</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Shib group in another group doesn't work</title>
            <url>https://github.com/IQSS/dataverse/issues/9369</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Shib group in another group doesn't work</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEwFlM</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>pdurbin</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>I think this is a 10 (1 day's work). It's just adding `?format=original` to the Dataverse content provider in repo2docker.
            
            Related issues:
            
            - https://github.com/jupyterhub/repo2docker/issues/1242
            - #8524
            - https://github.com/IQSS/dataverse.harvard.edu/issues/208
            - https://github.com/IQSS/dataverse.harvard.edu/issues/209</body>
            <bodyText>I think this is a 10 (1 day's work). It's just adding ?format=original to the Dataverse content provider in repo2docker.
            Related issues:
            
            jupyterhub/repo2docker#1242
            #8524
            IQSS/dataverse.harvard.edu#208
            IQSS/dataverse.harvard.edu#209</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-29T17:53:59Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: External Tool</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.3.2</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>9374</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Fix Binder and Whole Tale (repo2docker) to download original files rather than archival .tab files</title>
            <url>https://github.com/IQSS/dataverse/issues/9374</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: External Tool</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.3.2</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Fix Binder and Whole Tale (repo2docker) to download original files rather than archival .tab files</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>NIH bklog items (Stefano)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgExfKI</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>We're currently testing fresh installs of [8305-payara6-ee10](https://github.com/IQSS/dataverse/tree/8305-payara6-ee10) on Payara 6, but extant installations will need a reliable upgrade path from Payara 5. Opening this issue to track that work.</body>
            <bodyText>We're currently testing fresh installs of 8305-payara6-ee10 on Payara 6, but extant installations will need a reliable upgrade path from Payara 5. Opening this issue to track that work.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>D: Payara 6 Upgrade</name>
              </nodes>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9340</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>determine upgrade path from Payara 5 to 6</title>
            <url>https://github.com/IQSS/dataverse/issues/9340</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>D: Payara 6 Upgrade</name>
                </nodes>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>determine upgrade path from Payara 5 to 6</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Upgrades in Prep for DV6</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEwBIM</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>8094</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Code Infrastructure</name>
              </nodes>
              <nodes>
                <name>Feature: Installer</name>
              </nodes>
              <nodes>
                <name>Feature: Performance &amp; Stability</name>
              </nodes>
              <nodes>
                <name>Feature: Installation Guide</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>Containers &amp; Cloud</name>
              </nodes>
              <nodes>
                <name>D: Payara 6 Upgrade</name>
              </nodes>
              <totalCount>7</totalCount>
            </labels>
            <number>9291</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>8094 java17</title>
            <url>https://github.com/IQSS/dataverse/pull/9291</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Code Infrastructure</name>
                </nodes>
                <nodes>
                  <name>Feature: Installer</name>
                </nodes>
                <nodes>
                  <name>Feature: Performance &amp; Stability</name>
                </nodes>
                <nodes>
                  <name>Feature: Installation Guide</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>Containers &amp; Cloud</name>
                </nodes>
                <nodes>
                  <name>D: Payara 6 Upgrade</name>
                </nodes>
                <totalCount>7</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>8094 java17</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Upgrades in Prep for DV6</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEwBDA</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>**Overview of the Feature Request**
            
            Solr `8.X`, specifically, `8.11.2` according to [this page](https://solr.apache.org/downloads.html): "is the last release in the 8.x series."  This means it likely won't be receiving any more updates, features, or patches.  This also may have implications from a security perspective.  The Dataverse Solr schema and [major changes](https://solr.apache.org/guide/solr/latest/upgrade-notes/major-changes-in-solr-9.html) should be reviewed and tested.
            
            - [ ] Evaluate and update Solr schema if needed
            - [ ] Smoke-test with Solr `9.X`
            - [ ] Update documentation
            - [ ] Document migration steps?
            
            **What kind of user is the feature intended for?**
            
            Sysadmin and developers
            
            **What inspired the request?**
            
            
            **What existing behavior do you want changed?**
            
            
            **Any brand new behavior do you want to add to Dataverse?**
            
            
            **Any related open or closed issues to this feature request?**
            </body>
            <bodyText>Overview of the Feature Request
            Solr 8.X, specifically, 8.11.2 according to this page: "is the last release in the 8.x series."  This means it likely won't be receiving any more updates, features, or patches.  This also may have implications from a security perspective.  The Dataverse Solr schema and major changes should be reviewed and tested.
            
             Evaluate and update Solr schema if needed
             Smoke-test with Solr 9.X
             Update documentation
             Document migration steps?
            
            What kind of user is the feature intended for?
            Sysadmin and developers
            What inspired the request?
            What existing behavior do you want changed?
            Any brand new behavior do you want to add to Dataverse?
            Any related open or closed issues to this feature request?</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>D: Payara 6 Upgrade</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9260</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Test and move from Solr 8.X to Solr 9.X</title>
            <url>https://github.com/IQSS/dataverse/issues/9260</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>D: Payara 6 Upgrade</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Test and move from Solr 8.X to Solr 9.X</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Upgrades in Prep for DV6</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEwA_g</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MjEw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MjAx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-04-04T15:27:30Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Code Infrastructure</name>
              </nodes>
              <nodes>
                <name>Feature: Installer</name>
              </nodes>
              <nodes>
                <name>Feature: DOI &amp; Handle</name>
              </nodes>
              <nodes>
                <name>Feature: Installation Guide</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>Containers &amp; Cloud</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>bklog: NeedsDiscussion</name>
              </nodes>
              <nodes>
                <name>D: DataverseInDocker</name>
              </nodes>
              <totalCount>9</totalCount>
            </labels>
            <number>8828</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>7000 mpconfig pid doi hdl</title>
            <url>https://github.com/IQSS/dataverse/pull/8828</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Code Infrastructure</name>
                </nodes>
                <nodes>
                  <name>Feature: Installer</name>
                </nodes>
                <nodes>
                  <name>Feature: DOI &amp; Handle</name>
                </nodes>
                <nodes>
                  <name>Feature: Installation Guide</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>Containers &amp; Cloud</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>bklog: NeedsDiscussion</name>
                </nodes>
                <nodes>
                  <name>D: DataverseInDocker</name>
                </nodes>
                <totalCount>9</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>7000 mpconfig pid doi hdl</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 29, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Dataverse Team (Gustavo)</text>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFMT-4</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>There is a number of *old* open issues with requests for storage quotas, in different scenarios: 
            
            #4339 - requesting per-user quotas;
            #3939 - requesting per-dataset quotas;
            there's even an issue with a 3-digit number where collection-wise (well, "dataverse"-wise) quotas are mentioned: 
            #938 
            
            While I do believe we should consider all of the above, I am opening this narrowly-defined issue specifically for collection quotas, since this is becoming increasingly important. 
            
            Perhaps there should be the installation-wide size default. With a mechanism for assigning custom limits to specific collections. In other words this should be handled the same way custom stores are handled now. At a minimum, this could be another storage option in the collection settings (available to the superusers only). Or we could add a dashboard UI. 
            </body>
            <bodyText>There is a number of old open issues with requests for storage quotas, in different scenarios:
            #4339 - requesting per-user quotas;
            #3939 - requesting per-dataset quotas;
            there's even an issue with a 3-digit number where collection-wise (well, "dataverse"-wise) quotas are mentioned:
            #938
            While I do believe we should consider all of the above, I am opening this narrowly-defined issue specifically for collection quotas, since this is becoming increasingly important.
            Perhaps there should be the installation-wide size default. With a mechanism for assigning custom limits to specific collections. In other words this should be handled the same way custom stores are handled now. At a minimum, this could be another storage option in the collection settings (available to the superusers only). Or we could add a dashboard UI.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>D: FixRateLimitingBehaviors</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>8549</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Add mechanism for collection-wise storage size quotas</title>
            <url>https://github.com/IQSS/dataverse/issues/8549</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>D: FixRateLimitingBehaviors</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add mechanism for collection-wise storage size quotas</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Dataverse Team (Gustavo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDNX3U</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>This is a narrow case of the overall "rate limiting" umbrella issue. This would not attempt to throttle the overall traffic to the site, or to regulate the rate of requests from "normal" users (that would be better done within the application. This mechanism would be the first line of defense, for detecting *obvious* bot/scripted or otherwise automated crawling - for ex., repeated calls coming from the same ip plowing through the collection page facets without pausing between calls - before it even gets to the application. 
            
            This would be doing essentially what we periodically do with custom command line scripts in our production. But third party tools should be readily available for addressing this common problem.  
            </body>
            <bodyText>This is a narrow case of the overall "rate limiting" umbrella issue. This would not attempt to throttle the overall traffic to the site, or to regulate the rate of requests from "normal" users (that would be better done within the application. This mechanism would be the first line of defense, for detecting obvious bot/scripted or otherwise automated crawling - for ex., repeated calls coming from the same ip plowing through the collection page facets without pausing between calls - before it even gets to the application.
            This would be doing essentially what we periodically do with custom command line scripts in our production. But third party tools should be readily available for addressing this common problem.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>D: FixRateLimitingBehaviors</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9359</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Investigate adding Apache-level mechanism for rejecting aggressive robot crawling</title>
            <url>https://github.com/IQSS/dataverse/issues/9359</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>D: FixRateLimitingBehaviors</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Investigate adding Apache-level mechanism for rejecting aggressive robot crawling</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Dataverse Team (Gustavo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEqdH8</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>The JSESSIONID cookie issued by Dataverse explicitly set a SameSite value of `None`
            
            &gt; When a cookie is set to SameSite=None, it will be transmitted from requests originating from all origins. As such, requests originating from third-party websites will include the affected cookie. This increases the risk of Cross- Site Request Forgery (CSRF) and information leak attacks.
            
            
            **Set the SameSite flag in all cookies**
            The following example shows how the same session cookie is set with strict samesite setting:
            
            ```
            Set-Cookie: jsessionid= 71500be2a6a71a5e1edb02740fe16e32;
            SameSite=Strict; secure;
            ```
            
            I'm not sure what changing this setting might break; I just know how to copy-paste.</body>
            <bodyText>The JSESSIONID cookie issued by Dataverse explicitly set a SameSite value of None
            
            When a cookie is set to SameSite=None, it will be transmitted from requests originating from all origins. As such, requests originating from third-party websites will include the affected cookie. This increases the risk of Cross- Site Request Forgery (CSRF) and information leak attacks.
            
            Set the SameSite flag in all cookies
            The following example shows how the same session cookie is set with strict samesite setting:
            Set-Cookie: jsessionid= 71500be2a6a71a5e1edb02740fe16e32;
            SameSite=Strict; secure;
            
            I'm not sure what changing this setting might break; I just know how to copy-paste.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>27</number>
            <repository>
              <name>dataverse-security</name>
            </repository>
            <title>Cookies with SameSite set to none</title>
            <url>https://github.com/IQSS/dataverse-security/issues/27</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNzU2OTc3NTI=</id>
                <name>dataverse-security</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Cookies with SameSite set to none</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Dataverse Team (Gustavo)</name>
            </nodes>
            <totalCount>3</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEuc1s</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>Following up on the thread on the google group:
            https://groups.google.com/forum/?utm_medium=email&amp;utm_source=footer#!topic/dataverse-community/34E9foKnxQs 
            
            ### Userstory 
            As a researcher, I want to be able to cite, using a permanent identifier, a specific version of dataset to avoid any ambiguity and to make the citation machine-actionable. 
            
            ### How this should probably look
            
            Zenodo would be a good template here.
            1. A dataset has one "generic" DOI that always points to the latest version (this would be used if you e.g. just cite the data generically)
            2. A dataset has one DOI per version to allow to point to a specific version
            #### Example 
            https://doi.org/10.5281/zenodo.1041767 is the generic dataset DOI, always pointing to the most recent version, with 10.5281/zenodo.1188752 being the DOI for the 2nd (current) version and 10.5281/zenodo.1041768 the DOI for the first version
            
            ### Relationship to other features
            
            #### File DOIs:
            File DOIs are great (and by themselves necessary), but they are not a replacement for dataset version DOIs. Datasets are often made up of multiple files. An analysis script (which itself may be part of the data and thus versioned) may point to multiple files in a dataset. It's not feasible (or desirable) for a researcher to include the DOI for every file used in a citation. They want to point to one single DOI to reference the exact data (made up of multiple files) they've been using. This is equally true for quantiative and qualitative data, btw.
            
            File DOIs of files that are not changed between versions should remain stable (otherwise there's a potential to massively inflate the number of DOIs issued for no good reason)
            
            #### UNFs
            UNFs (at least for tabular data) help *ensure* that a cited dataset is the one being used, so they avoid using incorrect versions, but they do not function as identifiers, i.e. UNF:6:edx+kB6SY2N3Zt9OsUbp4A== tells me nothing about where to find that dataset.
            </body>
            <bodyText>Following up on the thread on the google group:
            https://groups.google.com/forum/?utm_medium=email&amp;utm_source=footer#!topic/dataverse-community/34E9foKnxQs
            Userstory
            As a researcher, I want to be able to cite, using a permanent identifier, a specific version of dataset to avoid any ambiguity and to make the citation machine-actionable.
            How this should probably look
            Zenodo would be a good template here.
            
            A dataset has one "generic" DOI that always points to the latest version (this would be used if you e.g. just cite the data generically)
            A dataset has one DOI per version to allow to point to a specific version
            
            Example
            https://doi.org/10.5281/zenodo.1041767 is the generic dataset DOI, always pointing to the most recent version, with 10.5281/zenodo.1188752 being the DOI for the 2nd (current) version and 10.5281/zenodo.1041768 the DOI for the first version
            Relationship to other features
            File DOIs:
            File DOIs are great (and by themselves necessary), but they are not a replacement for dataset version DOIs. Datasets are often made up of multiple files. An analysis script (which itself may be part of the data and thus versioned) may point to multiple files in a dataset. It's not feasible (or desirable) for a researcher to include the DOI for every file used in a citation. They want to point to one single DOI to reference the exact data (made up of multiple files) they've been using. This is equally true for quantiative and qualitative data, btw.
            File DOIs of files that are not changed between versions should remain stable (otherwise there's a potential to massively inflate the number of DOIs issued for no good reason)
            UNFs
            UNFs (at least for tabular data) help ensure that a cited dataset is the one being used, so they avoid using incorrect versions, but they do not function as identifiers, i.e. UNF:6:edx+kB6SY2N3Zt9OsUbp4A== tells me nothing about where to find that dataset.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Feature: DOI &amp; Handle</name>
              </nodes>
              <nodes>
                <name>HERMES</name>
              </nodes>
              <nodes>
                <name>Size: Queued</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>4499</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>DOIs for Dataset versions</title>
            <url>https://github.com/IQSS/dataverse/issues/4499</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: DOI &amp; Handle</name>
                </nodes>
                <nodes>
                  <name>HERMES</name>
                </nodes>
                <nodes>
                  <name>Size: Queued</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>DOIs for Dataset versions</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Dataverse Team (Gustavo)</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgDd6O0</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>We have decided to define how we support the big 5 PIDs.
            Types DOI and ORCID are generally seen as  well supported by Dataverse by the team.
            For this spike we just need to:
            - [ ] identify where/how we have documented our level of support for these two 
            OR
            - [ ] Create brief externally readable summaries of how we support them.</body>
            <bodyText>We have decided to define how we support the big 5 PIDs.
            Types DOI and ORCID are generally seen as  well supported by Dataverse by the team.
            For this spike we just need to:
            
             identify where/how we have documented our level of support for these two
            OR
             Create brief externally readable summaries of how we support them.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>spike</name>
              </nodes>
              <nodes>
                <name>D: 5 Core PIDs</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9370</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Spike:  issue to locate or document support for DOIs and ORCID</title>
            <url>https://github.com/IQSS/dataverse/issues/9370</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>spike</name>
                </nodes>
                <nodes>
                  <name>D: 5 Core PIDs</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Spike:  issue to locate or document support for DOIs and ORCID</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>5 Core PIDs</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEwMv4</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>Summary:
            I suggest that Crossref Funder Registry IDs be implemented in the Citation Metadata section Grant Information.
            
            Context:
            In a recent report [(https://doi.org/10.29242/report.effectivedatapractices2020),](https://doi.org/10.29242/report.effectivedatapractices2020) the Association of Research Libraries (ARL) recommends wide adoption of these 5 core PIDs to power findability of research data:
            
            ![image](https://user-images.githubusercontent.com/21955790/94335172-10523d80-ffda-11ea-91bd-8cdedab43036.png)
            
            I suggest that Crossref Funder Registry IDs be implemented in the Citation Metadata section Grant Information.
            </body>
            <bodyText>Summary:
            I suggest that Crossref Funder Registry IDs be implemented in the Citation Metadata section Grant Information.
            Context:
            In a recent report (https://doi.org/10.29242/report.effectivedatapractices2020), the Association of Research Libraries (ARL) recommends wide adoption of these 5 core PIDs to power findability of research data:
            
            I suggest that Crossref Funder Registry IDs be implemented in the Citation Metadata section Grant Information.</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-11T20:43:49Z</closedAt>
            <labels>
              <nodes>
                <name>Type: Suggestion</name>
              </nodes>
              <nodes>
                <name>Feature: Metadata</name>
              </nodes>
              <nodes>
                <name>User Role: Curator</name>
              </nodes>
              <nodes>
                <name>User Role: Depositor</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.5.1</name>
              </nodes>
              <nodes>
                <name>D: 5 Core PIDs</name>
              </nodes>
              <nodes>
                <name>Size: NoSprintCost</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.5.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.5.2</name>
              </nodes>
              <totalCount>9</totalCount>
            </labels>
            <number>7285</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Support for Crossref Funder Registry ID</title>
            <url>https://github.com/IQSS/dataverse/issues/7285</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Type: Suggestion</name>
                </nodes>
                <nodes>
                  <name>Feature: Metadata</name>
                </nodes>
                <nodes>
                  <name>User Role: Curator</name>
                </nodes>
                <nodes>
                  <name>User Role: Depositor</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.5.1</name>
                </nodes>
                <nodes>
                  <name>D: 5 Core PIDs</name>
                </nodes>
                <nodes>
                  <name>Size: NoSprintCost</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.5.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.5.2</name>
                </nodes>
                <totalCount>9</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Support for Crossref Funder Registry ID</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>5 Core PIDs</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgEPn1s</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>I just uploaded and HDF5 file to https://demo.dataverse.org/dataset.xhtml?persistentId=doi:10.70122/FK2/JTUS2J and the NcML file was correctly extracted...
            
            ![Screen Shot 2023-02-15 at 10 16 02 AM](https://user-images.githubusercontent.com/21006/219069332-7d457e47-6b4e-4381-bb0c-70a6d312e16b.png)
            
            ... but the eyeball is absent because the NcML previewer hasn't yet been added. Can we please add it to the demo site? I can also open a separate issue for Harvard Dataverse or we can just use this one.
            
            Please note that there are actually two previewers because there are two MIME types in play. The following is copied from https://github.com/gdcc/dataverse-previewers/blob/d8193b1083d0b84443303fc345d8d6d5e12d9f04/5.2curlcommands.md#ncml-previewer-requirements
            
            
            ```
            curl -X POST -H 'Content-type: application/json' http://localhost:8080/api/admin/externalTools -d \
            '{
              "displayName":"Show NcML (XML)",
              "description":"Metadata from HDF5 files.",
              "toolName":"ncmlPreviewer",
              "scope":"file",
              "types":["preview"],
              "toolUrl":"https://gdcc.github.io/dataverse-previewers/previewers/betatest/NcmlPreview.html",
              "toolParameters": {
                  "queryParameters":[
                    {"fileid":"{fileId}"},
                    {"siteUrl":"{siteUrl}"},
                    {"key":"{apiToken}"},
                    {"datasetid":"{datasetId}"},
                    {"datasetversion":"{datasetVersion}"},
                    {"locale":"{localeCode}"}
                  ]
                },
              "requirements": {
                "auxFilesExist": [
                  {
                    "formatTag": "NcML",
                    "formatVersion": "0.1"
                  }
                ]
              },
              "contentType":"application/x-hdf5"
            }'
            ```
            
            Thanks!</body>
            <bodyText>I just uploaded and HDF5 file to https://demo.dataverse.org/dataset.xhtml?persistentId=doi:10.70122/FK2/JTUS2J and the NcML file was correctly extracted...
            
            ... but the eyeball is absent because the NcML previewer hasn't yet been added. Can we please add it to the demo site? I can also open a separate issue for Harvard Dataverse or we can just use this one.
            Please note that there are actually two previewers because there are two MIME types in play. The following is copied from https://github.com/gdcc/dataverse-previewers/blob/d8193b1083d0b84443303fc345d8d6d5e12d9f04/5.2curlcommands.md#ncml-previewer-requirements
            curl -X POST -H 'Content-type: application/json' http://localhost:8080/api/admin/externalTools -d \
            '{
              "displayName":"Show NcML (XML)",
              "description":"Metadata from HDF5 files.",
              "toolName":"ncmlPreviewer",
              "scope":"file",
              "types":["preview"],
              "toolUrl":"https://gdcc.github.io/dataverse-previewers/previewers/betatest/NcmlPreview.html",
              "toolParameters": {
                  "queryParameters":[
                    {"fileid":"{fileId}"},
                    {"siteUrl":"{siteUrl}"},
                    {"key":"{apiToken}"},
                    {"datasetid":"{datasetId}"},
                    {"datasetversion":"{datasetVersion}"},
                    {"locale":"{localeCode}"}
                  ]
                },
              "requirements": {
                "auxFilesExist": [
                  {
                    "formatTag": "NcML",
                    "formatVersion": "0.1"
                  }
                ]
              },
              "contentType":"application/x-hdf5"
            }'
            
            Thanks!</bodyText>
            <closed>True</closed>
            <closedAt>2023-02-28T19:19:29Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: External Tool</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <nodes>
                <name>pm.netcdf-hdf5.d</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>213</number>
            <repository>
              <name>dataverse.harvard.edu</name>
            </repository>
            <title>add NcML previewers (HDF5 and NetCDF) to demo and Harvard Dataverse</title>
            <url>https://github.com/IQSS/dataverse.harvard.edu/issues/213</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNzQwNTY1NTE=</id>
                <name>dataverse.harvard.edu</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: External Tool</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <nodes>
                  <name>pm.netcdf-hdf5.d</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>add NcML previewers (HDF5 and NetCDF) to demo and Harvard Dataverse</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>NIH NetCDF (Phil)</text>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgE5-kI</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>Currently we get this error:
            
            "Unable to retrieve NcML file. Please try again. The most common issue is that your login has timed out. If the problem persists, please contact the support team of this data repository. Please include any status code included at the end of this message: Forbidden"
            
            ![221693399-e18ececd-197e-431f-b130-7eafb405f900](https://user-images.githubusercontent.com/21006/221956396-9f6bbccf-e2c3-41cb-9088-11c32c0199b1.png)
            
            We should update ncml.js to handle API tokens (like other previewers)
            
            Please note: this issue is only for tracking. The work will be done in a gdcc repo:
            
            - https://github.com/gdcc/dataverse-previewers/issues/25</body>
            <bodyText>Currently we get this error:
            "Unable to retrieve NcML file. Please try again. The most common issue is that your login has timed out. If the problem persists, please contact the support team of this data repository. Please include any status code included at the end of this message: Forbidden"
            
            We should update ncml.js to handle API tokens (like other previewers)
            Please note: this issue is only for tracking. The work will be done in a gdcc repo:
            
            gdcc/dataverse-previewers#25</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>pm.netcdf-hdf5.d</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9416</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title> NcML previewer doesn't work with drafts</title>
            <url>https://github.com/IQSS/dataverse/issues/9416</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>pm.netcdf-hdf5.d</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text> NcML previewer doesn't work with drafts</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>NIH NetCDF (Phil)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFMisM</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>As a curator, I would like to be able to add additional standardized geospatial metadata to ensure usability of geospatial datasets.  Specifically, add the following spatial reference elements that are considered essential according to the FGDC-CSDGM Standard:
            
            - Latitude_Resolution
            - Longitude_Resolution
            - Geographic_Coordinate_Units
            - Map_Projection
            - Grid_Coordinate_System
            - Geospatial_Data_Presentation_Form
            </body>
            <bodyText>As a curator, I would like to be able to add additional standardized geospatial metadata to ensure usability of geospatial datasets.  Specifically, add the following spatial reference elements that are considered essential according to the FGDC-CSDGM Standard:
            
            Latitude_Resolution
            Longitude_Resolution
            Geographic_Coordinate_Units
            Map_Projection
            Grid_Coordinate_System
            Geospatial_Data_Presentation_Form</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Feature: Metadata</name>
              </nodes>
              <nodes>
                <name>Feature: Geospatial</name>
              </nodes>
              <nodes>
                <name>pm.netcdf-hdf5.d</name>
              </nodes>
              <nodes>
                <name>Size: 80</name>
              </nodes>
              <totalCount>4</totalCount>
            </labels>
            <number>6713</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Improve Geospatial Metadata Block by adding additional fields</title>
            <url>https://github.com/IQSS/dataverse/issues/6713</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Metadata</name>
                </nodes>
                <nodes>
                  <name>Feature: Geospatial</name>
                </nodes>
                <nodes>
                  <name>pm.netcdf-hdf5.d</name>
                </nodes>
                <nodes>
                  <name>Size: 80</name>
                </nodes>
                <totalCount>4</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Improve Geospatial Metadata Block by adding additional fields</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>NIH NetCDF (Phil)</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>NIH NetCDF (Phil)</text>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgE2uYY</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MjIw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MjEx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>- if NetCDF/HDF5 detected and if lat/long
              - continue to create aux file
              - enable geospatial block
              - populate bounding box
            - if FITS
              - enable astro block
              - populate astro fields
            - if multiple files, create that many instances of the fields (e.g. bounding box)</body>
            <bodyText>if NetCDF/HDF5 detected and if lat/long
            
            continue to create aux file
            enable geospatial block
            populate bounding box
            
            
            if FITS
            
            enable astro block
            populate astro fields
            
            
            if multiple files, create that many instances of the fields (e.g. bounding box)</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>pm.netcdf-hdf5.d</name>
              </nodes>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9410</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Automatically enable metadata block when extracting metadata from FITS, NetCDF, or HDF5</title>
            <url>https://github.com/IQSS/dataverse/issues/9410</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>pm.netcdf-hdf5.d</name>
                </nodes>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Automatically enable metadata block when extracting metadata from FITS, NetCDF, or HDF5</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>NIH NetCDF (Phil)</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>NIH NetCDF (Phil)</text>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFImyE</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>https://github.com/silx-kit/h5web
            
            More context: https://docs.google.com/document/d/1IG03pfUpTNRbfLG2Lhl9s0zBCvK6CJNbzJK72YwX2J4/edit?usp=sharing
            
            Giving this a 3 because Jan will be doing the heavy lifting. I'll answer any questions about the external tool framework. And we'll QA it, of course.</body>
            <bodyText>https://github.com/silx-kit/h5web
            More context: https://docs.google.com/document/d/1IG03pfUpTNRbfLG2Lhl9s0zBCvK6CJNbzJK72YwX2J4/edit?usp=sharing
            Giving this a 3 because Jan will be doing the heavy lifting. I'll answer any questions about the external tool framework. And we'll QA it, of course.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>pm.netcdf-hdf5.d</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9480</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>h5web external tool</title>
            <url>https://github.com/IQSS/dataverse/issues/9480</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>pm.netcdf-hdf5.d</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>h5web external tool</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>NIH NetCDF (Phil)</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>NIH NetCDF (Phil)</text>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFuqbE</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>For now I left a note with some screenshots here: https://github.com/IQSS/dataverse-sample-data/pull/35#issuecomment-1468178563</body>
            <bodyText>For now I left a note with some screenshots here: IQSS/dataverse-sample-data#35 (comment)</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>pm.netcdf-hdf5.d</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9442</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Extract and display file hierarchy from HDF5</title>
            <url>https://github.com/IQSS/dataverse/issues/9442</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>pm.netcdf-hdf5.d</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Extract and display file hierarchy from HDF5</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>NIH NetCDF (Phil)</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>NIH NetCDF (Phil)</text>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFblZo</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>Hi,
            I have a dataset that contains around   ~75k files (each less than 1MB).
            
            Problem:
            I can clearly see and access (open) the files of dataset by clicking "Files" from facet area. 
            But when I click the dataset i receive "500 internal server error " (after some minutes) and with no updates on server.log
            
            However if I try from  API call , eg Json rep of the dataset, I receive the following update  from server.log.(text file attached)
            
            Are there any other solutions /ideas to tackle them ? Apart from zipping(double zipping) them
            **[Ticket Number Reference: #324896]**
            link:  https://help.hmdc.harvard.edu/Ticket/Display.html?id=324896
            
            Best Regards
            Lincoln
            [error_serverlog_apicall.txt](https://github.com/IQSS/dataverse/files/9403005/error_serverlog_apicall.txt)
             </body>
            <bodyText>Hi,
            I have a dataset that contains around   ~75k files (each less than 1MB).
            Problem:
            I can clearly see and access (open) the files of dataset by clicking "Files" from facet area.
            But when I click the dataset i receive "500 internal server error " (after some minutes) and with no updates on server.log
            However if I try from  API call , eg Json rep of the dataset, I receive the following update  from server.log.(text file attached)
            Are there any other solutions /ideas to tackle them ? Apart from zipping(double zipping) them
            [Ticket Number Reference: #324896]
            link:  https://help.hmdc.harvard.edu/Ticket/Display.html?id=324896
            Best Regards
            Lincoln
            error_serverlog_apicall.txt</bodyText>
            <closed>True</closed>
            <closedAt>2022-08-24T08:23:44Z</closedAt>
            <labels>
              <nodes>
                <name>Size: NoSprintCost</name>
              </nodes>
              <nodes>
                <name>D: Dataset: large number of files</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>8928</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Dataset with large number of files</title>
            <url>https://github.com/IQSS/dataverse/issues/8928</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: NoSprintCost</name>
                </nodes>
                <nodes>
                  <name>D: Dataset: large number of files</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Dataset with large number of files</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Community Backlog (Phil)</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgE3DWU</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>landreev</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>We are monitoring the number of open file descriptors ever since we had serious problems with it in the past (last year).
            When the number of open file descriptors of the glassfish process is 3000 or higher (max is 4096) I get a mail, this happened several times in the past days. Now, the good news is that it goes down to the 'basis' value of around 700.
            But if the peak will be too high, the system will fail and I don't want that to happen, besides this I get a lot of warning emails from the ‘monitoring’ script.
             
            A typical run looks like the following:
             
            2020-02-27T15:26:01+0100,742
            2020-02-27T15:27:02+0100,1744
            2020-02-27T15:28:01+0100,1744
            2020-02-27T15:29:01+0100,2747
            2020-02-27T15:30:01+0100,2747
            2020-02-27T15:31:01+0100,1450
            2020-02-27T15:32:01+0100,1452
            2020-02-27T15:33:01+0100,2453
            2020-02-27T15:34:01+0100,3456
             
            With each line the timestamp followed by the number of open file descriptors, increments in steps of ~1000 (sampling every minute). 
            
            Below a chart showing what happened on that day:
            ![image](https://user-images.githubusercontent.com/2151103/75879150-2b314a80-5e1b-11ea-84a2-bf45d1ccc8e3.png)
            .
            
            After another warning mail, we checked the logs
            
            `[2020-03-02T13:51:04.422+0100] [glassfish 4.1] [SEVERE] [] [edu.harvard.hul.ois.jhove] [tid: _ThreadID=52 _ThreadName=jk-connector(3)] [timeMillis: 1583153464422] [levelValue: 1000] [[
              Testing SEVERE level]]
             
            [2020-03-02T13:51:04.431+0100] [glassfish 4.1] [SEVERE] [] [edu.harvard.hul.ois.jhove] [tid: _ThreadID=52 _ThreadName=jk-connector(3)] [timeMillis: 1583153464431] [levelValue: 1000] [[
              Testing SEVERE level]]
             
            [2020-03-02T13:51:04.437+0100] [glassfish 4.1] [SEVERE] [] [edu.harvard.hul.ois.jhove] [tid: _ThreadID=52 _ThreadName=jk-connector(3)] [timeMillis: 1583153464437] [levelValue: 1000] [[
              Testing SEVERE level]]
             
            [2020-03-02T13:51:04.447+0100] [glassfish 4.1] [SEVERE] [] [edu.harvard.hul.ois.jhove] [tid: _ThreadID=52 _ThreadName=jk-connector(3)] [timeMillis: 1583153464447] [levelValue: 1000] [[
              Testing SEVERE level]]
             
            [2020-03-02T13:51:04.450+0100] [glassfish 4.1] [WARNING] [] [edu.harvard.iq.dataverse.util.FileUtil] [tid: _ThreadID=52 _ThreadName=jk-connector(3)] [timeMillis: 1583153464450] [levelValue: 900] [[
              Zip upload - too many files.]]
             
            [2020-03-02T13:51:04.450+0100] [glassfish 4.1] [WARNING] [] [edu.harvard.iq.dataverse.util.FileUtil] [tid: _ThreadID=52 _ThreadName=jk-connector(3)] [timeMillis: 1583153464450] [levelValue: 900] [[
              Unzipping failed; rolling back to saving the file as is.]]
             `
            
            This is from the code in: edu.harvard.iq.dataverse.util.FileUtil
            There we see that there is a limit in: 
            edu/harvard/iq/dataverse/util/SystemConfig.java
            
            `/**
                 * The default number of datafiles that we allow to be created through 
                 * zip file upload.
                 */
                private static final int defaultZipUploadFilesLimit = 1000; 
                private static final int defaultMultipleUploadFilesLimit = 1000;
                private static final int defaultLoginSessionTimeout = 480; // = 8 hours
             `
            It is not set by us, so it should indeed be the default 1000. 
            
            Next I tested uploading a zip with a lot of files &gt;1000 and several things happened. 
            On the GUI I got the message: "The number of files in the zip archive is over the limit (1000); please upload a zip archive with fewer files, if you want them to be ingested as individual DataFiles."
            The files in the zip where indeed not extracted into the dataset, but the complete zip was added, as is. 
            
            But the following problems occurred: 
            - The number of open file descriptors peeked. 
            - All the temporary files where left in the Dataverse temp dir. 
            
            It would be much better if those two things did not happen.
            
            Furthermore, I tested it with a special constructed zip with exactly 1001 files in it. 
            Then all the files where extracted, although 1001 &gt; 1000. 
            
            If I change the limit to 999, with: 
            'curl -X PUT -d '999' http://localhost:8080/api/admin/settings/:ZipUploadFilesLimit'
            The zip is added 'as is'. This looks like a off-by-one error, which would be nice to have fixed in order to minimise confusion. 
            [1001_files.zip](https://github.com/IQSS/dataverse/files/4287255/1001_files.zip)
             
            
            </body>
            <bodyText>We are monitoring the number of open file descriptors ever since we had serious problems with it in the past (last year).
            When the number of open file descriptors of the glassfish process is 3000 or higher (max is 4096) I get a mail, this happened several times in the past days. Now, the good news is that it goes down to the 'basis' value of around 700.
            But if the peak will be too high, the system will fail and I don't want that to happen, besides this I get a lot of warning emails from the ‘monitoring’ script.
            A typical run looks like the following:
            2020-02-27T15:26:01+0100,742
            2020-02-27T15:27:02+0100,1744
            2020-02-27T15:28:01+0100,1744
            2020-02-27T15:29:01+0100,2747
            2020-02-27T15:30:01+0100,2747
            2020-02-27T15:31:01+0100,1450
            2020-02-27T15:32:01+0100,1452
            2020-02-27T15:33:01+0100,2453
            2020-02-27T15:34:01+0100,3456
            With each line the timestamp followed by the number of open file descriptors, increments in steps of ~1000 (sampling every minute).
            Below a chart showing what happened on that day:
            
            .
            After another warning mail, we checked the logs
            `[2020-03-02T13:51:04.422+0100] [glassfish 4.1] [SEVERE] [] [edu.harvard.hul.ois.jhove] [tid: _ThreadID=52 _ThreadName=jk-connector(3)] [timeMillis: 1583153464422] [levelValue: 1000] [[
            Testing SEVERE level]]
            [2020-03-02T13:51:04.431+0100] [glassfish 4.1] [SEVERE] [] [edu.harvard.hul.ois.jhove] [tid: _ThreadID=52 _ThreadName=jk-connector(3)] [timeMillis: 1583153464431] [levelValue: 1000] [[
            Testing SEVERE level]]
            [2020-03-02T13:51:04.437+0100] [glassfish 4.1] [SEVERE] [] [edu.harvard.hul.ois.jhove] [tid: _ThreadID=52 _ThreadName=jk-connector(3)] [timeMillis: 1583153464437] [levelValue: 1000] [[
            Testing SEVERE level]]
            [2020-03-02T13:51:04.447+0100] [glassfish 4.1] [SEVERE] [] [edu.harvard.hul.ois.jhove] [tid: _ThreadID=52 _ThreadName=jk-connector(3)] [timeMillis: 1583153464447] [levelValue: 1000] [[
            Testing SEVERE level]]
            [2020-03-02T13:51:04.450+0100] [glassfish 4.1] [WARNING] [] [edu.harvard.iq.dataverse.util.FileUtil] [tid: _ThreadID=52 _ThreadName=jk-connector(3)] [timeMillis: 1583153464450] [levelValue: 900] [[
            Zip upload - too many files.]]
            [2020-03-02T13:51:04.450+0100] [glassfish 4.1] [WARNING] [] [edu.harvard.iq.dataverse.util.FileUtil] [tid: _ThreadID=52 _ThreadName=jk-connector(3)] [timeMillis: 1583153464450] [levelValue: 900] [[
            Unzipping failed; rolling back to saving the file as is.]]
            `
            This is from the code in: edu.harvard.iq.dataverse.util.FileUtil
            There we see that there is a limit in:
            edu/harvard/iq/dataverse/util/SystemConfig.java
            /** * The default number of datafiles that we allow to be created through  * zip file upload. */ private static final int defaultZipUploadFilesLimit = 1000;  private static final int defaultMultipleUploadFilesLimit = 1000; private static final int defaultLoginSessionTimeout = 480; // = 8 hours 
            It is not set by us, so it should indeed be the default 1000.
            Next I tested uploading a zip with a lot of files &gt;1000 and several things happened.
            On the GUI I got the message: "The number of files in the zip archive is over the limit (1000); please upload a zip archive with fewer files, if you want them to be ingested as individual DataFiles."
            The files in the zip where indeed not extracted into the dataset, but the complete zip was added, as is.
            But the following problems occurred:
            
            The number of open file descriptors peeked.
            All the temporary files where left in the Dataverse temp dir.
            
            It would be much better if those two things did not happen.
            Furthermore, I tested it with a special constructed zip with exactly 1001 files in it.
            Then all the files where extracted, although 1001 &gt; 1000.
            If I change the limit to 999, with:
            'curl -X PUT -d '999' http://localhost:8080/api/admin/settings/:ZipUploadFilesLimit'
            The zip is added 'as is'. This looks like a off-by-one error, which would be nice to have fixed in order to minimise confusion.
            1001_files.zip</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Feature: File Upload &amp; Handling</name>
              </nodes>
              <nodes>
                <name>Type: Bug</name>
              </nodes>
              <nodes>
                <name>Feature: Performance &amp; Stability</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>spike</name>
              </nodes>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <nodes>
                <name>D: Dataset: large number of files</name>
              </nodes>
              <totalCount>7</totalCount>
            </labels>
            <number>6723</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>High levels of open file descriptors while uploading a zip with lots of files in it</title>
            <url>https://github.com/IQSS/dataverse/issues/6723</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: File Upload &amp; Handling</name>
                </nodes>
                <nodes>
                  <name>Type: Bug</name>
                </nodes>
                <nodes>
                  <name>Feature: Performance &amp; Stability</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>spike</name>
                </nodes>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <nodes>
                  <name>D: Dataset: large number of files</name>
                </nodes>
                <totalCount>7</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>High levels of open file descriptors while uploading a zip with lots of files in it</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgE3DZI</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>the dataset page is not completing to "success" message until manually refreshed</body>
            <bodyText>the dataset page is not completing to "success" message until manually refreshed</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-15T16:59:34Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: File Upload &amp; Handling</name>
              </nodes>
              <nodes>
                <name>Type: Bug</name>
              </nodes>
              <nodes>
                <name>D: Dataset: large number of files</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>5523</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>deleting datasets with large number of files &lt;400 should result in success message</title>
            <url>https://github.com/IQSS/dataverse/issues/5523</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: File Upload &amp; Handling</name>
                </nodes>
                <nodes>
                  <name>Type: Bug</name>
                </nodes>
                <nodes>
                  <name>D: Dataset: large number of files</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>deleting datasets with large number of files &lt;400 should result in success message</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT- NEEDS SIZING</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgE3Dak</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>User in production had 100 datasets, each with 500 files. They had problems publishing them , eventually ending up with permanently locked datasets, likely due to server restart somewhere during the process.
            
            This became a support issue, rt 268791 where a script needed to be written to delete locks. While benchmarking publishing these datasets, observed a single dataset takes 24mins, 2 datasets takes roughly 2x longer, 4 datasets 4x+ longer. It seems performance degrades linearly with number of pids.
            
            This is a great use case because all datasets are same size.
            
            Questions: 
            1. Why is performance for a single 500 file dataset so poor against DataCite (6x EZID)?
            2. Why does performance for concurrent publishing n take n times longer?
            
            Performance for DataCite was improved in a recent community pr by @qqmyers and while a big improvement, would likely not address this level.</body>
            <bodyText>User in production had 100 datasets, each with 500 files. They had problems publishing them , eventually ending up with permanently locked datasets, likely due to server restart somewhere during the process.
            This became a support issue, rt 268791 where a script needed to be written to delete locks. While benchmarking publishing these datasets, observed a single dataset takes 24mins, 2 datasets takes roughly 2x longer, 4 datasets 4x+ longer. It seems performance degrades linearly with number of pids.
            This is a great use case because all datasets are same size.
            Questions:
            
            Why is performance for a single 500 file dataset so poor against DataCite (6x EZID)?
            Why does performance for concurrent publishing n take n times longer?
            
            Performance for DataCite was improved in a recent community pr by @qqmyers and while a big improvement, would likely not address this level.</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-14T15:55:35Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: Performance &amp; Stability</name>
              </nodes>
              <nodes>
                <name>D: Dataset: large number of files</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>5283</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Performance: Publishing dataset with large number of files via DataCite takes too long.</title>
            <url>https://github.com/IQSS/dataverse/issues/5283</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Performance &amp; Stability</name>
                </nodes>
                <nodes>
                  <name>D: Dataset: large number of files</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Performance: Publishing dataset with large number of files via DataCite takes too long.</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT- NEEDS SIZING</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgE3DbY</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9387</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>DANS</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9388</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/9387 - Support protected system metadata</title>
            <url>https://github.com/IQSS/dataverse/pull/9388</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>DANS</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.14</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/9387 - Support protected system metadata</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>External Commitments (Jim)</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgE46Co</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>MellyGray</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>This issue is a follow on to the conversation at https://github.com/IQSS/dataverse-frontend/pull/4#issuecomment-1443390932
            
            In short, the skeleton app in PR #4 is based on Create React App, but there is a [long writeup by one of its creators](https://github.com/reactjs/reactjs.org/pull/5487#issuecomment-1409720741) that explains some potential problems with it:
            
            - "As the years passed, Create React App has stagnated."
            - "We could suggest people to migrate from Create React App to something like Vite."
            
            In short, Vite seems to have a brighter future than Create React App. I think Vite would be a stronger foundation for us. This issue is about trying to migrate to Vite.</body>
            <bodyText>This issue is a follow on to the conversation at #4 (comment)
            In short, the skeleton app in PR #4 is based on Create React App, but there is a long writeup by one of its creators that explains some potential problems with it:
            
            "As the years passed, Create React App has stagnated."
            "We could suggest people to migrate from Create React App to something like Vite."
            
            In short, Vite seems to have a brighter future than Create React App. I think Vite would be a stronger foundation for us. This issue is about trying to migrate to Vite.</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-04T19:46:05Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>10</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>migrate to Vite (brighter future than Create React App and Webpack)</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/10</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>migrate to Vite (brighter future than Create React App and Webpack)</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>February 8, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFMR5s</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>- As [discussed](https://dataverse.zulipchat.com/#narrow/stream/375812-containers/topic/PR.20.239424.3A.20dv.20container.20for.20dev/near/340931041), start with PR [#9424](https://github.com/IQSS/dataverse/issues/9424), make a new branch, merge in the latest from develop (especially PR #9417, which we are building upon for Postgres and Solr in containers)
            - keep the "dev" docker-compose, remove the other
            - remove mailhog 🐷 
            - think about a better name for [dev-rebuild-docker.sh](http://dev-rebuild-docker.sh/) - `bootstrap.sh`?
            - docs, docs, docs</body>
            <bodyText>As discussed, start with PR #9424, make a new branch, merge in the latest from develop (especially PR #9417, which we are building upon for Postgres and Solr in containers)
            keep the "dev" docker-compose, remove the other
            remove mailhog 🐷
            think about a better name for dev-rebuild-docker.sh - bootstrap.sh?
            docs, docs, docs</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-20T19:17:11Z</closedAt>
            <labels>
              <nodes>
                <name>Containers &amp; Cloud</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9434</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Build locally a Dataverse app image for dev</title>
            <url>https://github.com/IQSS/dataverse/issues/9434</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Containers &amp; Cloud</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Build locally a Dataverse app image for dev</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <totalCount>7</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFZJJQ</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MjMw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MjIx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-03-20T19:17:09Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9434</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Installation Guide</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>Containers &amp; Cloud</name>
              </nodes>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>D: DataverseInDocker</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>9439</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>9434 app container for dev</title>
            <url>https://github.com/IQSS/dataverse/pull/9439</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Installation Guide</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>Containers &amp; Cloud</name>
                </nodes>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>D: DataverseInDocker</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>2</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>9434 app container for dev</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 15, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFbws4</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>MellyGray</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            To start developing some pages for the SPA MVP we are going to need a common Layout component for all the pages. This Layout component is a wrapper with the common elements to all the pages, such as the header and the footer. All the pages will extend this component as a children.
            
            ## What kind of user is the feature intended for?
            Dataverse frontend developers
            
            ## What inspired the request?
            - Current work on SPA MVP Strategy
            - MVP Strategy document: [link](https://docs.google.com/document/d/1vOSsIGGCbgal4f_lSp1yInQifBcmo5vZ-Z9pfkVDyG4)
            
            ## What existing behavior do you want changed?
            The example page HelloDataverse.tsx will be encapsulated in the Layout component to serve as a real example.
            
            ## Any brand new behavior do you want to add to Dataverse Frontend?
            
            -  Layout component wrapper for the future Dataverse pages.
            -  Header component
            -  Footer component
            -  Add those components to the Storybook
            
            ## Any related open or closed issues to this feature request?
            
            Storybook need to be set up https://github.com/IQSS/dataverse-frontend/issues/3
            </body>
            <bodyText>Overview of the Feature Request
            To start developing some pages for the SPA MVP we are going to need a common Layout component for all the pages. This Layout component is a wrapper with the common elements to all the pages, such as the header and the footer. All the pages will extend this component as a children.
            What kind of user is the feature intended for?
            Dataverse frontend developers
            What inspired the request?
            
            Current work on SPA MVP Strategy
            MVP Strategy document: link
            
            What existing behavior do you want changed?
            The example page HelloDataverse.tsx will be encapsulated in the Layout component to serve as a real example.
            Any brand new behavior do you want to add to Dataverse Frontend?
            
            Layout component wrapper for the future Dataverse pages.
            Header component
            Footer component
            Add those components to the Storybook
            
            Any related open or closed issues to this feature request?
            Storybook need to be set up #3</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-21T16:19:25Z</closedAt>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>7</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Layout component</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/7</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Layout component</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFdG1s</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2023-03-01T18:26:13Z</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>1</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>4</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>1 - Create the skeleton of the React SPA</title>
            <url>https://github.com/IQSS/dataverse-frontend/pull/4</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>1</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>1 - Create the skeleton of the React SPA</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <totalCount>9</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFfcoM</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9361</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>D: FixRateLimitingBehaviors</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9409</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>9361 storage quotas</title>
            <url>https://github.com/IQSS/dataverse/pull/9409</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>D: FixRateLimitingBehaviors</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <reviewers>
                <totalCount>1</totalCount>
              </reviewers>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>9361 storage quotas</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Dataverse Team (Gustavo)</text>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFfeTY</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>9454</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>External tools fix</title>
            <url>https://github.com/IQSS/dataverse/pull/9454</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>External tools fix</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>External Commitments (Jim)</name>
            </nodes>
            <totalCount>3</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFiw44</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>mreekie</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>References:
            
            * [Backlog Grooming Board](https://github.com/orgs/IQSS/projects/32/views/11)
            
            **Problem Statement**
            
            Prior to this work, Dataverse is capable of storing up to about 1TB in S3. 
            
            **Proposed Solution**
            
            The first part was to integrate [Globus](https://www.globus.org/) as a large file transfer mechanism, into Dataverse. This was done by building on the work already done in the Borealis, the Canadian Dataverse Repository (Formerly Scholar’s Portal Fork of Dataverse) to allow Dataverse to integrate with Globus. This integration allows files bigger than a terabyte to be transferred from within Dataverse and to an S3 store via globus.
            
            The second part addresses very large files; items up upward of a petabyte or so are not realistic for DV to store. This solution enables Dataverse to manage datasets where one or more of the files is referenced rather than being directly stored within a Dataverse repository. In this solution, the large file remains in its original location and then is referenced from Dataverse.
            
            **Acceptance Criteria**
            
            * [x] Discussion with Dataverse community members with related work,
            * [x]  Set up Globus environment at NESE
            * [x] Design and implement code to call API to interact with Globus endpoints, 
            * [ ] Test integration﻿
            
            **Associated Issues:**
            
            * [x] https://github.com/IQSS/dataverse/pull/8894
            * [x] https://github.com/IQSS/dataverse/pull/8891
            * [x] https://github.com/IQSS/dataverse/issues/7740
            * [x] https://github.com/IQSS/dataverse/issues/7626
            * [x] https://github.com/IQSS/dataverse/issues/7524
            * [x] https://github.com/IQSS/dataverse/pull/7325
            * [x] https://github.com/IQSS/dataverse/issues/5994
            * [ ] https://github.com/IQSS/dataverse/issues/9123
            * [x] https://github.com/IQSS/dataverse/issues/9189
            * 
            * 
            * 
            
            See comments below for latest update.
            
            - - -
            
            
            ┆Issue is synchronized with this [Smartsheet row](https://app.smartsheet.com/sheets/3PXV7GPQcQ769PMhmJvPGr5RcCmgG65VgmFHJv21?rowId=2232809702287236) by [Unito](https://www.unito.io)
            </body>
            <bodyText>References:
            
            Backlog Grooming Board
            
            Problem Statement
            Prior to this work, Dataverse is capable of storing up to about 1TB in S3.
            Proposed Solution
            The first part was to integrate Globus as a large file transfer mechanism, into Dataverse. This was done by building on the work already done in the Borealis, the Canadian Dataverse Repository (Formerly Scholar’s Portal Fork of Dataverse) to allow Dataverse to integrate with Globus. This integration allows files bigger than a terabyte to be transferred from within Dataverse and to an S3 store via globus.
            The second part addresses very large files; items up upward of a petabyte or so are not realistic for DV to store. This solution enables Dataverse to manage datasets where one or more of the files is referenced rather than being directly stored within a Dataverse repository. In this solution, the large file remains in its original location and then is referenced from Dataverse.
            Acceptance Criteria
            
             Discussion with Dataverse community members with related work,
              Set up Globus environment at NESE
             Design and implement code to call API to interact with Globus endpoints,
             Test integration﻿
            
            Associated Issues:
            
             IQSS/dataverse#8894
             IQSS/dataverse#8891
             IQSS/dataverse#7740
             IQSS/dataverse#7626
             IQSS/dataverse#7524
             IQSS/dataverse#7325
             IQSS/dataverse#5994
             IQSS/dataverse#9123
             IQSS/dataverse#9189
            
            
            
            
            See comments below for latest update.
            
            ┆Issue is synchronized with this Smartsheet row by Unito</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>pm.GREI</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.1.1</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>13</number>
            <repository>
              <name>dataverse-pm</name>
            </repository>
            <title>1 | 1.1.1 | Minimum Viable Product (MVP) for registering metadata in the repository and connecting the metadata to the data in the research computing remote storage (NESE), including Globus endpoints | 15</title>
            <url>https://github.com/IQSS/dataverse-pm/issues/13</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOIwMRzQ</id>
                <name>dataverse-pm</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>pm.GREI</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.1.1</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>1 | 1.1.1 | Minimum Viable Product (MVP) for registering metadata in the repository and connecting the metadata to the data in the research computing remote storage (NESE), including Globus endpoints | 15</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>ℹ Reporting Deliverables</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Not-In-This-List</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFjdXA</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>4499</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: API</name>
              </nodes>
              <nodes>
                <name>Feature: Publishing &amp; Versions</name>
              </nodes>
              <nodes>
                <name>Feature: API Guide</name>
              </nodes>
              <nodes>
                <name>User Role: Curator</name>
              </nodes>
              <nodes>
                <name>User Role: API User</name>
              </nodes>
              <nodes>
                <name>User Role: Sysadmin</name>
              </nodes>
              <nodes>
                <name>User Role: Depositor</name>
              </nodes>
              <nodes>
                <name>HERMES</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.3.1</name>
              </nodes>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <totalCount>10</totalCount>
            </labels>
            <number>9462</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>4499 - dataset version pids</title>
            <url>https://github.com/IQSS/dataverse/pull/9462</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: API</name>
                </nodes>
                <nodes>
                  <name>Feature: Publishing &amp; Versions</name>
                </nodes>
                <nodes>
                  <name>Feature: API Guide</name>
                </nodes>
                <nodes>
                  <name>User Role: Curator</name>
                </nodes>
                <nodes>
                  <name>User Role: API User</name>
                </nodes>
                <nodes>
                  <name>User Role: Sysadmin</name>
                </nodes>
                <nodes>
                  <name>User Role: Depositor</name>
                </nodes>
                <nodes>
                  <name>HERMES</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.3.1</name>
                </nodes>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <totalCount>10</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>4499 - dataset version pids</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>HERMES (Oliver)</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFok1k</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>This is an umbrella to be used for all the issues we are seeing related to the title.
            What follows is a rough cut of what's been discussed thus far that would need to be done to complete this deliverable.
            
            As a "bklog: Deliverable" This is decomposed into smaller issues.
            - Each of the smaller issues gets the label "D: Dataset: large number of files"
            - This issue, the only issue to have both labels ("bklog: Deliverable", "D: Dataset: large number of files"), will stay in the Dataverse_Global_Backlog project forever.
            - It will stay in it's present column until the team feels like the issue has no smaller issues that need need to be broken off in order to resolve this issue
            - At that point, this issue stays in the Dataverse_Global_backlog, but changes it's status to: "Clear of the Backlog"
            
            ----
            
            
            We're talking about this issue in tech hours. Here are some pain points for users:
            
            - Editing the title (or other piece) when there are many files (30,000). The save is prohibitively expensive. Affects depositors. Maybe removing the cascade will help. There are two cascades. We could write tests with the 1000files.zip file vs 1 file. How long to edit the title?
            - Slow indexing of a dataset with 30,000 files. Affects sysadmins.
            - Only 20 files but many versions. Slow to make the next version. Multiplying affect. Affects depositors. Reindexing is slow?
            - ...
            
            Other discussion:
            
            - Does the new zip previewer/downloader help?
            - Creating a large JSON for the tree view?
            - Let's benchmark and measure perf.
            - Check open file handles.
            
            ---
            
            @linsherpa thanks for chatting and opening this issue and the ticket.
            
            I'll note that out of the box Dataverse only allows you unzip 1000 files at a time from a zip file: https://guides.dataverse.org/en/5.11.1/installation/config.html#multipleuploadfileslimit ... That's the most official statement I could find about how many files are supported in a single dataset... not a very strong one.
            
            As you mentioned, the practical workaround is probably to double zip the files.
            
            For developers I'll mention that `scripts/search/data/binary/1000files.zip` has 1000 small files we can test with.
            
            Finally, here are some open issues related to large numbers of files in a dataset:
            
            - IQSS/dataverse#8256
            - IQSS/dataverse-pm#27
            - IQSS/dataverse#6723
            - IQSS/dataverse#5523
            - IQSS/dataverse#5283
            - IQSS/dataverse#2641
            - https://github.com/IQSS/dataverse-pm/issues/27
            </body>
            <bodyText>This is an umbrella to be used for all the issues we are seeing related to the title.
            What follows is a rough cut of what's been discussed thus far that would need to be done to complete this deliverable.
            As a "bklog: Deliverable" This is decomposed into smaller issues.
            
            Each of the smaller issues gets the label "D: Dataset: large number of files"
            This issue, the only issue to have both labels ("bklog: Deliverable", "D: Dataset: large number of files"), will stay in the Dataverse_Global_Backlog project forever.
            It will stay in it's present column until the team feels like the issue has no smaller issues that need need to be broken off in order to resolve this issue
            At that point, this issue stays in the Dataverse_Global_backlog, but changes it's status to: "Clear of the Backlog"
            
            
            We're talking about this issue in tech hours. Here are some pain points for users:
            
            Editing the title (or other piece) when there are many files (30,000). The save is prohibitively expensive. Affects depositors. Maybe removing the cascade will help. There are two cascades. We could write tests with the 1000files.zip file vs 1 file. How long to edit the title?
            Slow indexing of a dataset with 30,000 files. Affects sysadmins.
            Only 20 files but many versions. Slow to make the next version. Multiplying affect. Affects depositors. Reindexing is slow?
            ...
            
            Other discussion:
            
            Does the new zip previewer/downloader help?
            Creating a large JSON for the tree view?
            Let's benchmark and measure perf.
            Check open file handles.
            
            
            @linsherpa thanks for chatting and opening this issue and the ticket.
            I'll note that out of the box Dataverse only allows you unzip 1000 files at a time from a zip file: https://guides.dataverse.org/en/5.11.1/installation/config.html#multipleuploadfileslimit ... That's the most official statement I could find about how many files are supported in a single dataset... not a very strong one.
            As you mentioned, the practical workaround is probably to double zip the files.
            For developers I'll mention that scripts/search/data/binary/1000files.zip has 1000 small files we can test with.
            Finally, here are some open issues related to large numbers of files in a dataset:
            
            IQSS/dataverse#8256
            #27
            IQSS/dataverse#6723
            IQSS/dataverse#5523
            IQSS/dataverse#5283
            IQSS/dataverse#2641
            #27</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>bklog: Deliverable</name>
              </nodes>
              <nodes>
                <name>D: Dataset: large number of files</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>29</number>
            <repository>
              <name>dataverse-pm</name>
            </repository>
            <title>Deliverable: Slow response for datasets with high number of files</title>
            <url>https://github.com/IQSS/dataverse-pm/issues/29</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOIwMRzQ</id>
                <name>dataverse-pm</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>bklog: Deliverable</name>
                </nodes>
                <nodes>
                  <name>D: Dataset: large number of files</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Deliverable: Slow response for datasets with high number of files</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Dataverse Team (Gustavo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFopsY</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>**Overview of the Feature Request**
            
            After #9293 refactor, it has become more visible that there are endpoints that, despite being intended to be open, triggers user authentication, when it is not required.
            
            This behavior already existed before the Auth Filter refactor, but it is now more visible by having the `@AuthRequired` annotation. Before the refactor, credential filtering was executed via the `AbstractApiBean.response(DataverseRequestHandler hdl)` method, which was called from several endpoints, a method which in turn called the `findUserOrDie` method.
            
            These methods no longer exist, since the logic is now moved to the Auth Filter, and the same endpoints which used those methods now they are wrapped by the Auth Filter.
            
            The goal of this issue is to simplify authentication by omitting the auth filter on endpoints that do not require user authentication. This makes the API code more understandable for developers and improves performance by bypassing the auth filter when it's not needed.
            
            Example endpoint:  `/api/info/version`.
            
            **What kind of user is the feature intended for?**
            API User, developers
            
            **What inspired the request?**
            Slack discussion about confusion when seeing endpoint `/api/info/version` marked with `AuthRequired` 
            
            **What existing behavior do you want changed?**
            API authentication
            
            **Any brand new behavior do you want to add to Dataverse?**
            No
            
            **Any open or closed issues related to this feature request?**
            - #9293</body>
            <bodyText>Overview of the Feature Request
            After #9293 refactor, it has become more visible that there are endpoints that, despite being intended to be open, triggers user authentication, when it is not required.
            This behavior already existed before the Auth Filter refactor, but it is now more visible by having the @AuthRequired annotation. Before the refactor, credential filtering was executed via the AbstractApiBean.response(DataverseRequestHandler hdl) method, which was called from several endpoints, a method which in turn called the findUserOrDie method.
            These methods no longer exist, since the logic is now moved to the Auth Filter, and the same endpoints which used those methods now they are wrapped by the Auth Filter.
            The goal of this issue is to simplify authentication by omitting the auth filter on endpoints that do not require user authentication. This makes the API code more understandable for developers and improves performance by bypassing the auth filter when it's not needed.
            Example endpoint:  /api/info/version.
            What kind of user is the feature intended for?
            API User, developers
            What inspired the request?
            Slack discussion about confusion when seeing endpoint /api/info/version marked with AuthRequired
            What existing behavior do you want changed?
            API authentication
            Any brand new behavior do you want to add to Dataverse?
            No
            Any open or closed issues related to this feature request?
            
            #9293</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Feature: API</name>
              </nodes>
              <nodes>
                <name>User Role: API User</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.7.1 (reArchitecture)</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>9466</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Evolve API authentication to omit it on endpoints intended to be open</title>
            <url>https://github.com/IQSS/dataverse/issues/9466</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: API</name>
                </nodes>
                <nodes>
                  <name>User Role: API User</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.7.1 (reArchitecture)</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Evolve API authentication to omit it on endpoints intended to be open</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Re-arch: Auth MVP (Phil)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFospo</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>This is the first step in addressing: https://github.com/IQSS/dataverse-pm/issues/26
            
            Agree on general structure - create a schema that matches our dataset JSON without adding too much specifics on the metadata. Check the Structure. (no code) (10)</body>
            <bodyText>This is the first step in addressing: IQSS/dataverse-pm#26
            Agree on general structure - create a schema that matches our dataset JSON without adding too much specifics on the metadata. Check the Structure. (no code) (10)</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>D: ImproveJsonValidation</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9463</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Dataset Json Validation: Agree on general structure - create a schema that matches our dataset JSON</title>
            <url>https://github.com/IQSS/dataverse/issues/9463</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>D: ImproveJsonValidation</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Dataset Json Validation: Agree on general structure - create a schema that matches our dataset JSON</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFpAhc</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MjQw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MjMx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>This is the second step in addressing: https://github.com/IQSS/dataverse-pm/issues/26
            
            Use this schema to update the code. We currently have a library that checks the JSON schema (wc3provenance schema). As part of this solution we should not feel limited to using our current library. (On the page about the JSON schema there are multiple java library options available for validation.)(10)</body>
            <bodyText>This is the second step in addressing: IQSS/dataverse-pm#26
            Use this schema to update the code. We currently have a library that checks the JSON schema (wc3provenance schema). As part of this solution we should not feel limited to using our current library. (On the page about the JSON schema there are multiple java library options available for validation.)(10)</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>D: ImproveJsonValidation</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9464</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Dataset Json Validation: Update the code to use this schema</title>
            <url>https://github.com/IQSS/dataverse/issues/9464</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>D: ImproveJsonValidation</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Dataset Json Validation: Update the code to use this schema</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFpAkg</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>This is the third step in addressing: https://github.com/IQSS/dataverse-pm/issues/26
            
            Create API endpoints to retrieve a JSON schema that also has info about the required meta-data so that we can create a full-fledged validation of a dataset. That API end point has a paramenter that is the dataverse collection that you are targetting for deposit. (10)</body>
            <bodyText>This is the third step in addressing: IQSS/dataverse-pm#26
            Create API endpoints to retrieve a JSON schema that also has info about the required meta-data so that we can create a full-fledged validation of a dataset. That API end point has a paramenter that is the dataverse collection that you are targetting for deposit. (10)</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>D: ImproveJsonValidation</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>9465</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Dataset Json Validation: Create API endpoints to retrieve a JSON schema</title>
            <url>https://github.com/IQSS/dataverse/issues/9465</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>D: ImproveJsonValidation</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Dataset Json Validation: Create API endpoints to retrieve a JSON schema</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFpA_0</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>MellyGray</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            We would like to add buttons and dropdown elements of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent buttons and dropdowns across our applications.
            
            The buttons and dropdowns would be the ones documented in the [Design System Analysis document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.8nqu9gh25f0n).
            
            These buttons and dropdowns would be using the Design tokens as SASS variables if applicable. These variables are described in [the document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.byjoci5aw2)
            
            ## What kind of user is the feature intended for?
            
            This feature is intended for developers who use React to build and test components for our web applications.
            
            ## What inspired the request?
            
            Our design system includes a set of buttons and dropdowns that are used consistently across our applications. By creating reusable React components for these elements and documenting them in Storybook, we can provide a centralized and easy-to-use reference for developers.
            
            Some references for the Storybook:
            
            - [Vibe Design System](https://style.monday.com/?path=/docs/foundations-colors--page)
            - [Storybook Design System](https://storybook-design-system.netlify.app/?path=/docs/colors--page)
            - [More references](https://storybook.js.org/showcase)
            
            ## What existing behavior do you want changed?
            
            We want to add a new section to Storybook that displays our buttons and dropdowns as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            
            ## Any brand new behavior do you want to add to Dataverse?
            
            No, this feature request does not introduce any brand new behavior to Dataverse.
            
            ## Any open or closed issues related to this feature request?
            
            - https://github.com/IQSS/dataverse-frontend/issues/14
            
            - https://github.com/IQSS/dataverse-frontend/issues/30</body>
            <bodyText>Overview of the Feature Request
            We would like to add buttons and dropdown elements of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent buttons and dropdowns across our applications.
            The buttons and dropdowns would be the ones documented in the Design System Analysis document.
            These buttons and dropdowns would be using the Design tokens as SASS variables if applicable. These variables are described in the document
            What kind of user is the feature intended for?
            This feature is intended for developers who use React to build and test components for our web applications.
            What inspired the request?
            Our design system includes a set of buttons and dropdowns that are used consistently across our applications. By creating reusable React components for these elements and documenting them in Storybook, we can provide a centralized and easy-to-use reference for developers.
            Some references for the Storybook:
            
            Vibe Design System
            Storybook Design System
            More references
            
            What existing behavior do you want changed?
            We want to add a new section to Storybook that displays our buttons and dropdowns as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            Any brand new behavior do you want to add to Dataverse?
            No, this feature request does not introduce any brand new behavior to Dataverse.
            Any open or closed issues related to this feature request?
            
            
            #14
            
            
            #30</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: Design System</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>32</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Create the buttons and dropdowns of the design system</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/32</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: Design System</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create the buttons and dropdowns of the design system</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 29, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <totalCount>9</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFr76k</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>MellyGray</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            To provide the documentation of the design system we will be using the Storybook docs capabilities. Then, we'll need to create a template for the docs in .mdx format. This template is intended to be used with the design system elements, not necessary for the rest of the components of the SPA.
            
            The current style guide could be a reference for this documentation. As well as other public Storybook:
            
            - [Dataverse style guide](https://guides.dataverse.org/en/latest/style/index.html)
            - [Storybook design system](https://storybook-design-system.netlify.app/?path=/docs/button--basic)
            - [Monday storybook](https://style.monday.com/?path=/docs/buttons-button--overview)
            
            ## What kind of user is the feature intended for?
            Developers and contributors
            
            ## What inspired the request?
            The analysis of the Design System elements.
            
            ## What existing behavior do you want changed?
            None
            
            ## Any brand new behavior do you want to add to Dataverse?
            Storybook documentation template for the design system elements
            
            ## Any open or closed issues related to this feature request?
            
            - https://github.com/IQSS/dataverse-frontend/issues/14</body>
            <bodyText>Overview of the Feature Request
            To provide the documentation of the design system we will be using the Storybook docs capabilities. Then, we'll need to create a template for the docs in .mdx format. This template is intended to be used with the design system elements, not necessary for the rest of the components of the SPA.
            The current style guide could be a reference for this documentation. As well as other public Storybook:
            
            Dataverse style guide
            Storybook design system
            Monday storybook
            
            What kind of user is the feature intended for?
            Developers and contributors
            What inspired the request?
            The analysis of the Design System elements.
            What existing behavior do you want changed?
            None
            Any brand new behavior do you want to add to Dataverse?
            Storybook documentation template for the design system elements
            Any open or closed issues related to this feature request?
            
            #14</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: Design System</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>40</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Add mdx template for the Storybook documentation of the design system elements</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/40</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: Design System</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add mdx template for the Storybook documentation of the design system elements</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 29, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <totalCount>9</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFwh08</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>MellyGray</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            We would like to add the design tokens of our design system to Storybook and to the code using SASS variables to make it easier for developers to reference and use these tokens in their projects. These design tokens are specified in the [Design System analysis document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.pjqhiu86e7l8).
            
            ## What kind of user is the feature intended for?
            
            This feature is intended for developers who use Storybook to build and test components for our web application.
            
            ## What inspired the request?
            
            Our design system includes a set of design tokens that define our brand colors, typography, spacing, and other styles. These tokens are used consistently across our applications to ensure a cohesive and polished user experience. However, developers currently have to manually reference these tokens in their code, which can be time-consuming and error-prone. By adding the design tokens with SASS variables and document them in the Storybook, we can provide a centralized and easy-to-use reference for developers.
            
            Some references for the Storybook:
            
            - [Vibe Design System](https://style.monday.com/?path=/docs/foundations-colors--page)
            - [Storybook Design System](https://storybook-design-system.netlify.app/?path=/docs/colors--page)
            - [More references](https://storybook.js.org/showcase)
            
            ## What existing behavior do you want changed?
            
            We want to add a new section to Storybook that displays our design tokens in a clear and organized way. This section should include documentation on how to use each token, as well as examples of how the tokens can be applied to different components. This tokens would be used in the scss files using SASS variables. 
            
            ## Any brand new behavior do you want to add to Dataverse?
            
            No, this feature request does not introduce any brand new behavior to Dataverse.
            
            ## Any open or closed issues related to this feature request?
            
            - https://github.com/IQSS/dataverse-frontend/issues/14</body>
            <bodyText>Overview of the Feature Request
            We would like to add the design tokens of our design system to Storybook and to the code using SASS variables to make it easier for developers to reference and use these tokens in their projects. These design tokens are specified in the Design System analysis document.
            What kind of user is the feature intended for?
            This feature is intended for developers who use Storybook to build and test components for our web application.
            What inspired the request?
            Our design system includes a set of design tokens that define our brand colors, typography, spacing, and other styles. These tokens are used consistently across our applications to ensure a cohesive and polished user experience. However, developers currently have to manually reference these tokens in their code, which can be time-consuming and error-prone. By adding the design tokens with SASS variables and document them in the Storybook, we can provide a centralized and easy-to-use reference for developers.
            Some references for the Storybook:
            
            Vibe Design System
            Storybook Design System
            More references
            
            What existing behavior do you want changed?
            We want to add a new section to Storybook that displays our design tokens in a clear and organized way. This section should include documentation on how to use each token, as well as examples of how the tokens can be applied to different components. This tokens would be used in the scss files using SASS variables.
            Any brand new behavior do you want to add to Dataverse?
            No, this feature request does not introduce any brand new behavior to Dataverse.
            Any open or closed issues related to this feature request?
            
            #14</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: Design System</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>30</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Create the design tokens of the design system using SASS variables</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/30</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: Design System</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create the design tokens of the design system using SASS variables</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFrqPk</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>ekraffmiller</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            We would like to add the toast element of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent modals across our applications.
            
            The toast element would be the one documented in the [Design System Analysis document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.fmvlx98dp83q).
            
            This toast element would be using the Design tokens as SASS variables if applicable. These variables are described in [the document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.byjoci5aw2)
            
            ## What kind of user is the feature intended for?
            
            This feature is intended for developers who use React to build and test components for our web applications.
            
            ## What inspired the request?
            
            Our design system includes a toast element that is used consistently across our application. By creating a reusable React component for this element and documenting it in Storybook, we can provide a centralized and easy-to-use reference for developers.
            
            Some references for the Storybook:
            
            - [Vibe Design System](https://style.monday.com/?path=/docs/foundations-colors--page)
            - [Storybook Design System](https://storybook-design-system.netlify.app/?path=/docs/colors--page)
            - [More references](https://storybook.js.org/showcase)
            
            ## What existing behavior do you want changed?
            
            We want to add a new section to Storybook that displays our toast element as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            
            ## Any brand new behavior do you want to add to Dataverse?
            
            No, this feature request does not introduce any brand new behavior to Dataverse.
            
            ## Any open or closed issues related to this feature request?
            
            - https://github.com/IQSS/dataverse-frontend/issues/14
            
            - https://github.com/IQSS/dataverse-frontend/issues/30</body>
            <bodyText>Overview of the Feature Request
            We would like to add the toast element of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent modals across our applications.
            The toast element would be the one documented in the Design System Analysis document.
            This toast element would be using the Design tokens as SASS variables if applicable. These variables are described in the document
            What kind of user is the feature intended for?
            This feature is intended for developers who use React to build and test components for our web applications.
            What inspired the request?
            Our design system includes a toast element that is used consistently across our application. By creating a reusable React component for this element and documenting it in Storybook, we can provide a centralized and easy-to-use reference for developers.
            Some references for the Storybook:
            
            Vibe Design System
            Storybook Design System
            More references
            
            What existing behavior do you want changed?
            We want to add a new section to Storybook that displays our toast element as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            Any brand new behavior do you want to add to Dataverse?
            No, this feature request does not introduce any brand new behavior to Dataverse.
            Any open or closed issues related to this feature request?
            
            
            #14
            
            
            #30</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: Design System</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>38</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Create the toast element of the design system</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/38</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: Design System</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create the toast element of the design system</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 29, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFt_jo</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>ekraffmiller</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            We would like to add the tooltips elements of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent tooltips elements across our applications.
            
            The tooltips elements would be the ones documented in the [Design System Analysis document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.uj2douoq4na0).
            
            These tooltips elements would be using the Design tokens as SASS variables if applicable. These variables are described in [the document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.byjoci5aw2)
            
            ## What kind of user is the feature intended for?
            
            This feature is intended for developers who use React to build and test components for our web applications.
            
            ## What inspired the request?
            
            Our design system includes a set of tooltips elements that are used consistently across our applications. By creating reusable React components for these elements and documenting them in Storybook, we can provide a centralized and easy-to-use reference for developers.
            
            Some references for the Storybook:
            
            - [Vibe Design System](https://style.monday.com/?path=/docs/foundations-colors--page)
            - [Storybook Design System](https://storybook-design-system.netlify.app/?path=/docs/colors--page)
            - [More references](https://storybook.js.org/showcase)
            
            ## What existing behavior do you want changed?
            
            We want to add a new section to Storybook that displays our tooltips elements as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            
            ## Any brand new behavior do you want to add to Dataverse?
            
            No, this feature request does not introduce any brand new behavior to Dataverse.
            
            ## Any open or closed issues related to this feature request?
            
            - https://github.com/IQSS/dataverse-frontend/issues/14
            
            - https://github.com/IQSS/dataverse-frontend/issues/30</body>
            <bodyText>Overview of the Feature Request
            We would like to add the tooltips elements of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent tooltips elements across our applications.
            The tooltips elements would be the ones documented in the Design System Analysis document.
            These tooltips elements would be using the Design tokens as SASS variables if applicable. These variables are described in the document
            What kind of user is the feature intended for?
            This feature is intended for developers who use React to build and test components for our web applications.
            What inspired the request?
            Our design system includes a set of tooltips elements that are used consistently across our applications. By creating reusable React components for these elements and documenting them in Storybook, we can provide a centralized and easy-to-use reference for developers.
            Some references for the Storybook:
            
            Vibe Design System
            Storybook Design System
            More references
            
            What existing behavior do you want changed?
            We want to add a new section to Storybook that displays our tooltips elements as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            Any brand new behavior do you want to add to Dataverse?
            No, this feature request does not introduce any brand new behavior to Dataverse.
            Any open or closed issues related to this feature request?
            
            
            #14
            
            
            #30</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: Design System</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>37</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Create tooltips of the design system</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/37</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: Design System</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create tooltips of the design system</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 29, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFt_qI</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            We would like to add the button group element of our design system as React component and document it in Storybook. This will make it easier for developers to use and maintain consistent button groups across our applications.
            
            The button groups would be the ones documented in the [Design System Analysis document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.2pztj1o8ldpe).
            
            ## What kind of user is the feature intended for?
            
            This feature is intended for developers who use React to build and test components for our web applications.
            
            ## What inspired the request?
            
            Our design system includes a set of buttons and dropdowns that are used consistently across our applications. In the PR review we talked about the button groups with should be part of the design system.
            
            - https://github.com/IQSS/dataverse-frontend/pull/41
            
            ## What existing behavior do you want changed?
            
            We want to add a new section to Storybook that displays the button group as a React component. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            
            ## Any brand new behavior do you want to add to Dataverse?
            
            No, this feature request does not introduce any brand new behavior to Dataverse.
            
            ## Any open or closed issues related to this feature request?
            
            - https://github.com/IQSS/dataverse-frontend/issues/32
            - https://github.com/IQSS/dataverse-frontend/issues/14</body>
            <bodyText>Overview of the Feature Request
            We would like to add the button group element of our design system as React component and document it in Storybook. This will make it easier for developers to use and maintain consistent button groups across our applications.
            The button groups would be the ones documented in the Design System Analysis document.
            What kind of user is the feature intended for?
            This feature is intended for developers who use React to build and test components for our web applications.
            What inspired the request?
            Our design system includes a set of buttons and dropdowns that are used consistently across our applications. In the PR review we talked about the button groups with should be part of the design system.
            
            #41
            
            What existing behavior do you want changed?
            We want to add a new section to Storybook that displays the button group as a React component. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            Any brand new behavior do you want to add to Dataverse?
            No, this feature request does not introduce any brand new behavior to Dataverse.
            Any open or closed issues related to this feature request?
            
            #32
            #14</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: Design System</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>45</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Create the ButtonGroup of the design system</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/45</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: Design System</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create the ButtonGroup of the design system</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Re-arch: SPA MVP (Guillermo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgF1YBA</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            We would like to add the modal element of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent modals across our applications.
            
            The modal element would be the one documented in the [Design System Analysis document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.qhr17m77uhlt).
            
            This modal element would be using the Design tokens as SASS variables if applicable. These variables are described in [the document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.byjoci5aw2)
            
            ## What kind of user is the feature intended for?
            
            This feature is intended for developers who use React to build and test components for our web applications.
            
            ## What inspired the request?
            
            Our design system includes a modal element that is used consistently across our application. By creating a reusable React component for this element and documenting it in Storybook, we can provide a centralized and easy-to-use reference for developers.
            
            Some references for the Storybook:
            
            - [Vibe Design System](https://style.monday.com/?path=/docs/foundations-colors--page)
            - [Storybook Design System](https://storybook-design-system.netlify.app/?path=/docs/colors--page)
            - [More references](https://storybook.js.org/showcase)
            
            ## What existing behavior do you want changed?
            
            We want to add a new section to Storybook that displays our modal element as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            
            ## Any brand new behavior do you want to add to Dataverse?
            
            No, this feature request does not introduce any brand new behavior to Dataverse.
            
            ## Any open or closed issues related to this feature request?
            
            - https://github.com/IQSS/dataverse-frontend/issues/14
            
            - https://github.com/IQSS/dataverse-frontend/issues/30</body>
            <bodyText>Overview of the Feature Request
            We would like to add the modal element of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent modals across our applications.
            The modal element would be the one documented in the Design System Analysis document.
            This modal element would be using the Design tokens as SASS variables if applicable. These variables are described in the document
            What kind of user is the feature intended for?
            This feature is intended for developers who use React to build and test components for our web applications.
            What inspired the request?
            Our design system includes a modal element that is used consistently across our application. By creating a reusable React component for this element and documenting it in Storybook, we can provide a centralized and easy-to-use reference for developers.
            Some references for the Storybook:
            
            Vibe Design System
            Storybook Design System
            More references
            
            What existing behavior do you want changed?
            We want to add a new section to Storybook that displays our modal element as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            Any brand new behavior do you want to add to Dataverse?
            No, this feature request does not introduce any brand new behavior to Dataverse.
            Any open or closed issues related to this feature request?
            
            
            #14
            
            
            #30</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: Design System</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>36</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Create the modal element of the design system</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/36</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: Design System</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create the modal element of the design system</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Re-arch: SPA MVP (Guillermo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFt_uY</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            We would like to add the accordion element of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent accordion elements across our applications.
            
            The accordion elements would be the ones documented in the [Design System Analysis document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.2rshrjavenkd).
            
            These accordion elements would be using the Design tokens as SASS variables if applicable. These variables are described in [the document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.byjoci5aw2)
            
            ## What kind of user is the feature intended for?
            
            This feature is intended for developers who use React to build and test components for our web applications.
            
            ## What inspired the request?
            
            Our design system includes an accordion element that is used consistently across our application. By creating a reusable React component for this element and documenting it in Storybook, we can provide a centralized and easy-to-use reference for developers.
            
            Some references for the Storybook:
            
            - [Vibe Design System](https://style.monday.com/?path=/docs/foundations-colors--page)
            - [Storybook Design System](https://storybook-design-system.netlify.app/?path=/docs/colors--page)
            - [More references](https://storybook.js.org/showcase)
            
            ## What existing behavior do you want changed?
            
            We want to add a new section to Storybook that displays our accordion element as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            
            ## Any brand new behavior do you want to add to Dataverse?
            
            No, this feature request does not introduce any brand new behavior to Dataverse.
            
            ## Any open or closed issues related to this feature request?
            
            - https://github.com/IQSS/dataverse-frontend/issues/14
            
            - https://github.com/IQSS/dataverse-frontend/issues/30</body>
            <bodyText>Overview of the Feature Request
            We would like to add the accordion element of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent accordion elements across our applications.
            The accordion elements would be the ones documented in the Design System Analysis document.
            These accordion elements would be using the Design tokens as SASS variables if applicable. These variables are described in the document
            What kind of user is the feature intended for?
            This feature is intended for developers who use React to build and test components for our web applications.
            What inspired the request?
            Our design system includes an accordion element that is used consistently across our application. By creating a reusable React component for this element and documenting it in Storybook, we can provide a centralized and easy-to-use reference for developers.
            Some references for the Storybook:
            
            Vibe Design System
            Storybook Design System
            More references
            
            What existing behavior do you want changed?
            We want to add a new section to Storybook that displays our accordion element as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            Any brand new behavior do you want to add to Dataverse?
            No, this feature request does not introduce any brand new behavior to Dataverse.
            Any open or closed issues related to this feature request?
            
            
            #14
            
            
            #30</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: Design System</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>35</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Create the accordion of the design system</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/35</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: Design System</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create the accordion of the design system</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Re-arch: SPA MVP (Guillermo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFt_1o</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MjUw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MjQx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            We would like to add the table elements of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent table elements across our applications.
            
            The table elements would be the ones documented in the [Design System Analysis document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.x2qrlcdwtvag).
            
            These table elements would be using the Design tokens as SASS variables if applicable. These variables are described in [the document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.byjoci5aw2)
            
            ## What kind of user is the feature intended for?
            
            This feature is intended for developers who use React to build and test components for our web applications.
            
            ## What inspired the request?
            
            Our design system includes a set of table elements that are used consistently across our applications. By creating reusable React components for these elements and documenting them in Storybook, we can provide a centralized and easy-to-use reference for developers.
            
            Some references for the Storybook:
            
            - [Vibe Design System](https://style.monday.com/?path=/docs/foundations-colors--page)
            - [Storybook Design System](https://storybook-design-system.netlify.app/?path=/docs/colors--page)
            - [More references](https://storybook.js.org/showcase)
            
            ## What existing behavior do you want changed?
            
            We want to add a new section to Storybook that displays our table elements as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            
            ## Any brand new behavior do you want to add to Dataverse?
            
            No, this feature request does not introduce any brand new behavior to Dataverse.
            
            ## Any open or closed issues related to this feature request?
            
            - https://github.com/IQSS/dataverse-frontend/issues/14
            
            - https://github.com/IQSS/dataverse-frontend/issues/30</body>
            <bodyText>Overview of the Feature Request
            We would like to add the table elements of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent table elements across our applications.
            The table elements would be the ones documented in the Design System Analysis document.
            These table elements would be using the Design tokens as SASS variables if applicable. These variables are described in the document
            What kind of user is the feature intended for?
            This feature is intended for developers who use React to build and test components for our web applications.
            What inspired the request?
            Our design system includes a set of table elements that are used consistently across our applications. By creating reusable React components for these elements and documenting them in Storybook, we can provide a centralized and easy-to-use reference for developers.
            Some references for the Storybook:
            
            Vibe Design System
            Storybook Design System
            More references
            
            What existing behavior do you want changed?
            We want to add a new section to Storybook that displays our table elements as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            Any brand new behavior do you want to add to Dataverse?
            No, this feature request does not introduce any brand new behavior to Dataverse.
            Any open or closed issues related to this feature request?
            
            
            #14
            
            
            #30</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: Design System</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>34</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Create the tables of the design system</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/34</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: Design System</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create the tables of the design system</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Re-arch: SPA MVP (Guillermo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFt_6U</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            We would like to add the navigation elements of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent navigation elements across our applications.
            
            The navigation elements would be the ones documented in the [Design System Analysis document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.8nqu9gh25f0n).
            
            These navigation elements would be using the Design tokens as SASS variables if applicable. These variables are described in [the document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.byjoci5aw2)
            
            The Header/navbar is already implemented as part of the Layout, but we may need to improve the Storybook documentation and tests and maybe use the design tokens as SASS variables for the brand color or any other font/color applicable.
            
            ## What kind of user is the feature intended for?
            
            This feature is intended for developers who use React to build and test components for our web applications.
            
            ## What inspired the request?
            
            Our design system includes a set of navigation elements that are used consistently across our applications. By creating reusable React components for these elements and documenting them in Storybook, we can provide a centralized and easy-to-use reference for developers.
            
            Some references for the Storybook:
            
            - [Vibe Design System](https://style.monday.com/?path=/docs/foundations-colors--page)
            - [Storybook Design System](https://storybook-design-system.netlify.app/?path=/docs/colors--page)
            - [More references](https://storybook.js.org/showcase)
            
            ## What existing behavior do you want changed?
            
            We want to add a new section to Storybook that displays our navigation elements as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            
            ## Any brand new behavior do you want to add to Dataverse?
            
            No, this feature request does not introduce any brand new behavior to Dataverse.
            
            ## Any open or closed issues related to this feature request?
            
            - https://github.com/IQSS/dataverse-frontend/issues/14
            
            - https://github.com/IQSS/dataverse-frontend/issues/30</body>
            <bodyText>Overview of the Feature Request
            We would like to add the navigation elements of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent navigation elements across our applications.
            The navigation elements would be the ones documented in the Design System Analysis document.
            These navigation elements would be using the Design tokens as SASS variables if applicable. These variables are described in the document
            The Header/navbar is already implemented as part of the Layout, but we may need to improve the Storybook documentation and tests and maybe use the design tokens as SASS variables for the brand color or any other font/color applicable.
            What kind of user is the feature intended for?
            This feature is intended for developers who use React to build and test components for our web applications.
            What inspired the request?
            Our design system includes a set of navigation elements that are used consistently across our applications. By creating reusable React components for these elements and documenting them in Storybook, we can provide a centralized and easy-to-use reference for developers.
            Some references for the Storybook:
            
            Vibe Design System
            Storybook Design System
            More references
            
            What existing behavior do you want changed?
            We want to add a new section to Storybook that displays our navigation elements as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            Any brand new behavior do you want to add to Dataverse?
            No, this feature request does not introduce any brand new behavior to Dataverse.
            Any open or closed issues related to this feature request?
            
            
            #14
            
            
            #30</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: Design System</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>33</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Create the navigation elements of the design system</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/33</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: Design System</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create the navigation elements of the design system</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Re-arch: SPA MVP (Guillermo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFuAAQ</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            We would like to add form elements of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent form elements across our applications. We are also planning to export this elements in an npm module so they should be independent of the business logic.
            
            The form elements would be the ones documented in the [Design System Analysis document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.8nqu9gh25f0n).
            
            These form elements would be using the Design tokens as SASS variables if applicable. These variables are described in [the document](https://docs.google.com/document/d/1OxCQO7B-yJaMWRl8EzuflcSmIaCmVSs19aoD83PjPmA/edit#heading=h.byjoci5aw2)
            
            ## What kind of user is the feature intended for?
            
            This feature is intended for developers who use React to build and test components for our web application.
            
            ## What inspired the request?
            
            Our design system includes a set of form elements, such as text inputs, select menus, and checkboxes, that are used consistently across our applications. By creating reusable React components for these elements and documenting them in Storybook, we can provide a centralized and easy-to-use reference for developers. Moreover, this components would be part of a components library exported to an npm module so contributors can use them in their Dataverse plugins.
            
            Some references for the Storybook:
            
            - [Vibe Design System](https://style.monday.com/?path=/docs/foundations-colors--page)
            - [Storybook Design System](https://storybook-design-system.netlify.app/?path=/docs/colors--page)
            - [More references](https://storybook.js.org/showcase)
            
            ## What existing behavior do you want changed?
            
            We want to add a new section to Storybook that displays our form elements as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            
            ## Any brand new behavior do you want to add to Dataverse?
            
            No, this feature request does not introduce any brand new behavior to Dataverse.
            
            ## Any open or closed issues related to this feature request?
            
            - https://github.com/IQSS/dataverse-frontend/issues/14
            
            - https://github.com/IQSS/dataverse-frontend/issues/30</body>
            <bodyText>Overview of the Feature Request
            We would like to add form elements of our design system as React components and document them in Storybook. This will make it easier for developers to use and maintain consistent form elements across our applications. We are also planning to export this elements in an npm module so they should be independent of the business logic.
            The form elements would be the ones documented in the Design System Analysis document.
            These form elements would be using the Design tokens as SASS variables if applicable. These variables are described in the document
            What kind of user is the feature intended for?
            This feature is intended for developers who use React to build and test components for our web application.
            What inspired the request?
            Our design system includes a set of form elements, such as text inputs, select menus, and checkboxes, that are used consistently across our applications. By creating reusable React components for these elements and documenting them in Storybook, we can provide a centralized and easy-to-use reference for developers. Moreover, this components would be part of a components library exported to an npm module so contributors can use them in their Dataverse plugins.
            Some references for the Storybook:
            
            Vibe Design System
            Storybook Design System
            More references
            
            What existing behavior do you want changed?
            We want to add a new section to Storybook that displays our form elements as React components. This section should include documentation on how to use each component, as well as examples of how the components can be customized.
            Any brand new behavior do you want to add to Dataverse?
            No, this feature request does not introduce any brand new behavior to Dataverse.
            Any open or closed issues related to this feature request?
            
            
            #14
            
            
            #30</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: Design System</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>31</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Create the form elements of the design system</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/31</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: Design System</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create the form elements of the design system</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Re-arch: SPA MVP (Guillermo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFuANQ</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            The goal is to create a npm module that includes the elements of the Dataverse Design System, decoupled from the frontend application. The initial elements to be included in this plugin will be identified in #14.
            
            This npm module will have an associated GitHub repository, as well as independent versioning. The module will be installed on the Dataverse Frontend application, as well as any other application of the community which needs to use the Dataverse UI elements. The future Dataverse plugins, as described in #23, will be able to use this module as well.
            
            We will develop the UI elements identified in #14 directly on this module.
            
            ## What kind of user is the feature intended for?
            Dataverse frontend developers
            
            ## What inspired the request?
            - Frontend subgroup weekly meeting
            - #23 
            
            ## What existing behavior do you want changed?
            N/A
            
            ## Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            
            ## Any related open or closed issues to this feature request?
            - #14 
            - #23 
            - #39</body>
            <bodyText>Overview of the Feature Request
            The goal is to create a npm module that includes the elements of the Dataverse Design System, decoupled from the frontend application. The initial elements to be included in this plugin will be identified in #14.
            This npm module will have an associated GitHub repository, as well as independent versioning. The module will be installed on the Dataverse Frontend application, as well as any other application of the community which needs to use the Dataverse UI elements. The future Dataverse plugins, as described in #23, will be able to use this module as well.
            We will develop the UI elements identified in #14 directly on this module.
            What kind of user is the feature intended for?
            Dataverse frontend developers
            What inspired the request?
            
            Frontend subgroup weekly meeting
            #23
            
            What existing behavior do you want changed?
            N/A
            Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            Any related open or closed issues to this feature request?
            
            #14
            #23
            #39</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: Design System</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>28</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Create a npm module for the Dataverse Design System so the community can use it for their applications and future plugins</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/28</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: Design System</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create a npm module for the Dataverse Design System so the community can use it for their applications and future plugins</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Re-arch: SPA MVP (Guillermo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFiB0w</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>ekraffmiller</login>
              </nodes>
              <totalCount>1</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            Now that we have decided to use Cypress for our component testing,cwe need to add Cypress tests for the components that have already been created.
            
            ## What kind of user is the feature intended for?
            
            This feature is intended for developers who use React to build and test components for our web applications.
            
            ## What inspired the request?
            
            The analysis of the storybook testing capabilities #27 
            
            ## What existing behavior do you want changed?
            
            We need to add Cypress tests for the components that have already been created.
            
            ## Any brand new behavior do you want to add to Dataverse?
            
            No, this feature request does not introduce any brand new behavior to Dataverse.
            
            ## Any open or closed issues related to this feature request?
            
            - https://github.com/IQSS/dataverse-frontend/issues/27
            - https://github.com/IQSS/dataverse-frontend/issues/32</body>
            <bodyText>Overview of the Feature Request
            Now that we have decided to use Cypress for our component testing,cwe need to add Cypress tests for the components that have already been created.
            What kind of user is the feature intended for?
            This feature is intended for developers who use React to build and test components for our web applications.
            What inspired the request?
            The analysis of the storybook testing capabilities #27
            What existing behavior do you want changed?
            We need to add Cypress tests for the components that have already been created.
            Any brand new behavior do you want to add to Dataverse?
            No, this feature request does not introduce any brand new behavior to Dataverse.
            Any open or closed issues related to this feature request?
            
            #27
            #32</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>D: Design System</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>5</totalCount>
            </labels>
            <number>47</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Create Cypress component tests for existing UI components</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/47</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>D: Design System</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>5</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Create Cypress component tests for existing UI components</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>SPRINT READY</name>
            </nodes>
            <totalCount>5</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgF7pAE</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>The other day @GPortas and I spoke about how a good first step toward getting the frontend to talk to the backend could be to show the version of Dataverse in the bottom right corner, which is available via API as /api/info/version: https://guides.dataverse.org/en/5.13/api/native-api.html#show-dataverse-software-version-and-build-number
            
            `{"status":"OK","data":{"version":"5.13","build":"1244-79d6e57"}}` is what we currently see on the demo server: https://demo.dataverse.org/api/info/version
            
            Here's how the current JSF UI shows the version. Let's keep it the same:
            
            ![Screen Shot 2023-03-03 at 11 18 50 AM](https://user-images.githubusercontent.com/21006/222775025-f7d3e355-0ccc-42ff-9c68-04654d1d6247.png)
            ![Screen Shot 2023-03-03 at 11 19 32 AM](https://user-images.githubusercontent.com/21006/222775027-41678ca4-ca2b-406a-b50f-b5d20d8e973b.png)
            
            Relates to:
            
            - #6 
            - https://github.com/IQSS/dataverse/issues/9347</body>
            <bodyText>The other day @GPortas and I spoke about how a good first step toward getting the frontend to talk to the backend could be to show the version of Dataverse in the bottom right corner, which is available via API as /api/info/version: https://guides.dataverse.org/en/5.13/api/native-api.html#show-dataverse-software-version-and-build-number
            {"status":"OK","data":{"version":"5.13","build":"1244-79d6e57"}} is what we currently see on the demo server: https://demo.dataverse.org/api/info/version
            Here's how the current JSF UI shows the version. Let's keep it the same:
            
            
            Relates to:
            
            #6
            IQSS/dataverse#9347</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>MVP Milestone 2</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>12</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Add version number to bottom right of each page (e.g. v. 5.13 build 1244-79d6e57)</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/12</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>MVP Milestone 2</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add version number to bottom right of each page (e.g. v. 5.13 build 1244-79d6e57)</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Re-arch: SPA MVP (Guillermo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFPe5M</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            The goal is to set up the documentation guides for the Dataverse Frontend project, similar to the general sphinx-based Dataverse guides, but specific to the Frontend application.
            
            We don't necessarily have to use sphinx for these guides. Let's do research on possible implementations to find the best fit.
            
            ## What kind of user is the feature intended for?
            Dataverse users and frontend developers
            
            ## What inspired the request?
            - Recent needs to document frontend procedures. For example: application deployment and accessibility changes. We are currently documenting these procedures in the project README, though they will eventually be migrated to the guides once they are established.
            - Discussion with @pdurbin 
            - #16
            
            ## What existing behavior do you want changed?
            N/A
            
            ## Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            
            ## Any related open or closed issues to this feature request?
            - #16</body>
            <bodyText>Overview of the Feature Request
            The goal is to set up the documentation guides for the Dataverse Frontend project, similar to the general sphinx-based Dataverse guides, but specific to the Frontend application.
            We don't necessarily have to use sphinx for these guides. Let's do research on possible implementations to find the best fit.
            What kind of user is the feature intended for?
            Dataverse users and frontend developers
            What inspired the request?
            
            Recent needs to document frontend procedures. For example: application deployment and accessibility changes. We are currently documenting these procedures in the project README, though they will eventually be migrated to the guides once they are established.
            Discussion with @pdurbin
            #16
            
            What existing behavior do you want changed?
            N/A
            Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            Any related open or closed issues to this feature request?
            
            #16</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>3</totalCount>
            </labels>
            <number>26</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Add Dataverse Frontend guides</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/26</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>3</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add Dataverse Frontend guides</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Re-arch: SPA MVP (Guillermo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFh_SY</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            When including the SECURITY.md file, based on the same as the Dataverse core repository, I realized that it will be necessary to add security-related guides for the Frontend, since at the moment we are referencing the general guidelines of Dataverse:
            
            - https://guides.dataverse.org/en/latest/installation/config.html#securing-your-installation
            - https://guides.dataverse.org/en/latest/developers/security.html
            
            For including these security-related guides for the Frontend we need to close #26 first.
            
            ## What kind of user is the feature intended for?
            Dataverse frontend developers
            
            ## What inspired the request?
            - Including SECURITY.md for #2 
            
            ## What existing behavior do you want changed?
            N/A
            
            ## Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            
            ## Any related open or closed issues to this feature request?
            - #2 
            - #26</body>
            <bodyText>Overview of the Feature Request
            When including the SECURITY.md file, based on the same as the Dataverse core repository, I realized that it will be necessary to add security-related guides for the Frontend, since at the moment we are referencing the general guidelines of Dataverse:
            
            https://guides.dataverse.org/en/latest/installation/config.html#securing-your-installation
            https://guides.dataverse.org/en/latest/developers/security.html
            
            For including these security-related guides for the Frontend we need to close #26 first.
            What kind of user is the feature intended for?
            Dataverse frontend developers
            What inspired the request?
            
            Including SECURITY.md for #2
            
            What existing behavior do you want changed?
            N/A
            Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            Any related open or closed issues to this feature request?
            
            #2
            #26</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>16</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Update guides to include frontend security advices, practices and procedures</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/16</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Update guides to include frontend security advices, practices and procedures</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Re-arch: SPA MVP (Guillermo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFTqFQ</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>This is a follow up from last weeks front-end meeting where I presented a small example of how plugins could be integrated within an SPA. You can re-watch it on [DataverseTV](https://harvard.zoom.us/rec/play/tmIx4zwg4N6Fbe0TVTVjB85fcmLS6beYbrCkZJwTavWPo-8Ta_X1n5SMWKghHPX3AuP7L4EXS94mgdRr.t826wUdAi5n5hDWD?continueMode=true&amp;_x_zm_rtaid=gJ-RYbUkTDGMVhk0e-t0CA.1678807756035.ee9bc16f4ed6d4c8a2565ffb3c3424ce&amp;_x_zm_rhtaid=706) and inspect the code [here](https://codesandbox.io/s/plugin-store-example-b5m5s3).
            
            According to @GPortas the addition of a marketplace and plugin-support is more of a long-term goal than something that should be implemented in this phase. Hence, this issue is set as a reminder and collection of ideas how we can conceptualize this even further.
            
            I am happy to further investigate this and it would be awesome to collect ideas within this issue. Here are my previous thoughts condensed into some bullet points:
            
            * Marketplace for community and Dataverse plugins (+ metadatablocks?)
            * Plugins could modify the Dataverse UI and add extra buttons/tabs (Small utilities such as an ORCID Finder)
            * Plugins could transfer data to another web-app (such as a Review Tool)
            * Dedicated Plugin-Registry from which users can choose and transfer to the "Plugin-Store"-State
            </body>
            <bodyText>This is a follow up from last weeks front-end meeting where I presented a small example of how plugins could be integrated within an SPA. You can re-watch it on DataverseTV and inspect the code here.
            According to @GPortas the addition of a marketplace and plugin-support is more of a long-term goal than something that should be implemented in this phase. Hence, this issue is set as a reminder and collection of ideas how we can conceptualize this even further.
            I am happy to further investigate this and it would be awesome to collect ideas within this issue. Here are my previous thoughts condensed into some bullet points:
            
            Marketplace for community and Dataverse plugins (+ metadatablocks?)
            Plugins could modify the Dataverse UI and add extra buttons/tabs (Small utilities such as an ORCID Finder)
            Plugins could transfer data to another web-app (such as a Review Tool)
            Dedicated Plugin-Registry from which users can choose and transfer to the "Plugin-Store"-State</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>pm.GREI-d-2.7.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-2.7.2</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>23</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Dataverse marketplace and modularity</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/23</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>pm.GREI-d-2.7.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-2.7.2</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Dataverse marketplace and modularity</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Re-arch: SPA MVP (Guillermo)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFh9xk</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>This is a placeholder for us to research where we can add in support for organizational and funder identifers into Dataverse's metadata (at the Account, Dataverse and Dataset level since Affiliations exist throughout these pieces).
            </body>
            <bodyText>This is a placeholder for us to research where we can add in support for organizational and funder identifers into Dataverse's metadata (at the Account, Dataverse and Dataset level since Affiliations exist throughout these pieces).</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-27T18:28:18Z</closedAt>
            <labels>
              <nodes>
                <name>Status: UX &amp; UI</name>
              </nodes>
              <nodes>
                <name>Type: Suggestion</name>
              </nodes>
              <nodes>
                <name>Feature: Metadata</name>
              </nodes>
              <nodes>
                <name>User Role: Curator</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.5.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.5.1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.5.2</name>
              </nodes>
              <totalCount>7</totalCount>
            </labels>
            <number>3074</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Add Support for Organizational and Funder Identifiers</title>
            <url>https://github.com/IQSS/dataverse/issues/3074</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Status: UX &amp; UI</name>
                </nodes>
                <nodes>
                  <name>Type: Suggestion</name>
                </nodes>
                <nodes>
                  <name>Feature: Metadata</name>
                </nodes>
                <nodes>
                  <name>User Role: Curator</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.5.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.5.1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.5.2</name>
                </nodes>
                <totalCount>7</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Add Support for Organizational and Funder Identifiers</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Harvard Dataverse Instance (Sonia)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFvDWU</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MjYw</endCursor>
          <hasNextPage>True</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MjUx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages> <pages>
  <organization>
    <email>None</email>
    <id>MDEyOk9yZ2FuaXphdGlvbjY3NTIzNw==</id>
    <login>IQSS</login>
    <projectV2>
      <closed>False</closed>
      <closedAt>None</closedAt>
      <createdAt>2022-10-13T16:30:18Z</createdAt>
      <creator>
        <login>mreekie</login>
      </creator>
      <id>PVT_kwDOAApNpc4AHKIs</id>
      <items>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>9431</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 3</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>9482</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>IQSS/9431-support checksum alg in direct uploads</title>
            <url>https://github.com/IQSS/dataverse/pull/9482</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 3</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>IQSS/9431-support checksum alg in direct uploads</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>External Commitments (Jim)</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgFwY08</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <closed>True</closed>
            <closedAt>2022-11-30T19:36:08Z</closedAt>
            <closingIssuesReferences>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Feature: Geospatial</name>
              </nodes>
              <nodes>
                <name>pm.netcdf-hdf5.d</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>8239</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Geospatial search</title>
            <url>https://github.com/IQSS/dataverse/pull/8239</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>1</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Geospatial</name>
                </nodes>
                <nodes>
                  <name>pm.netcdf-hdf5.d</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <milestone>
                <title>5.13</title>
              </milestone>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Geospatial search</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>Pre December 2022</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>NIH NetCDF (Phil)</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgF0Rxs</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>If you try to create a guestbook with a custom question that has more than 255 characters, the result us the success page, but no new guestbook is created. (in the log we see an exception that gets thrown.
            
            ```
            org.postgresql.util.PSQLException: ERROR: value too long for type character varying(255)
            Error Code: 0
            Call: INSERT INTO CUSTOMQUESTION (DISPLAYORDER, HIDDEN, QUESTIONSTRING, QUESTIONTYPE, REQUIRED, GUESTBOOK_ID) VALUES (?, ?, ?, ?, ?, ?)
            ```
            
            We should do one of the following: 
            a) keep the user on the input page with the error message at the top, 
            b) limit # of characters that can be input, or 
            c) allow longer questions</body>
            <bodyText>If you try to create a guestbook with a custom question that has more than 255 characters, the result us the success page, but no new guestbook is created. (in the log we see an exception that gets thrown.
            org.postgresql.util.PSQLException: ERROR: value too long for type character varying(255)
            Error Code: 0
            Call: INSERT INTO CUSTOMQUESTION (DISPLAYORDER, HIDDEN, QUESTIONSTRING, QUESTIONTYPE, REQUIRED, GUESTBOOK_ID) VALUES (?, ?, ?, ?, ?, ?)
            
            We should do one of the following:
            a) keep the user on the input page with the error message at the top,
            b) limit # of characters that can be input, or
            c) allow longer questions</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </labels>
            <number>9492</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Creating a guestbook with a custom question that has more than 255 characters says "success" but silently fails</title>
            <url>https://github.com/IQSS/dataverse/issues/9492</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Creating a guestbook with a custom question that has more than 255 characters says "success" but silently fails</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Dataverse Team (Gustavo)</name>
            </nodes>
            <totalCount>3</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgF4wLo</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <closingIssuesReferences>
              <nodes>
                <number>32</number>
              </nodes>
              <totalCount>1</totalCount>
            </closingIssuesReferences>
            <labels>
              <nodes>
                <name>Size: 10</name>
              </nodes>
              <totalCount>1</totalCount>
            </labels>
            <number>41</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>32 - Add buttons and dropdowns of the design system</title>
            <url>https://github.com/IQSS/dataverse-frontend/pull/41</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>2</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Size: 10</name>
                </nodes>
                <totalCount>1</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>32 - Add buttons and dropdowns of the design system</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 29, 2023</name>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <nodes>
              <field>
                <name>ScratchCheckbox</name>
              </field>
              <name>Checked</name>
            </nodes>
            <totalCount>8</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgF_Mvg</id>
          <type>PULL_REQUEST</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            This issue is created within the scope of IQSS/dataverse#9423.
            
            Since there are already approaches and ongoing work for Dataverse application containerization, the goal of this issue is to analyze the existing resources and achievements, which can be useful for creating the Dataverse development container needed for IQSS/dataverse#9423 and to complement IQSS/dataverse#9414.
            
            ## What kind of user is the feature intended for?
            Developers
            
            ## What inspired the request?
            - Working on IQSS/dataverse#9423
            - Standup discussions
            
            ## What existing behavior do you want changed?
            N/A
            
            ## Any brand new behavior do you want to add to Dataverse?
            No, should be the same.
            
            ## Any related open or closed issues to this feature request?
            - IQSS/dataverse#9423
            - IQSS/dataverse#9414</body>
            <bodyText>Overview of the Feature Request
            This issue is created within the scope of #9423.
            Since there are already approaches and ongoing work for Dataverse application containerization, the goal of this issue is to analyze the existing resources and achievements, which can be useful for creating the Dataverse development container needed for #9423 and to complement #9414.
            What kind of user is the feature intended for?
            Developers
            What inspired the request?
            
            Working on #9423
            Standup discussions
            
            What existing behavior do you want changed?
            N/A
            Any brand new behavior do you want to add to Dataverse?
            No, should be the same.
            Any related open or closed issues to this feature request?
            
            #9423
            #9414</bodyText>
            <closed>True</closed>
            <closedAt>2023-03-13T16:14:16Z</closedAt>
            <labels>
              <nodes>
                <name>Feature: Code Infrastructure</name>
              </nodes>
              <nodes>
                <name>Feature: Developer Guide</name>
              </nodes>
              <nodes>
                <name>Containers &amp; Cloud</name>
              </nodes>
              <nodes>
                <name>NIH OTA: 1.7.1 (reArchitecture)</name>
              </nodes>
              <nodes>
                <name>Size: 33</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>6</totalCount>
            </labels>
            <number>9415</number>
            <repository>
              <name>dataverse</name>
            </repository>
            <title>Analyze Dataverse application containerization for development</title>
            <url>https://github.com/IQSS/dataverse/issues/9415</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>MDEwOlJlcG9zaXRvcnkxNDA1MTAwNA==</id>
                <name>dataverse</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>Feature: Code Infrastructure</name>
                </nodes>
                <nodes>
                  <name>Feature: Developer Guide</name>
                </nodes>
                <nodes>
                  <name>Containers &amp; Cloud</name>
                </nodes>
                <nodes>
                  <name>NIH OTA: 1.7.1 (reArchitecture)</name>
                </nodes>
                <nodes>
                  <name>Size: 33</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>6</totalCount>
              </labels>
            </nodes>
            <nodes>
              <pullRequests>
                <totalCount>1</totalCount>
              </pullRequests>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Analyze Dataverse application containerization for development</text>
            </nodes>
            <nodes>
              <field>
                <name>OGQueue</name>
              </field>
              <text>Re-arch: SPA MVP (Guillermo)</text>
            </nodes>
            <nodes>
              <field>
                <name>LatestSprintIssueActiveIn</name>
              </field>
              <name>March 1, 2023</name>
            </nodes>
            <totalCount>6</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgF_NMU</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>## Overview of the Feature Request
            
            During several Re-architecture discussions, different options have been evaluated for the infrastructure of the Dataverse frontend (S3, Dataverse Payara server, Docker, etc), as well as for its deployment (.zip vs .war, pull vs push, bash and Python scripts, Jenkins, etc).
            
            Although being a static website there are several options for its deployment and infrastructure, we need to offer a standard solution to ease the installation process. For example, when planning to deploy the frontend to a QA environment, we have had to evaluate different options on the fly.
            
            The goal is to define a standard design for the infrastructure of the Dataverse frontend SPA and configure the necessary automations that allow the application to be easily deployed to the chosen standard infrastructure. For greater adaptability, It is important that the chosen solution does not exclude the application from being deployed in different ways.
            
            Once the design is established, it should be applied to the QA environment, since it should mirror a production SPA environment. Until this issue is completed, we will use alternative ways to deploy to QA in order not to block the QA phase of the workflow.
            
            Possible approach to follow:
            
            _We can offer a transition solution for people who want to run the SPA alongside Dataverse in an all in one solution - serve it via payara through proxypass but also offer a clean sheet deployment guide such as S3 or some other method, similar to how we described our server architecture: start out with all components on a single server and as your needs grow you can place different services, ie db, solr, payara, on different servers or even in a cluster._
            
            ## What kind of user is the feature intended for?
            Dataverse frontend developers and QA
            
            ## What inspired the request?
            - Working on #5 
            - Discussion with @kcondon
            
            ## What existing behavior do you want changed?
            N/A
            
            ## Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            
            ## Any related open or closed issues to this feature request?
            
            - #5 </body>
            <bodyText>Overview of the Feature Request
            During several Re-architecture discussions, different options have been evaluated for the infrastructure of the Dataverse frontend (S3, Dataverse Payara server, Docker, etc), as well as for its deployment (.zip vs .war, pull vs push, bash and Python scripts, Jenkins, etc).
            Although being a static website there are several options for its deployment and infrastructure, we need to offer a standard solution to ease the installation process. For example, when planning to deploy the frontend to a QA environment, we have had to evaluate different options on the fly.
            The goal is to define a standard design for the infrastructure of the Dataverse frontend SPA and configure the necessary automations that allow the application to be easily deployed to the chosen standard infrastructure. For greater adaptability, It is important that the chosen solution does not exclude the application from being deployed in different ways.
            Once the design is established, it should be applied to the QA environment, since it should mirror a production SPA environment. Until this issue is completed, we will use alternative ways to deploy to QA in order not to block the QA phase of the workflow.
            Possible approach to follow:
            We can offer a transition solution for people who want to run the SPA alongside Dataverse in an all in one solution - serve it via payara through proxypass but also offer a clean sheet deployment guide such as S3 or some other method, similar to how we described our server architecture: start out with all components on a single server and as your needs grow you can place different services, ie db, solr, payara, on different servers or even in a cluster.
            What kind of user is the feature intended for?
            Dataverse frontend developers and QA
            What inspired the request?
            
            Working on #5
            Discussion with @kcondon
            
            What existing behavior do you want changed?
            N/A
            Any brand new behavior do you want to add to Dataverse Frontend?
            N/A
            Any related open or closed issues to this feature request?
            
            #5</bodyText>
            <closed>True</closed>
            <closedAt>2023-04-10T11:36:45Z</closedAt>
            <labels>
              <nodes>
                <name>MVP Milestone 1</name>
              </nodes>
              <nodes>
                <name>pm.GREI-d-1.7.1</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>6</number>
            <repository>
              <name>dataverse-frontend</name>
            </repository>
            <title>Design and configure a default option for infrastructure and deployment</title>
            <url>https://github.com/IQSS/dataverse-frontend/issues/6</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOI3pPiw</id>
                <name>dataverse-frontend</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>MVP Milestone 1</name>
                </nodes>
                <nodes>
                  <name>pm.GREI-d-1.7.1</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Design and configure a default option for infrastructure and deployment</text>
            </nodes>
            <nodes>
              <field>
                <name>Status</name>
              </field>
              <name>Clear of the Backlog</name>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgGAk8M</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes></nodes>
              <totalCount>0</totalCount>
            </assignees>
            <body>The actual bklog issue is:  [bklog: Deliverable - Upgrade to Payara 6 and from EE 8 to EE 10 (end of Payara 5 Community Edition security patches Q2/2022) #8305](https://github.com/IQSS/dataverse/issues/8305)
            
            It could not be moved over to this repo because it's got attached PRs.</body>
            <bodyText>The actual bklog issue is:  bklog: Deliverable - Upgrade to Payara 6 and from EE 8 to EE 10 (end of Payara 5 Community Edition security patches Q2/2022) #8305
            It could not be moved over to this repo because it's got attached PRs.</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>D: Payara 6 Upgrade</name>
              </nodes>
              <nodes>
                <name>bklog: Deliverable</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>28</number>
            <repository>
              <name>dataverse-pm</name>
            </repository>
            <title>bklog: Deliverable - Upgrade to Payara 6 and from EE 8 to EE 10 (Placeholder issue)</title>
            <url>https://github.com/IQSS/dataverse-pm/issues/28</url>
          </content>
          <fieldValues>
            <nodes>
              <repository>
                <id>R_kgDOIwMRzQ</id>
                <name>dataverse-pm</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>D: Payara 6 Upgrade</name>
                </nodes>
                <nodes>
                  <name>bklog: Deliverable</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>bklog: Deliverable - Upgrade to Payara 6 and from EE 8 to EE 10 (Placeholder issue)</text>
            </nodes>
            <totalCount>3</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgGA6vM</id>
          <type>ISSUE</type>
        </nodes>
        <nodes>
          <content>
            <assignees>
              <nodes>
                <login>landreev</login>
              </nodes>
              <nodes>
                <login>scolapasta</login>
              </nodes>
              <totalCount>2</totalCount>
            </assignees>
            <body>This ticket is a placeholder for general API rate and access limiting logic to better control the load placed on the service and provide options in case of system instability.
            
            Rate limiting was mentioned during search api testing and github search api uses this concept too:
            https://developer.github.com/v3/search/
            
            Limiting access might involve varying degrees of options: general api access on/off switch, per api, and/or whitelist/blacklist of ip addresses/ users. The last might be integrated with groups and permissions. 
            
            ---
            
            Update: additional terms for this:
            
            - API throttling</body>
            <bodyText>This ticket is a placeholder for general API rate and access limiting logic to better control the load placed on the service and provide options in case of system instability.
            Rate limiting was mentioned during search api testing and github search api uses this concept too:
            https://developer.github.com/v3/search/
            Limiting access might involve varying degrees of options: general api access on/off switch, per api, and/or whitelist/blacklist of ip addresses/ users. The last might be integrated with groups and permissions.
            
            Update: additional terms for this:
            
            API throttling</bodyText>
            <closed>False</closed>
            <closedAt>None</closedAt>
            <labels>
              <nodes>
                <name>D: FixRateLimitingBehaviors</name>
              </nodes>
              <nodes>
                <name>bklog: Deliverable</name>
              </nodes>
              <totalCount>2</totalCount>
            </labels>
            <number>23</number>
            <repository>
              <name>dataverse-pm</name>
            </repository>
            <title>Spike: Revisit the issue of adding rate limiting logic to the application, create a list of actionable issues to start the effort.</title>
            <url>https://github.com/IQSS/dataverse-pm/issues/23</url>
          </content>
          <fieldValues>
            <nodes>
              <users>
                <totalCount>2</totalCount>
              </users>
            </nodes>
            <nodes>
              <repository>
                <id>R_kgDOIwMRzQ</id>
                <name>dataverse-pm</name>
              </repository>
            </nodes>
            <nodes>
              <labels>
                <nodes>
                  <name>D: FixRateLimitingBehaviors</name>
                </nodes>
                <nodes>
                  <name>bklog: Deliverable</name>
                </nodes>
                <totalCount>2</totalCount>
              </labels>
            </nodes>
            <nodes>
              <field>
                <name>Title</name>
              </field>
              <text>Spike: Revisit the issue of adding rate limiting logic to the application, create a list of actionable issues to start the effort.</text>
            </nodes>
            <totalCount>4</totalCount>
          </fieldValues>
          <id>PVTI_lADOAApNpc4AHKIszgGA6yw</id>
          <type>ISSUE</type>
        </nodes>
        <pageInfo>
          <endCursor>MjY4</endCursor>
          <hasNextPage>False</hasNextPage>
          <hasPreviousPage>True</hasPreviousPage>
          <startCursor>MjYx</startCursor>
        </pageInfo>
        <totalCount>268</totalCount>
      </items>
      <number>34</number>
      <title>Dataverse_Global_Backlog</title>
      <updatedAt>2023-04-10T14:29:42Z</updatedAt>
      <url>https://github.com/orgs/IQSS/projects/34</url>
    </projectV2>
    <projectsUrl>https://github.com/orgs/IQSS/projects</projectsUrl>
  </organization>
</pages>
</root>
